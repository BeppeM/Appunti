\message{ !name(archid.tex)}\documentclass[a4paper,12pt, oneside]{book}

% \usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{engrec}
\usepackage{rotating}
\usepackage{verbatim}
\usepackage[safe,extra]{tipa}
%\usepackage{showkeys}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{fontspec}
\usepackage{enumerate}
\usepackage{braket}
\usepackage{marginnote}
\usepackage{pgfplots}
\usepackage{cancel}
\usepackage{polynom}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage[cache=false]{minted}
\usepackage{mathtools}
\usepackage[noend]{algpseudocode}

\usepackage{tikz}\usetikzlibrary{er}\tikzset{multi  attribute /.style={attribute
    ,double  distance =1.5pt}}\tikzset{derived  attribute /.style={attribute
    ,dashed}}\tikzset{total /.style={double  distance =1.5pt}}\tikzset{every
  entity /.style={draw=orange , fill=orange!20}}\tikzset{every  attribute
  /.style={draw=MediumPurple1, fill=MediumPurple1!20}}\tikzset{every
  relationship /.style={draw=Chartreuse2,
    fill=Chartreuse2!20}}\newcommand{\key}[1]{\underline{#1}}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{decorations.markings}
  \usetikzlibrary{arrows,shapes,backgrounds,petri}
\tikzset{
  place/.style={
        circle,
        thick,
        draw=black,
        minimum size=6mm,
    },
  transition/.style={
    rectangle,
    thick,
    fill=black,
    minimum width=8mm,
    inner ysep=2pt
  },
  transitionv/.style={
    rectangle,
    thick,
    fill=black,
    minimum height=8mm,
    inner xsep=2pt
    }
  } 
\usetikzlibrary{automata,positioning}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}
\fancyfoot[C]{\thepage}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{epsfig}
\usepackage{pst-grad} % For gradients
\usepackage{pst-plot} % For axes
\usepackage[space]{grffile} % For spaces in paths
\usepackage{etoolbox} % For spaces in paths
\makeatletter % For spaces in paths
\patchcmd\Gread@eps{\@inputcheck#1 }{\@inputcheck"#1"\relax}{}{}
\makeatother

\title{Architetture Dati}
\author{UniShare\\\\Davide Cozzi\\\href{https://t.me/dlcgold}{@dlcgold}}
\date{}

\pgfplotsset{compat=1.13}
\begin{document}

\message{ !name(archid.tex) !offset(-3) }

\maketitle

\definecolor{shadecolor}{gray}{0.80}
\setlist{leftmargin = 2cm}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}
\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}
\tableofcontents
\renewcommand{\chaptermark}[1]{%
  \markboth{\chaptername
    \ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}%
\chapter{Introduzione}
\textbf{Questi appunti sono presi a lezione. Per quanto sia stata fatta
  una revisione è altamente probabile (praticamente certo) che possano
  contenere errori, sia di stampa che di vero e proprio contenuto. Per
  eventuali proposte di correzione effettuare una pull request. Link: }
\url{https://github.com/dlcgold/Appunti}.\\
\chapter{Sistemi centralizzati}
\begin{definizione}
  Un \textbf{DBMS (\textit{DataBase Management System})} è un sistema, ovvero un
  software, in grado di gestire collezioni di dati che siano:
  \begin{itemize}
    \item \textit{grandi}, ovvero di dimensioni maggiori della memoria centrale
    dei sistemi di calcolo usati (se ho a che fare con una quantità di dati non
    così grande e con un uso personale posso affidarmi ad una \textit{hashmap}
    piuttosto che ad un db)
    \item \textit{persistenti}, ovvero con un periodo di vita indipendente dalle
    singole esecuzioni dei programmi che le utilizzano e per molto tempo 
    \item \textit{condivise}, ovvero usate da diversi applicativi e diversi
    utenti (fattore che porta anche allo studio del carico di lavoro,
    \textit{workload}). L'accesso può essere sia \textit{in scrittura} che
    \textit{in lettura} (ovviamente anche entrambi) a seconda del caso. SI
    pongono quindi problemi di concorrenza e sicurezza
    \item \textit{affidabili}, sia resistente dal punto di vista hardware (un
    guasto non deve farmi perdere i dati) che dal punto di vista della sicurezza
    informatica. Le transazioni devono essere quindi \textbf{atomiche} (o tutto
    o niente) e \textbf{definitive} (che non verranno più dimenticate). Il
    software può cambiare mentre i dati no
  \end{itemize}
\end{definizione}
A livello di architettura per un \textit{sistema centralizzati} si hanno:
\begin{itemize}
  \item uno o più \textit{storage} per memorizzare i dati, a loro volta su uno o
  più file del \textit{file system}
  \item il \textit{DBMS}, il componente software che funge da componente logico
  \item diverse applicazioni che elaborano i dati provenienti dal db
  (\textit{lettura}) ed eventualmente scrivono dati sullo stesso
  (\textit{scrittura})
  \item il \textbf{DBA (\textit{DataBase Administrator})} che tramite riga di
  comando o GUI si occupa di manutenzione, sicurezza, ottimizzazione etc$\ldots$
  del DBMS 
\end{itemize}
L'\textit{architettura dati} di un DBMS è definita dall'ente \textit{ANSI/SPARC}
e è a tre livelli:
\begin{enumerate}
  \item diversi \textbf{schemi esterni}, porzioni di db messi a disposizione per
  le varie applicazioni
  \item uno \textbf{schema logico (o concettuale)}, che fa riferimento al
  \textit{modello relazionale} dei dati ed è indipendente dalla tecnologia
  usata. Avendo un unico schema logico si ha un'unica semantica (perlomeno a
  livello astratto). Si ha unica base di dati, quindi un unico insieme di record
  interrogati e aggiornati da tutti gli utenti. Non si ha nessuna forma di
  eterogeneità concettuale 
  \item uno \textbf{schema fisico}, che fa riferimento alla tecnologia usata per
  implementare le tabelle per salvare i dati. Si ha un'unica rappresentazione
  fisica dei dati e quindi nessuna distribuzione e nessuna eterogeneità fisica
\end{enumerate}
\textit{Un unico schema fisico è collegato ad un unico schema logico.}\\
Inoltre si hanno:
\begin{itemize}
  \item un \textbf{unico linguaggio di interrogazione} e quindi un'unica
  modalità di accesso ai dati
  \item un unico sistema di gestione per accesso, aggiornamento e gestione per
  la transazioni e le interrogazioni
  \item un'unica modalità di ripristino in caso d'emergenza
  \item un unico amministratore dei dati
  \item \textbf{nessuna autonomia gestionale}
\end{itemize}
Per il discorso della persistenza dei dati si ha necessità di una memoria
secondaria dove il DBMS salva le strutture dati, studiando un modo efficiente di
trasferimento dei dati nel \textit{buffer} in memoria centrale. Il
\textit{buffer} è un'area di memoria (o meglio un componente software) nella
memoria centrale che cerca, tramite una logica di ``vicinanza'', di mettere i
dati della memoria secondaria in quella centrale. Si usa il \textbf{principio di
  località}.\\
A causa degli accessi condivisi al db si hanno problemi di \textbf{concorrenza},
avendo accesso multi-utente alla stessa dei dati condivisa, accesso che
necessità anche di meccanismi di \textbf{autorizzazione}. In merito alla
concorrenza si ha che le transazioni sono corrette se \textbf{seriali} (ordinate
temporalmente) ma questo non è sempre applicabile e quindi si deve stabilire un
\textit{controllo della concorrenza}.\\
Per accedere ai dati di un db si hanno le \textbf{query
  (\textit{interrogazioni})} che fanno parte del modello logico a cui si
interfaccia l'utente. Essendo i dati nelle memorie secondarie bisogna cercare un
modo di rendere gli accessi performanti, in primis tramite opportune strutture
fisiche in quanto e strutture logiche non sarebbero efficienti in memoria
secondaria. Bisogna fare in modo che gli accessi alla memoria secondaria siano
il più limitati possibili e quindi bisogna ottimizzare l'esecuzione delle query.
Ovviamente una scansione lineare delle tabelle sarebbe troppo dispendiosa con
tabelle grosse, ricordando che i file sono ad accesso sequenziale. Inoltre un
ipotetico \textit{join} tra tabelle renderebbe ancora più complesso l'accesso,
soprattutto se \textit{full-join}.\\
Per poter garantire tutto ciò che è stato detto l'architettura del DBMS deve
essere organizzata in termini di \textit{funzionalità cooperanti}:
\begin{itemize}
  \item un \textbf{query compiler} che prende una query in SQL e la traduce con
  un compilatore
  \item un \textbf{gestore di interrogazioni e aggiornamenti} che trasforma le
  query in SQL in algebra relazionale facendo operazioni di ottimizzazione
  \item un \textbf{gestore dei metodi di accesso} per permettere il passaggio
  tra file e tabelle passando dal \textbf{gestore del buffer} e il
  \textbf{gestore della memoria secondaria} dove i dati non sono in forma
  tabellare ma di file e pagine
  \item un \textbf{DDL compiler}, dove DDL sta per Data Description Language,
  che si occupa dei comandi del DBA
  \item un \textbf{gestore della concorrenza}, che garantisce il controllo della
  concorrenza
  \item un \textbf{gestore dell'affidabilità}, che garantisce che un dato non
  vada perso
  \item un \textbf{gestore delle transazioni}
\end{itemize}
Gli ultimi quattro entrano in uso specialmente in fase di scrittura.\\
\textbf{Tutto deve essere veloce!}\\
In un sistema distribuito la parte di query compiler, gestore delle
interrogazioni, gestore delle transazioni e gestore della concorrenza resta
invariato mentre il resto cambia drasticamente (in quanto i dati sono
distribuiti) dovendo gestire diversamente l'accesso ai dati e la sua
sicurezza. Bisogna gestire anche come i vari nodi devono interagire coi dati.
\section{Ottimizzazione delle query}
Ottimizzare le query è tutt'altro che banale.\\
Il primo step è il \textbf{parsing}, che stabilisce se la query è sensata dal
punto di vista sintattico e se i vari nomi di tabelle e attributi sono coerenti
con lo schema. Per questo ultimo aspetta ci si appoggia al \textbf{Data
  Catalog}, un particolare db che contiene informazioni sui vari database, in
primis sui vari nomi delle tabelle e per ciascuna sui nomi di ogni attributo. SI
ha quindi una soluzione per gestire i \textit{metadati}. Il parser effettua
un'analisi lessicale, per la sintattica e la semantica, usando il dizionario e
l a traduzione in algebra relazionale, producendo un \textbf{query tree}. Si
calcola anche un \textbf{query plan logico}, utilizzando regole sintattiche di
buon senso, per capire cosa fare prima (per esempio se fare prima una
\textit{select} o un \textit{join}) per ottenere il risultato corretto nel minor
tempo possibile (prima di fare una \textit{join} magari seleziono prima una
sottotabella con i dati potenzialmente utili, togliendo quelli sicuramente
inutili$\ldots$ magari quel \textit{join} può anche essere evitato). La query
viene quindi rappresentata come un albero dove e foglie corrispondono alle
strutture dati logiche, ovvero le tabelle. I nodi interni sono invece le varie
\textbf{operazioni algebriche (\textit{select, join, proiezione, prodotto
    cartesiano} e \textit{operazioni insiemistiche})}.
\newpage
\begin{esempio}
  Vediamo una query:
  \begin{minted}{sql}
    SELECT Pnumber, Dnum, Lname, Address, Bdate
    FROM Project P, Dept D, Emp E
    Where P.dnum=D.dnumber and E.ssn = D.mgrssn
    and P.location = 'Stafford'
  \end{minted}
  che produce:
  \begin{center}
    \psscalebox{1.0 1.0} % Change this value to rescale the drawing.
    {
      \begin{pspicture}(0,-2.36)(10.7,2.36)
        \rput[bl](4.0,2.1249022){$\pi$ Pnumber, Dnum, Lname, Address, Bdate}
        \rput[bl](5.6,0.9249023){join mgrssn=ssn}
        \rput[bl](2.0,0.124902345){join dnum=dnumber}
        \rput[bl](8.4,0.124902345){emp}
        \rput[bl](0.0,-1.0750977){$\sigma$ plocation='stafford'}
        \rput[bl](6.4,-1.0750977){dept}
        \rput[bl](1.6,-2.2750976){project}
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm
        2.0,arrowlength=1.4,arrowinset=0.0]{<-}(6.8,1.3249023)(6.8,2.1249022)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm
        2.0,arrowlength=1.4,arrowinset=0.0]{<-}(8.8,0.52490234)(8.4,0.9249023)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm
        2.0,arrowlength=1.4,arrowinset=0.0]{<-}(5.2,0.52490234)(6.0,0.9249023)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm 2.0,
        arrowlength=1.4,arrowinset=0.0]{<-}(3.6,-0.67509764)(3.6,0.124902345)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm 2.0,
        arrowlength=1.4,arrowinset=0.0]{<-}(6.4,-0.67509764)(4.8,0.124902345)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm
        2.0,arrowlength=1.4,arrowinset=0.0]{<-}(2.4,-1.8750976)(2.4,-1.0750977)
      \end{pspicture}
    }
  \end{center}
  ma l'ottimizzatore va oltre (magari invertendo i \textit{where} etc$\ldots$)
  con un query plan più efficiente che permette di cambiare automaticamente le
  query in altre più efficienti.\\
\end{esempio}
Si ha un db chiamato \textbf{Statistics} che contiene statistiche sulla storia
delle query nonché altre informazioni sui dati. L'uso di tale db permette di
ottimizzare le query.\\
Solo dopo questo processo si ha la trasformazione delle tabelle logiche in
strutture fisiche e metodi di accesso alla memoria e la trasformazione delle
operazioni algebriche nelle loro implementazioni sulle strutture fisiche. Per la
trasformazione si usano proprietà algebriche e una stima dei costi delle
operazioni fondamentali per diversi metodi di accesso (in poche parole le regole
della ricerca operativa). L'ottimizzazione ha complessità \textbf{esponenziale}
e quindi si introducono approssimazioni basate su euristiche, usando
un'\textbf{alberatura di costi} usando la tecnica del \textbf{Branch\&Bound}.
\section{Transazioni}
Una \textbf{transazione} è l'insieme di istruzioni di accesso in lettura e
scrittura ai dati, istruzioni eventualmente inserite in un linguaggio di
programmazione. Una transazione gode di proprietà che garantiscono la corretta
esecuzione anche in ambito di concorrenza e sicurezza, tanto che sono
paradigmatiche del modello relazionale. Le transazioni iniziano con un
\textbf{begin-transaction} (a volte finiscono con \textit{end-transaction},
opzionale) e all'interno deve essere eseguito tra:
\begin{itemize}
  \item \textbf{commit work}, per terminare correttamente la lettura e/o
  scrittura 
  \item \textbf{rollback work}, per abortire la transazione
\end{itemize}
Un \textbf{sistema transazionale OLTP (\textit{OnLine Transaction Processing})}
è in grado di definire ed eseguire transazioni per conto di un certo numero di
applicazioni concorrenti anche alto. 
\begin{esempio}
  Vediamo un esempio di transazione (esempio di addebito su un conto corrente e
  accredito su un altro):
  \begin{minted}{sql}
    start transaction;
    update ContoCorrente
      set Saldo = Saldo + 10 where
      NumConto = 12202;
    update ContoCorrente
      set Saldo = Saldo – 10 where
      NumConto = 42177;
    commit work;
  \end{minted}
  oppure, con anche la verifica che ci siano ancora soldi dopo il prelievo (con
  eventuale aborto):
  \begin{minted}{sql}
    start transaction;
    update ContoCorrente
      set Saldo = Saldo + 10 where
      NumConto = 12202;
    update ContoCorrente
      set Saldo = Saldo – 10 where
      NumConto = 42177;
    select Saldo into A
      from ContoCorrente
      where NumConto = 42177;
    if (A >= 0) then commit work
    else rollback work;
  \end{minted}
  Il controllo può essere fatto a posteriori grazie al rollback che permette di
  ``dimenticare'' tutte le operazioni precedenti
\end{esempio}
Le istruzioni commit work e rollback work possono comparire più volte
all'interno del programma ma esattamente una delle due deve essere eseguita. Si
ha un \textbf{approccio binario}.\\
Bisogna approfondire quindi le \textbf{unità di elaborazione} che hanno le
proprietà cosiddette \textit{ACID}:
\begin{itemize}
  \item \textbf{Atomicità}, ovvero una transazione è un'unità atomica di
  elaborazione. Non si può lasciare il db in uno ``stato 
  intermedio''. Un problema prima del commit cancella tutto le operazioni svolte
  (\textit{UNDO}) e un problema dopo il commit non deve avere conseguenze, se
  necessario vanno ripetute le operazioni (\textit{REDO}) 
  \item \textbf{Consistenza}, ovvero la transazione rispetta i vincoli di
  integrità (se lo stato iniziale è corretto lo è anche quello finale). Quindi
  se ci sono violazioni non devono restare alla fine (nel caso
  \textit{rollback})
  \item \textbf{Isolamento}, ovvero la transazione non risente delle altre
  transazioni concorrenti. Una transazione non espone i suoi stati intermedi
  evitando l'\textit{effetto domino} (si evita che il rollback di una
  transazione vada in cascata con le altre). L'esecuzione concorrente di una
  collezione di transazioni deve produrre un risultato che si potrebbe ottenere
  con una esecuzione sequenziale
  \item \textbf{Durabilità} (ovvero persistenza), ovvero gli effetti di una
  transazione andata in commit non vanno persi anche in presenza di guasti (a
  tal fine si sfrutta il \textbf{recovery manager}, che garantisce
  l'affidabilità, del DBMS)
\end{itemize}
\section{Gestore della concorrenza}
Il \textbf{gestore della concorrenza} permette di eseguire in parallelo più
operazioni.\\
Definiamo \textbf{schedule} come una sequenza di esecuzione di un insieme di
transazioni. Uno schedule è \textbf{seriale} se se una transazione  termina
prima che la successiva iniziale, altrimenti è \textbf{non seriale}. Qualora non
sia seriale si potrebbero avere problemi.\\
Si sfrutta quindi la \textbf{proprietà di isolamento} facendo in modo che ogni
transazione esegua come se non ci fosse concorrenza: \textit{un insieme di
  transazioni eseguite concorrentemente produce lo stesso risultato che
  produrrebbe una (qualsiasi) delle possibili esecuzioni sequenziali delle stesse
  transazioni allora si ha la proprietà di isolamento}.\\
Si ha quindi che uno schedule è serializzabile se l'esito della sua esecuzione è
lo stesso che si avrebbe con una qualsiasi sequenza seriale delle transazioni
contenute.\\
Si hanno quindi diversi algoritmi per il controllo della concorrenza secondo
varie tipologie:
\begin{itemize}
  \item controllo basato su \textit{conflict equivalence}
  \item controllo di concorrenza basato su \textit{locks} \textit{(protocollo
    2PL o two phase locking, shared locks e gestione dei deadlock}). Il
  protocollo 2PL è usato nei DBMS dove per costruzione si hanno schedule
  serializzabili usando i lock per  bloccare l'accesso alla risorse da parte di
  una transazione fino a che una risorsa non sia rilasciata. Si hanno quindi i
  concetti di \textit{lock} e \textit{unlock} che garantiscono l'uso esclusivo
  di una risorsa e l'autorizzazione esclusiva dell'uso di una risorsa viene dato
  dal gestore delle transazioni. Si hanno delle \textbf{tabelle di lock}. Si ha
  che, in ogni transazione, tutte le richieste di \textit{lock} precedono tutti
  gli \textit{unlock} (che comunque devono essere fatti dopo l'operazione di
  \textit{commit}) 
  \item controllo di concorrenza basato su \textit{timestamps}
\end{itemize}
\chapter{Sistemi distribuiti relazionali}
Abbiamo visto nei sistemi centralizzati come ci fosse una sola base dati. In un
sistema distribuito abbiamo diversi \textbf{basi dati locali}, diverse
applicazioni su ogni nodo di elaborazione (dove ogni nodo condivide varie
informazioni) con gli utenti che accedono alle varie applicazioni. Questo tipo
di architettura prende il nome di \textbf{architettura shared nothing}, in
quanto i DBMS di ogni singola macchina sono autonome (anche di vendor diversi)
ma che lavorano insieme.\\
Un sistema distribuito permette non solo di avere dati ``distribuiti'' tra vari
nodi ma anche di ``duplicarne'' alcuni per diversi scopi, coi nodi collegati in
rete (addirittura si hanno soluzioni interamente distribuite nel cloud).\\
Confrontando un db distribuito con un multi-database (ovvero vari database
completi da ``unificare'') notiamo come entrambi
abbiano un'alta distribuzione, il primo una bassa eterogeneità (a differenza del
secondo, dove nei vari db potrei avere forte differenza di tipologia dei dati
contenuti). Si ha anche bassa autonomia nel caso si db distribuiti a differenza
del multi-database (dove ogni db è singolarmente autonomo).\\
Bisogna capire cosa distribuire. Si hanno diverse condizioni (che possono essere
presenti simultaneamente):
\begin{itemize}
  \item le applicazioni, fra loro cooperanti, risiedono su più nodi elaborativi
  \textbf{(elaborazione distribuita})
  \item l'archivio informativo è distribuito su più nodi (\textbf{base di dati
  distribuita}) 
\end{itemize}
La distribuzione si dice essere \textbf{ortogonale e trasparente} agli altri.\\
Capire cosa distribuire è una parte consistente dello studio di come costruire
un'architettura distribuita (magari frutto di situazioni particolari come la
``fusione'' di due sistemi a causa di un'acquisizione aziendale etc$\ldots$ dove
diverse logiche applicative e diverse strutture dati possono creare situazioni
molto pericolose).\\
Possiamo classificare i db distribuiti. Si ha innanzitutto che un \textbf{DBMS
Distribuito Eterogeneo Autonomo} è in generale una federazione di DBMS che
collaborano nel fornire servizi di accesso ai dati con livelli di
\textit{trasparenza} definiti (infatti le diversità tra db nei nodi vengono
``nascosti'' a vari \textit{livelli di trasparenza} per distribuzione,
eterogeneità e autonomia). Come abbiamo visto esiste l'esigenza di integrare a
posteriori vari db preesistenti (anche a causa di integrazione di nuovi
applicativi o nuove cooperazioni di processi) e questa situazione è spinta
dallo sviluppo della rete.\\
Possiamo quindi dividere i livello di federazione su tre categorie tra loro
ortogonali (ovvero indipendenti):
\begin{itemize}
  \item autonomia
  \item distribuzione
  \item eterogeneità
\end{itemize}
\subsubsection{Autonomia}
L'\textbf{autonomia} fa riferimento al grado di indipendenza tra i nodi e si
hanno diverse forme:
\begin{itemize}
  \item \textbf{autonomia di progetto}, il livello ``massimo'' dove ogni nodo ha
  un proprio modello dei dati e di gestione delle transazioni
  \item \textbf{autonomia di condivisione}, dove ogni nodo sceglie la porzione
  di dati da condividere ma condividendo con gli altri nodi lo schema comune
  \item \textbf{autonomia di esecuzione}, dove ogni nodo sceglie in che modo
  eseguire le transazioni
\end{itemize}
Si hanno quindi:
\begin{itemize}
  \item \textbf{DBMS Strettamente integrati} con nessuna autonomia, con dati
  logicamente centralizzati, un unico data manager per le transazioni
  applicative e vari data manager locali che non operano in modo autonomo ma
  eseguono le direttive centrali
  \item \textbf{DBMS semi-autonomi}, dove ogni data manager è autonomo ma
  partecipa a transazioni globali, dove una parte dei dati è condivisa e dove
  sono richieste modifiche architetturali  per poter fare parte della
  federazione
  \item \textbf{DBMS Peer to Peer} completamente autonomi, dove ogni DBMS lavora
  in completa autonomia ed è inconsapevole dell'esistenza degli altri  
\end{itemize}
\subsubsection{Distribuzione}
Per la\textbf{ distribuzione} dei dati si hanno 3 livelli classici:
\begin{itemize}
  \item \textbf{distribuzione client/server}, in cui la gestione dei dati è
  concentrata nei server, mentre i client forniscono l'ambiente applicativo e la
  presentazione
  \item \textbf{distribuzione Peer to Peer}, in cui non c'è distinzione tra
  client e server, e tutti i nodi del sistema hanno identiche funzionalità DBMS
  \item \textbf{nessuna distribuzione}
\end{itemize}
Le prime due possono anche non essere distinte.
\subsubsection{Eterogeneità}
L'\textbf{eterogeneità} può invece riguardare vari aspetti:
\begin{itemize}
  \item \textbf{modello dei dati} (relazionale, XML, object oriented (OO), json)
  \item \textbf{linguaggio di query} (diversi dialetti SQL, query by example,
  linguaggi di interrogazione OO o XML)
  \item \textbf{gestione delle transazione} (protocolli diversi per il gestore
  della concorrenza o per il recovery)
  \item \textbf{schema concettuale e logico} (concetti rappresentati in uno
  schema come attributo e in altri come entità)
\end{itemize}
Quindi si hanno vari tipi di DBMS:
\begin{itemize}
  \item \textbf{DBMS distribuito omogeneo (DDBMS)} quando si ha alta
  distribuzione ma non si hanno autonomia ed eterogeneità (gestiti solitamente
  dallo stesso vendor)
  \item \textbf{DBMS eterogeneo logicamente integrato (data warehouse)} quando
  si ha alta eterogeneità ma non si hanno distribuzione e autonomia
  \item \textbf{DBMS distribuiti eterogenei} quando si ha alta eterogeneità e
  distribuzione ma non autonomia 
  \item \textbf{DBMS federati distribuiti} quando si ha alta
  distribuzione, semi autonomia e non eterogeneità
  \item \textbf{DBMS distribuiti federati eterogenei} quando si ha alta
  distribuzione ed eterogeneità e semi autonomia
  \item \textbf{multi db MS}, totalmente autonomi ed eventualmente omogenei o
  eterogenei 
\end{itemize}
\textit{Si hanno molti altri sistemi in base alle 3 categorie}.\\
\section{DDBMS}
Parliamo di \textbf{DBMS distribuito omogeneo (\textit{DDBMS})}.\\
Studiamo uno schema in cui si passa da un sistema centralizzato ad un sistema
distribuito.\\
Si hanno due architetture di riferimento:
\begin{itemize}
  \item l'\textbf{architettura dati}
  \item l'\textbf{architettura funzionale}, ovvero l'insieme di tecnologie a
  supporto dell'architettura dati
\end{itemize}
Non avendo eterogeneità mantengo lo stesso schema di un DBMS centralizzato ma
distribuisco dati bisogna prendere lo schema centralizzato e aggiungere
componenti tra lo schema logico e lo schema fisico. Infatti non si avrà più un
solo schema logico e un unisco schema fisico ma tanti schemi logici e fisici
locali (ad ogni logico corrisponde un fisico). I vari schemi logici inoltre si
interfacciano con uno \textbf{schema logico globale}, i vari schemi logici
locali non sono quindi altro che delle \textit{viste} dello schema logico
globale. Questa organizzazione tra schemi logici locali e schema logico globale
è la cosiddetta \textbf{organizzazione LAV (\textit{Local As View})}. In ogni
caso il progettista interroga lo schema logico globale e saranno varie
tecnologie ad interrogare gli schemi logici locali (si fa una sorta di routing
delle query).\\
Per ciascuna funzione (come query processing, transaction manager etc$\ldots$)
si possono avere vari tipi di gestione:
\begin{itemize}
  \item centralizzata/gerarchica o distribuita
  \item con assegnazione statica o dinamica dei ruoli
\end{itemize}
\textit{Lo schema globale viene progettato prima degli schemi locali.}\\
Ovviamente cambia il \textbf{processo di progettazione} nel caso dei
DDBMS. Normalmente si ha un approccio \textit{top-down} per la progettazione,
con:
\begin{enumerate}
  \item analisi dei requisiti
  \item progettazione concettuale
  \item progettazione logica
  \item progettazione fisica
\end{enumerate}
ma questo tipo di progettazione va cambiato e quindi si introduce una nuova
fase e si cambiano le ultime due:
\begin{enumerate}
  \item analisi dei requisiti
  \item progettazione concettuale
  \item \textbf{progettazione della distribuzione}, per capire dove mettere i
  dati
  \item progettazione logica \textbf{locale}, che traduce dallo schema
  concettuale globale allo schema logico locale solo alcuni concetti
  \item progettazione fisica \textbf{locale}
\end{enumerate}
Si introduce il concetto di \textbf{portabilità}, ovvero la capacità di
eseguire le stesse applicazioni DB su ambienti runtime diversi (anche con SQL
diversi e differenti dallo standard). La portabilità è a \textit{compile-time}\\
Si ha anche il concetto di \textbf{interoperabilità} (tra vendors diversi),
ovvero la capacità di eseguire applicazioni che coinvolgono contemporaneamente
sistemi diversi ed eterogenei (con zero autonomia). A tal fine sono stati
introdotti dei \textit{middleware}, tra cui \textbf{ODBC} che si occupa
dell'accesso a dati di diversi vendor. ODBC, a livello architetturale, si pone
sopra il DBMS e da un'immagine indipendente da ciò che c'è sotto (funziona come
una sorta di \textit{driver}), trasformando tutto in una sorta di SQL
standard. Si hanno anche dei protocolli, come \textbf{X-Open Distributed
  Transaction Processing (\textit{DTP})}, che consentono di eseguire delle
transazioni secondo una logica diversa. Questo protocollo stabilisce una serie
di API che vengono implementate da ogni singolo DBMS per offrire una
connettività standard (approccio molto usato per transazioni con vendor
diversi). Il protocollo funziona sia se si ha che fare con omogeneità che con
eterogeneità. \\
Si hanno altri approcci:
\begin{itemize}
  \item \textbf{basi dati parallele}, con incremento delle prestazione mediante
  parallelismo sia di storage devices che di processore (scalabilità
  orizzontale). Un esempio sono le \textbf{basi dati GRID}
  \item \textbf{basi dati replicate} dove si ha la
  replicazione della stessa informazione su diversi server per motivi di
  performance. Importanti per i temi della consistenza e della sicurezza
  \item \textbf{Data warehouses}, ovvero DBMS centralizzati, risultato
  dell'integrazione di fonti eterogenee, dedicati nel dettaglio alla gestione di
  dati per il supporto alle decisioni. Prevede la \textit{cristallizzazione} dei
  dati, acquisiti da varie sorgenti, creando un nuovo schema con la
  memorizzazione dei dati in formato nuovo (solitamente relazionale). Non usa un
  approccio LAV 
\end{itemize}
\subsection{Caratteristiche dei DDBMS}
Si hanno vari tipi di architetture DDBMS:
\begin{itemize}
  \item \textbf{shared-everything}, ad esempio \textit{SMP server}, dove il db
  management system e il disco sono in un unico nodo
  \item \textbf{shared-disk}, ad esempio \textit{Oracle RAC}, dove diversi db
  management systems 
  agiscono su una stessa \textbf{SAN (\textit{Storage Area Network})}, ovvero
  un'architettura dati di puro storage (con tanti dischi in raid). I vari db
  accedono ai dati secondo una certa regolazione. Viene distribuito il carico
  sui db ma si hanno problemi di concorrenza e hanno grandi problemi di
  scalabilità e costo economico
  \item \textbf{shared-nothing}, sempre più usati, dove ogni db management
  system ha il suo disco. È molto scalabile e, a patto di gestire la
  complessità, posso aggiungere nodi in modo illimitato (\textbf{scalabilità
    orizzontale}). Si presta molto all'ambiente cloud. Sono \textit{architetture
  federate}.
\end{itemize}
Vediamo quindi le proprietà generali di un DDBMS (facendo esplicito riferimento
alle architetture \textit{shared-nothing} per la loro scalabilità):
\begin{itemize}
  \item \textbf{località}, secondo il \textit{principio di località}, che
  garantisce un aumento di performances (nonché di sicurezza) tenendo i dati si
  trovano ``vicino'' 
  alle applicazioni che li utilizzano più frequentemente 
  \item \textbf{modularità}, permettendo di scalare orizzontalmente e
  permettendo modifiche a dati ed applicazioni a basso costo
  \item \textbf{resistenza ai guasti}
  \item \textbf{prestazioni ed efficienza}
\end{itemize}
Concentrandoci sulla \textbf{località} si ha che la partizione dei dati
corrisponde spesso ad una partizione naturale delle applicazioni e degli utenti.
I dati risiedono più vicino a dove vengono più usati ma possono comunque essere
raggiunti anche da lontano (\textit{globalmente}). Si cerca inoltre sempre di
più di spostare i dati verso le applicazioni (paradigma ribaltato nel caso di
\textit{big data}).\\
In merito alla \textbf{modularità} si nota come la distribuzione dinamica dei
dati si adatta meglio alle esigenze delle applicazioni (magari spostando solo
sottotabelle verso alcuni nodi etc$\ldots$, sia in modo trasparente rispetto
all'utente che altrimenti).\\
Parlando di \textbf{resistenza ai guasti} si ha una maggior fragilità a causa
delle unità che aumentano di numero ma si ha \textbf{ridondanza} e quindi
maggiore resistenza ai guasti di dati e applicazioni ridondate (\textit{fail
  soft}).\\
Discorso più interessante è da farsi sulle \textbf{prestazioni}. Ogni nodo in un
sistema shared-nothing gestisce db di dimensioni ridotte. Inoltre ogni nodo può
essere ottimizzato ad hoc ed è più semplice gestire e ottimizzare applicazioni
locali. Si ha inoltre distribuzione del carico totale e parallelismo  tra
transazioni locali che fanno parte di una stessa transazione distribuita (anche
se questo aspetta obbliga soluzioni di coordinamento e appesantisce il carico
sulla rete, che rischia di diventare un ``collo di bottiglia'').\\
I DDBMS hanno ovviamente \textbf{funzionalità} specifiche.\\
Ogni server ha buona capacità di gestire transazioni indipendentemente, anche se
le interazione distribuita tra server rappresentata un carico supplementare. Per
le interrogazioni si ha che le query arrivano dalle applicazioni e i risultati
dai server mentre per le transazioni le richieste transazionali arrivano dalle
applicazioni ma sono richiesti \textbf{dati di controllo} per il
coordinamento.\\’
La gestione della rete deve essere ottimizzata e serve uno studio sulla
distribuzione locale dei dati.\\
Ricapitolando si hanno le seguenti funzionalità specifiche:
\begin{itemize}
  \item \textbf{trasmissione} di query, transizioni, frammenti di db e dati di
  controllo tra i nodi
  \item \textbf{frammentazione, replicazione e trasparenza} (secondo vari
  livelli), fattori legati alla natura distribuita dei dati
  \item un \textbf{query processor} e un \textbf{query plan} per la previsione
  di una strategia globale accanto a strategie per le query locali. Si gestisce
  il passaggio tra schema logico globale e quelli locali. Chi esegue
  la query lo fa senza pensare alla frammentazione dei dati
  \item \textbf{controllo di concorrenza} tramite algoritmi distribuiti,
  fondamentale per gli accessi \textit{in scrittura}
  \item \textbf{strategie di recovery} e \textbf{gestione dei guasti}, sia in
  merito alla rete che all'hardware stesso
\end{itemize}
\subsection{Frammentazione e replicazione}
Si definisce \textbf{frammentazione} come la possibilità di allocare porzioni
(\textit{chunk}) diverse del db su nodi diversi.\\
Si definisce \textbf{replicazione} come la possibilità di allocare stesse
porzioni del db su nodi diversi.\\
Si definisce \textbf{trasparenza} come la possibilità per l'applicazione di
accedere ai dati senza sapere dove sono allocati (serve qualcosa che instradi le
query).
\subsubsection{frammentazione}
Esistono due tipi di frammentazione:
\begin{enumerate}
  \item \textbf{frammentazione orizzontale}, che prevede di prendere una tabella
  e frammentare in base alle righe (le prime $n$ da una parte, le seconde $m$
  dall'altra etc$\ldots$). Si mantiene quindi inalterato lo schema in quanto
  ottengo solamente delle tabelle più piccole in quanto pezzi. Per spezzare uso
  una \textit{select} (per la \textbf{selezione}) che selezioni ogni volta un
  certo ``blocco'' di tabella 
  \item \textbf{frammentazione verticale}, che consente di ridurre la
  dimensionalità della tabelle spezzandola in base alle colonne. In ogni nuova
  tabella però la prima colonna deve essere uguale alla prima della tabella
  originale (ovvero dove si ha la chiave primaria), questo per garantire che si
  possa ricomporre la tabella (e lo schema) originale (con operazioni di
  \textit{join}, o meglio un \textit{natural join}) e garantire la
  trasparenza. Anche in questo caso uso 
  una \textit{select} (per la \textbf{proiezione}) che selezioni ogni volta un
  certo numero di colonne da mettere nella nuova tabella
\end{enumerate}
Bisogna quindi garantire:
\begin{itemize}
  \item \textbf{completezza}, ovvero ogni record della relazione $R$ di partenza
  deve poter essere ritrovato in almeno uno dei frammenti
  \item \textbf{ricostruibilità}, ovvero la relazione $R$ di partenza deve poter
  essere ricostruita senza perdita di informazione a partire dai frammenti
  \item \textbf{disgiunzione}, ovvero ogni record della relazione $R$ deve
  essere rappresentato in uno solo dei frammenti
  \item \textbf{replicazione}, l'opposto della disgiunzione
\end{itemize}
Quindi possiamo definire meglio le proprietà dei due tipi di frammentazione per
la relazione $R$, frammentata in diversi $R_i$:
\begin{enumerate}
  \item \textbf{orizzontale}:
  \begin{itemize}
    \item $schema(R_i)=schema(R),\,\forall i$
    \item ogni $R_i$ contiene un sottoinsieme dei record di $R$
    \item è definita da una proiezione su una condizione $ci$: $\sigma_{ci}(R)$
    \item garantisce la completezza, infatti $R_1\cup R_2\cup\ldots R_n=R$
    \item l'unione garantisce la ricostruibilità
  \end{itemize}
  \item \textbf{verticale}:
  \begin{itemize}
    \item $schema(R)=L=(A_1,\ldots,A_m)$ e $schema(R_i) = L_i =
    (A_{i1},\ldots,A_{ik})$ 
    \item garantisce la completezza, infatti $L_1\cup L_2\cup\ldots L_n=L$, dove
    i vari $L_i$ sono i frammenti verticali ed $L$ è la tabella originale
    \item si garantisce la ricostruibilità in quanto $L_i\cap L_j \supseteq
    chiave\,\,\,primaria(R),\,\forall i\neq j$ (ovvero ogni frammento deve
    contenere la chiave primaria)
  \end{itemize}
\end{enumerate}
\subsubsection{Replicazione}
Approfondiamo ora la \textbf{replicazione}. Si hanno diversi aspetti positivi
per l'accesso \textit{in lettura},
come il miglioramento delle prestazioni in quanto consente la coesistenza di
applicazioni con requisiti operazionali diversi sugli stessi dati e aumenta la
\textit{località dei dati} usati da ogni applicazioni. Nel momento in cui si ha
l'accesso \textit{in scrittura} si hanno però diversi aspetti negativi. Si hanno
diverse complicazioni architetturali, tra cui la gestione della transazioni e
l'updates di copie multiple, che devono essere tutte aggiornate. Inoltre bisogna
studiare dal punto di vista progettuale cosa replicare, quanto replicare (ovvero
capire quante copie mantenere), dove allocare le copie e le politiche per
gestirle.\\
In merito all'allocazione studiamo anche gli \textbf{schemi di
  allocazione}. Ogni frammento può essere allocato su un nodo diverso. Lo schema
globale quindi è solo \textit{virtuale} (in quanto non materializzato in un
solo nodo) e lo \textbf{schema di allocazione} definisce il \textit{mapping} tra
un frammento e un nodo. Si ha quindi una tabella, un \textbf{catalogo}, che ci
da informazioni sul partizionamento, associando ogni frammento al nodo in cui è
allocato.
\subsubsection{Trasparenza}
Con la \textbf{trasparenza} si ha la separazione della semantica di alto livello
dalle modalità di frammentazione e allocazione. Si separa quindi la
\textit{logica applicativa} dalla \textit{logica dei dati} ma per farlo serve
uno strato software che gestisca la traduzione dallo schema unico ai
sottoschemi, comportando un aumento di complessità del sistema e una perdita di
prestazioni (problemi che si riducono con un \textit{mapping} integrato del
DDBMS).\\
Le applicazioni (transazioni, interrogazioni) non devono essere modificate a
seguito di cambiamenti nella definizione e organizzazione dei dati e si hanno
due tipi di trasparenza, che si applicano agli schemi ANSI-SPARC nel modello
distribuito (schema logico globale e schemi logici/fisici locali):
\begin{enumerate}
  \item \textbf{trasparenza logica (o indipendenza logica)}, ovvero in
  dipendenza dell'applicazione da modifiche dello schema logico. Un'applicazione
  che usa un frammento non viene modificata se vengono modificati altri
  frammenti
  \item \textbf{trasparenza fisica (o indipendenza fisica)}, ovvero in
  dipendenza dell'applicazione da modifiche dello schema fisico
\end{enumerate}
Frammentazione e allocazione sono tra lo schema logico globale e ogni schema
logico locale. \\
Si hanno quindi tre livelli di trasparenza:
\begin{itemize}
  \item \textbf{trasparenza di frammentazione}, che permette di ignorare
  l'esistenza dei frammenti ed è lo scenario migliore per la programmazione
  applicativa con un'applicazione scritta in SQL standard. Il sistema si occupa
  di convertire query globali in locali e relazioni in sotto-relazioni. La
  scomposizione delle query per ogni sotto-relazione è detta \textbf{query
    rewriting} 
  \item \textbf{trasparenza di replicazione/allocazione}, dove l'applicazione è
  consapevole dei frammenti ma non dei nodi in cui si trovano. In questo caso la
  query è già spezzata in quanto si sa di avere a che fare con un sistema
  frammentato
  \item \textbf{trasparenza di linguaggio}, dove l'applicazione specifica sia
  i frammenti che i nodi, nodi che possono offrire interfacce che non sono SQL
  standard. Tuttavia l'applicazione sarà scritta in SQL standard a prescindere
  dai linguaggi locali dei nodi. Le query vengono quindi tradotte
  ottimizzatone di query. \textit{Questo è il livello di trasparenza più
    basso}
\end{itemize}
\section{Query distribuite}
Analizzeremo prevalentemente DDBMS distribuiti \textit{shared-nothing} e, in
seguito, \textit{architetture di replica} (con un \textit{replication server}
atto a gestire al replica).\\
Le query sono ovviamente le operazioni più importanti. Possono essere di sola
\textit{lettura} (tramite operazioni come la \textit{select}) o anche di
\textit{scrittura}. Le due tipologie di operazioni vengono gestite in modo
molto differente (la lettura sincrona non è un problema, se non hardware
risolvibile con una distribuzione del carico, a differenza della scrittura
sincrona). Le operazioni devono essere eseguite \textbf{velocemente}.
\subsection{Accesso in lettura}
Studiamo prima le \textbf{query in scrittura}.\\
Esistono, in un sistema relazionale, una serie di attività che convertono la
query in SQL in algebra relazionale e solo dopo si ha la distribuzione. 
L'utente, ignaro dello schema distribuito, interroga lo schema
logico globale e il DDBMS decompone la query secondo una localizzazione
specifica in base ai singoli frammenti (ovvero deve distribuire la query in modo
sensato). Si ha anche un'ottimizzazione globale della query prima della
distribuzione in modo che anche la distribuzione stessa sia ottimizzabile
correttamente, infatti il gestore delle interrogazioni manda ai singoli nodi i
giusti frammenti di query che verranno ottimizzati localmente. Ho quindi nel
complesso 4 fasi che compongono il \textbf{query processor}:
\begin{enumerate}
  \item \textbf{query decomposition}
  \item \textbf{data localization}
  \item \textbf{global query optimization}
  \item \textbf{local optimization}
\end{enumerate}
\subsubsection{Query decomposition}
La \textit{query decomposition} opera sullo schema logico globale non tenendo
conto della distribuzione. In questo caso si hanno tecniche di ottimizzazione
algebrica (usando quindi l'algebra relazionale indipendentemente dalla
distribuzione) analoghe a quelle usati in sistemi centralizzati e si ha come
output un \textbf{query tree} non ottimizzato rispetto ai \textbf{costi di
comunicazione}. Il costo di comunicazione riguarda il costo di uso della
\textbf{rete} e dipende da vari fattori. Il costo di comunicazione è il vero
``collo di bottiglia'' in sistemi distribuiti.
\subsubsection{Data localization}
La \textit{data localization} considera la frammentazione delle tabelle e la
distribuzione, capendo ad esempio dove effettuare le \textit{select}
etc$\ldots$. Si procede quindi all'ottimizzazione delle operazioni rispetto 
alla frammentazione, tramite \textbf{tecniche di riduzione}. Viene quindi
prodotta una query efficiente per la frammentazione ma non
ottimizzata. Supponiamo per esempio di avere una tabella su 3 nodi (distribuita
tramite frammentazione orizzontalmente) e che di base
la query faccia la richiesta a tutti e tre (facendo l'unione dei
risultati). Usando la tecnica di riduzione, qualora, per esempio, effettivamente
sia necessaria solo in un nodo, si avrà che la query sarà distribuita unicamente
nel nodo corretto.
\subsubsection{Global query optimization}
La \textit{global query optimization} si basa sulle statistiche sui frammenti
per effettuare l'ottimizzazione. Viene arricchito il \textbf{query tree}, creato
con gli operatori dell'algebra relazionale, tramite gli \textbf{operatori di
  comunicazione} (ovvero \textit{send} e \textit{receive}), che vengono
effettuati tra nodi. Alcune query, dopo aver tenuto conto dei tempi di
comunicazione, potranno essere eseguite in parallelo (grazie all'indipendenza
data dallo \textit{shared-nothing}). In questo caso le decisione più rilevanti
riguardano le operazioni di \textit{join} (che è uno degli operatori più
complicati) e,in particolare (come vedremo più avanti), l'ordine tra i
\textit{join} n-ari e la scelta tra \textit{join} e \textit{semijoin} (un
operatore particolare per i sistemi distribuiti). L'operatore di \textit{join}
infatti ``ingrandisce'' i dati ``fondendo'' tabelle, che magari sono frammentate
in più tabelle su vari nodi. L'uso di \textit{send} e \textit{receive} permette
la comunicazione dei dati tra i nodi, anche se questo rischia di diventare
troppo esoso in termini di prestazioni. Si hanno quindi degli \textbf{algoritmi
  di calcolo del costo adattivi} e si deve studiare la rete e i suoi
ritardi, che dipendono dalla \textit{topologia} della rete stessa e dal carico
applicativo. Si ha quindi una fase di \textbf{ottimizzazione a runtime}, dove si
riadatta il \textbf{query plan}. Per riadattarlo si fa in primis monitoring
sull'esecuzione della query, si procede adattando il modello di costo
(eventualmente con software automatici) e, eventualmente, riadattando la query
se si calcola uno scarto di costo troppo elevato. È il DBA che stabilisce delle
soglie temporali entro le quali ottenere una risposta. Per questo conta la
trasparenza, in quanto non è l'applicazione che deve interessarsi di questo
aspetto. Si introduce un nuovo \textit{layer} di complessità.\\
In alcuni casi è impossibile ad avere un DDBMS che si occupi di questo tipo di
ottimizzazioni.\\
\textbf{La distribuzione non è predicibile a priori}.
Vediamo un semplice esempio:
\begin{esempio}
   \label{esempio:costi}
  Si supponga di avere il seguente schema:
  \begin{itemize}
    \item Employee (eno, ename, title), di cardinalità 400
    \item AssiGN(eno, projectno, resp, dur), di cardinalità 1000 e dove
    \emph{resp} rappresentata il tipo di responsabilità
  \end{itemize}
  Si ha la seguente query: \textit{trovare i nomi dei dipendenti che sono anche
    manager di progetti:}
  \begin{minted}{sql}
    SELECT ename
    FROM Employee E JOIN AssiGN A on E.eno=A.eno
    WHERE resp=''manager''
  \end{minted}
  Che, in algebra relazionale già abbastanza ottimizzata ipotizzando che ci
  siano pochi manager, sarebbe:
  \[\pi_{ename}(EMP><_{eno}(\sigma_{resp=''manager''}(ASG)))\]
  Supponiamo di avere poi 5 nodi uguali, il quinto per il risultato e i primi 4
  frammentati orizzontalmente secondo questo schema di divisione per nodo:
  \begin{enumerate}
    \item $ASG1=\sigma_{eno}\leq 'E3'(ASG)$
    \item $ASG2=\sigma_{eno}> 'E3'(ASG)$
    \item $EMP1=\sigma_{eno}\leq 'E3'(EMP)$
    \item $EMP2=\sigma_{eno}> 'E3'(EMP)$
  \end{enumerate}
  Vediamo quindi una prima esecuzione:
  \begin{itemize}
    \item chiedo al nodo 1 i manager e sposto i risultati di\\
    $\sigma_{resp=''manager''}(ASG1)$ sul nodo 3 (dove sono 
    descritti in modo più completo) come $(ASG'1)$. Il risultato di
    $EMP1><_{eno}(ASG1)$, calcolato sul nodo 4, lo porto sul nodo 5 $EMP'1$ 
    \item chiedo al nodo 2 i manager e sposto i risultati di\\
    $\sigma_{resp=''manager''}(ASG'2)$ sul nodo 4 (dove sono descritti in modo
    più completo) come $(ASG'2)$. Il risultato di $EMP2><_{eno}(ASG'2)$,
    calcolato sul nodo 4, lo porto sul nodo 5 come $EMP'2$ 
    \item sul nodo 5 il risultato sarà $EMP'1\cup EMP'2$
  \end{itemize}
  Vediamo una seconda soluzione:
  \begin{itemize}
    \item contemporaneamente chiedo al nodo 1 e la nodo 3 di mandare al nodo 5
    tutti i manager. Sempre contemporaneamente a queste due operazioni chiedo al
    nodo 2 e al nodo 4 di mandare al nodo 5 tutte le informazioni. I tempi
    saranno basati sul più lento dei quattro nodi, che determinerà il tempo
    massimo dell'operazione (che sono circa calcolabili a priori tramite la
    tabella delle statistiche)
    \item nel nodo 5 calcolo il risultato:
    \[(EMP1\cup EMP2)><_{eno}\sigma_{resp=''manager''}(ASG1\cup ASG2)\]
  \end{itemize}
  I tempi di trasporto detteranno quale soluzione tra le due è la più
  performante ma, viste le cardinalità esigue di dati, probabilmente vince la
  seconda (dove si ha un solo spostamento globale). Questa seconda strategia
  costringe a pensare a particolari strutture di accesso secondarie dette
  \textbf{indici}, che permettono interrogazioni efficaci ma che \textbf{non
    possono essere ``portati''} in sistemi distribuiti. Quindi nel nodo 5 non ho
  gli \textbf{indici} e quindi devo fare l'intero \textbf{prodotto cartesiano}
  per il \textit{join} (che però in questo caso ha un tempo trascurabile,
  grazie alla bassa cardinalità dei dati, rispetto ai costi di trasferimento,
  generalmente non trascurabili rispetto ai costi delle operazioni interne ad un
  nodo).
\end{esempio}
Riprendendo l'esempio definiamo:
\begin{itemize}
  \item \textbf{costo di messaggio} come il costo fisso di spedizione o
  ricezione di un messaggio (detto \textit{setup})
  \item \textbf{costo di trasmissione} come il costo, fisso rispetto alla
  topologia, di trasmissione dati
  \item \textbf{costo di comunicazione} come la somma tra il costo di messaggio,
  moltiplicato per il numero di messaggi, più il costo di trasmissione,
  moltiplicato per il numero di \textit{bytes} trasmessi
  \item \textbf{costo totale} come la somma dei costi delle operazioni
  (\textit{I/O} e \textit{CPU}) più i costi di comunicazione
  (\textit{comunicazione})
  \item \textbf{response time} come la somma dei costi qualora si tenga conto
  del \textit{parallelismo delle trasmissioni}, quindi come la somma tra il
  costo di messaggio, moltiplicato per il numero di messaggi comunicati in modo
  sequenziale, più il costo di trasmissione, moltiplicato per il numero di
  \textit{bytes} trasmessi in modo sequenziale. In questo conto volendo posso
  usare dei \textbf{pesi} basati sulla cardinalità delle unità da trasferire e
  tenere conto del massimo tempo di risposta che si ottiene
\end{itemize}
Si ha quindi che:
\begin{itemize}
  \item nelle \textbf{grandi reti geografiche} i costi di\textit{ comunicazione}
  sono molto maggiori del costo di \textit{I/O}, circa di 10 volte 
  \item nelle \textbf{reti locali} i costi di \textit{comunicazione} e
  \textit{I/O} sono paragonabili, grazie alle reti \textit{gigabit} in locale
\end{itemize}
Tendenzialmente il costo di comunicazione è ancora il \textbf{fattore critico}
ma sempre meno.\\
Bisogna scegliere cosa \textbf{minimizzare}:
\begin{itemize}
  \item il \textit{response time}, aumentando il parallelismo che però può
  portare ad un aumento del \textit{costo totale}, con un maggior numero di
  trasmissione e un maggior processing locale. Nell'esempio \ref{esempio:costi}
  potrebbe sembrare la seconda soluzione, che effettivamente parallelizza di più
  ma non minimizza i costi di risposta 
  \item il \textit{costo totale}, senza tener conto del parallelismo utilizzando
  meglio le risorse e aumentando il \textit{throughput} ma peggiorando così il
  \textit{response time}. Nell'esempio \ref{esempio:costi} è la prima soluzione
\end{itemize}
\subsubsection{Join e Semijoin}
Il \textbf{join} presenta il problema di portare alla perdita
dell'\textbf{indice}. Bisogna quindi studiare come effettuare l'operazione tra
due tabelle su due nodi diversi. Una prima operazione è data dell'operazione di
\textit{semijoin}.
\begin{definizione}
  Definiamo, in algebra relazionale, l'operazione \textit{semijoin}, tra due
  tabelle $R$ e $S$, sull'attributo $A$, come:
  \[R\,\,\,semijoin_A\,\,\,S\equiv \pi_{R^*}(R\,\,\,join_A \,\,\,A)\]
  dove $R^*$ è l'insieme degli attributi di $R$.\\
  In altre parole scelgo esplicitamente di tenere solo gli attributi di $R$ dopo
  il \textit{semijoin}.\\
  Quindi con $R\,\,\,semijoin_A\,\,\,S$ ho la proiezione sugli attributi di $R$
  operazione di \textit{join} e quindi ho che il \textit{semijoin} non è
  \textbf{commutativo}.\\
  Dalla seconda tabella porto solo la serie di attributi che mi servono
  esplicitamente ($\pi_A(S)$) riducendo il carico di lavoro.\\
 \textbf{ Alla fine il nostro $R'$ con i risultati del \textit{semijoin} sarà
  trasportato nel nodo di $S$}
\end{definizione}
Prese due tabelle allocate su nodi differenti, il \textit{joi}n tra di esse può
quindi essere calcolato tramite operazioni di \textit{semijoin}, valgono infatti
le seguenti equivalenze (che portano a diverse strategie a seconda della stima
dei costi):
\begin{itemize}
  \item
  $R\,\,\,join_{\theta}\,\,\,S \iff (R\,\,\,semijoin_{\theta}\,\,\,S)
  \,\,\,join_\theta\,\,\,S$
  \item $R\,\,\,join_{\theta}\,\,\,S \iff
  R\,\,\,join_\theta\,\,\,(S\,\,\,semijoin_{\theta}\,\,\,R)$ 
  \item $R\,\,\,join_{\theta}\,\,\,S \iff (R\,\,\,semijoin_{\theta}\,\,\,S)
  \,\,\,join_\theta\,\,\,(A\,\,\,semijoin_{\theta}\,\,\,R)$
\end{itemize}
In tutti i casi si riduce lo spostamento dei dati.\\
L'uso del \textit{semijoin} è conveniente sse il costo del suo calcolo e del
trasferimento del risultato è inferiore al costo del trasferimento dell'intera
relazione e del costo dell'intero \textit{join} (e questo dipende dal numero di
attributi coinvolti).\\
\textit{Avere più di un \textit{join} complica la situazione, anche solo per la
  scelta dell'ordine in cui eseguirli.}
\subsubsection{Local optimization}
La \textit{local optimization} si occupa dell'ottimizzazione degli schemi
locali. Ogni nodo riceve una \textit{fragment query} e la ottimizza, con
tecniche analoghe ai sistemi centralizzati, in modo completamente
indipendente. Si hanno comunque operazioni di ottimizzazione locale a priori
sul fatto che il \textit{global query optimization} punti a ridurre i costi di
comunicazione (nel caso di un DDBMS in rete geografica) o ad aumentare il
parallelismo (in caso di DDBMS in rete locale).\\
In ogni caso nella progettazione di sistemi di gestione dati distribuiti bisogna
tener conto di:
\begin{itemize}
  \item tipologie di query distribuite
  \item stime o statistiche sullo storico query distribuite già eseguite (fatto
  periodicamente dal DDBMS)
  \item topologia della rete
  \item carico aspettato e workload previsto
\end{itemize}
\subsection{Accesso in scrittura e controllo di concorrenza}
In questo caso la situazione si complica. Un conto è avere delle \textbf{remote
  requests (read-only)}, che possono essere un numero arbitrario di query SQL in
sola lettura, un altro è avere delle \textbf{remote transactions (read-write)},
ovvero un numero arbitrario di operazioni SQL che prevedono anche
\textit{insert} e \textit{update}. Ragionando in un'ottica in cui si ha un
numero arbitrario di server si parla di \textbf{distribuited requests}, dove
ogni singola operazione SQL si può riferire, grazie ad un \textit{ottimizzatore
distribuito}, a qualunque insieme di server, e di \textbf{distribuited
transactions}, dove ogni operazione è diretta ad un unico server e dove le
transazioni possono modificare più di un db, tutto ciò grazie ad un
\textit{protocollo transazionale di coordinamento distribuito}, detto
\textbf{two-phase commit} (in questo caso si ha spesso a che fare con sistemi
\textit{eterogenei} e \textit{federati}). Deve valore la \textbf{proprietà di
  atomicità} di \textit{ACID}. Sempre riguardo \textit{ACID} si ha che la
\textbf{proprietà di consistenza} non dipende dalla distribuzione, in quanto le
proprietà sono indipendenti dall'allocazione, e si ha che la \textbf{proprietà
  di durabilità} viene garantita localmente. Vanno invece rivisti
architetturalmente la \textbf{proprietà di atomicità}, tramite componenti come
il \textit{reliability control} e il \textit{recovery manager} (in caso di
guasti), e la \textbf{proprietà di isolamento}, tramite il \textit{concurrency
  control} (senza il quale si può incorrere in \textit{update fantasma}, dove un
\textit{update} viene cancellato da uno seguente).\\ 
Rivedendo i \textbf{principi del controllo di concorrenza}.
\begin{definizione}
  Data una transazione $t_i$ si ha che essa viene scomposta in sotto-transazioni
  $t_{ij}$ a seconda del nodo $j$-simo su cui viene eseguita. A sua volta una
  transizione $t_{ij}$ viene nominata $r_{ij}$ per le operazioni di lettura e
  $w_{ij}$ per le operazioni di scrittura. L'uso di una risorsa $x$ viene
  indicata, per esempio, con $r_{ij}(x)$ o $w_{ij}(x)$.
\end{definizione}
Ogni sotto-transazione viene schedulata in modo indipendente di server di
ciascun nodo e quindi la \textbf{schedule globale} (dove \textit{schedules}
indica le sequenze delle transazioni da eseguire) dipende dalle
\textbf{schedules locali} di ogni nodo.\\
Purtroppo \textbf{la serializzabilità locale di ogni schedule non garantisce la
  sua serializzabilità globale}. Si viene a creare un \textbf{grafo globale dei
  conflitti} in quanto i conflitti non sono a livello locale ma a livello
globale (infatti si hanno risorse occupate tra i vari nodi, si arriva, in certi
casi, ad una \textbf{situazione di deadlock}). \\
Si ha quindi che lo \textit{schedule globale} è serializzabile sse \textbf{gli
  ordini di serializzazione sono gli stessi per tutti i nodi coinvolti} (nel
caso in cui il db non sia replicato).\\
Qualora si abbia un db replicato si aggiunge un altro problema qualora le
scritture riguardino due repliche diverse. In tal caso si può violare la
\textbf{mutua consistenza} (che dice che al termine della transazione tutte le
copie devono avere lo stesso valore) dei due db locali, anche con due schedule
localmente seriali. Si introduce quindi un \textbf{protocollo di controllo delle
  repliche}.
Il \textbf{protocollo di controllo delle repliche} viene chiamato \textbf{ROWA
  (\textit{Read Once Write All})}. In base a questo protocollo, dato un item
logico $X$ (con $x_1\ldots x_n$ items fisici), si ha che le transazioni vedono
solamente $X$ ed è il protocollo che si occupa di mappare \textit{read(X)} su
una copia qualunque e \textit{write(X)} su tutte le copie. Questo meccanismo
torna utile nell'uso standard delle repliche, permettendo al client di leggere
dal nodo più vicino ma imponendo, eventualmente, la scrittura su tutte le
copie e bloccando le operazioni fino a quando l'ultima scrittura non è
avvenuta. Si hanno purtroppo problemi di perdita di prestazioni a causa di
questa scrittura ``di massa''. Per lo stesso problema si hanno anche condizioni
di rilascio tramite \textit{protocolli asincroni}.
\subsection{2 phase locking}
Anche l'\textbf{algoritmo 2PL (\textit{2 Phase Locking})} viene esteso al caso
di schemi distribuiti. Si hanno due possibili strategie:
\begin{enumerate}
  \item \textbf{primary site}, \textit{centralized}, in quanto
  basata sui siti
  \item \textbf{primary copy}, in quanto basata sulle copie
\end{enumerate}
2PL prevede che prima di rilasciare un \textit{lock} debba averli richiesti
tutti, e nello \textit{stricted 2PL} solo dopo che sia anche stato effettuato il
\textit{commit}.\\
Nel caso di \textit{centralized 2PL} si ha un \textbf{lock manager (LM)} per
ogni nodo, è un'architettura ``master-slave''. Il ``master'' è appunto il
\textit{lock manager} che gestisce i \textit{lock} per l'intero db
distribuito. Gli ``slave'' sono invece i \textit{data processor}, che seguono
quanto fa il \textit{lock manager coordinatore} (che se non è disponibile per
problemi tecnici del nodo comporta seri problemi in quanto la scelta di un nuovo
\textit{lock manager} tra quelli di ogni nodo è parecchio complicata).\\
Si ha inoltre che il \textbf{transaction manager (TM)} del nodo in cui inizia la
transazione sarà ritenuto il \textit{TM coordinatore} dei transaction
manager. La transazione anche in questo caso sarà eseguita dai \textit{data
  processor} nei vari nodi. Il TM coordinatore formula all'LM coordinatore le
richieste di \textit{lock}, che vengono concesse tramite l'\textit{algoritmo
  2PL}. Una volta concesse il TM coordinatore le comunica ai vari \textit{data
  processor}, assegnando ad essi i vari lock e l'accesso ai dati. AL termine
delle operazioni i \textit{data processor} comunicheranno il termine al TM
coordinatore che a sua volta lo comunicherà all'LM coordinatore, che rilascerà i
lock. Si ha però un effetto ``collo di bottiglia'' sul nodo del LM che deve
gestire moltissime richieste e fino a che non risponde sistema va in
\textit{wait}. Una soluzione a questo problema è individuata nella tecnica della
\textbf{copia primaria}. Prima dell'assegnazione del \textit{lock}, viene
individuata per ogni risorsa una \textit{copia primaria}. Inoltre si ha che i
diversi nodi hanno diversi \textit{lock manager} attivi, ognuno che gestisce una
partizione dei lock complessivi, relativi alle risorse primarie residenti nel
nodo. Inoltre, per ogni risorsa nella transazione, il TM comunica le richieste
di lock al LM responsabile della copia primaria, che assegna i \textit{lock}. Si
evita quindi il ``collo di bottiglia'' ma è necessario determinare a priori il
LM per ogni risorsa. Inoltre si necessità di una \textbf{directory globale} dove
tutti i nodi ``vedono tutto''.
\subsection{Gestione dei deadlock}
Indipendentemente da quanto appena discusso si può creare un'\textbf{attesa
  circolare} tra transazioni di due o più nodi. Bisogna quindi applicare un
algoritmo distribuito. Per costruire l'algoritmo dobbiamo ragionare che siamo in
una ``rete tra pari'' \textit{Peer-to-Peer} (e non ``master-slave'') e quindi
bisogna definire un protocollo su cui costruire l'algoritmo \textit{asincrono e
  distribuito}. L'algoritmo potrebbe partire su uno qualsiasi dei nodi.\\
Si ipotizza innanzitutto che tutte le sotto-transazioni siano attivate in modo
sincrono, tramite \textit{Remote Procedure Call (RPC)} bloccante, ovvero una
transazione chiede di fare un'operazione su un certo nodo facendo una RPC ad un
altro nodo, mettendosi in attesa fino a che non finisce. Si possono generare due
tipi di attesa:
\begin{enumerate}
  \item \textbf{attesa da RPC}, una sotto-transazione su un nodo attende
  un'altra sotto-transazione, della stessa transazione, su un altro nodo
  \item \textbf{attesa da rilascio di risorsa}, una sotto-transazione su un nodo
  attende un'altra sotto-transazione, della stessa transazione, sullo stesso
  nodo a causa del rilascio di una risorsa (che normalmente è la tipica
  situazione che porta ad un deadlock in un sistema centralizzato)
\end{enumerate}
La composizione dei due tipi di attesa può generare un \textbf{deadlock
  globale}. \\
E’ possibile caratterizzare le condizioni di attesa su ciascun nodo tramite
condizioni di precedenza e serve quindi specificare qualche notazione, per
rappresentare il fatto che ogni nodo deve capire quali sono le transazioni sono
in attesa per una chiamata esterna o per l'accesso ad una risorsa interna:
\begin{itemize}
  \item $EXT_i$ per una chiamata all'esecuzione di una transazione sul nodo $i$
  \item $x < y$ per indicare che $x$ sta aspettando il rilascio di una risorsa
  da parte di $y$ (che può essere anche $EXT$)
  \item indichiamo quindi la \textbf{sequenza di attesa generale} al nodo $k$
  come: 
  \[EXT<T_{ik}<T_{jk}<EXT\]
\end{itemize}
\begin{esempio}
  Sul DBMS1 si ha:
  \[EXT2<T_{21}<T_{11}<EXT2\]
  e sul DBMS2:
  \[EXT1<T_{12}<T_{22}<EXT1\]
  ovvero sul nodo 2 c'è la transazione 1 che sta aspettando che finisca. La
  transazione 1 sul nodo 1 sta aspettando che la transazione 2 sul nodo 1
  finisca, che a sua volta sta aspettando che la transazione sul nodo 2
  finisca. Però sul DBMS2 scopriamo che la transazione 1 sul nodo 1 è in
  attesa della transazione 2 sul nodo 2 finisca. Quest'ultima sta aspettando
  che finisca la transazione 1 sul nodo 2 che a sua volta attende la
  transazione sul nodo 1. Si ha quindi un \textbf{deadlock distribuito},
  rappresentato nell'immagine \ref{esempio:1}.
  \begin{figure}
    \centering
    \psscalebox{1.0 1.0} % Change this value to rescale the drawing.
    {
      \begin{pspicture}(0,-3.50458)(9.6,3.50458)
        \definecolor{colour0}{rgb}{0.03529412,0.6392157,0.91764706}
        \definecolor{colour1}{rgb}{0.98039216,0.27450982,0.27450982}
        \psframe[linecolor=black, linewidth=0.002, shadow=true,
        shadowsize=0.10583334,shadowcolor=black,fillstyle=solid,
        fillcolor=colour0, dimen=outer](4.0,2.8954198)(0.0,-3.50458)
        \psframe[linecolor=black, linewidth=0.002, shadow=true,
        shadowsize=0.10583334,shadowcolor=black,fillstyle=solid,
        fillcolor=colour0, dimen=outer](9.6,2.8954198)(5.6,-3.50458)
        \psellipse[linecolor=black, linewidth=0.04,
        fillstyle=solid,fillcolor=colour1, dimen=outer](2.0,1.49542)(0.8,0.6)
        \psellipse[linecolor=black, linewidth=0.04,
        fillstyle=solid,fillcolor=colour1,
        dimen=outer](2.0,-1.3045801)(0.8,0.6)
        \psellipse[linecolor=black, linewidth=0.04, fillstyle=solid,
        fillcolor=colour1, dimen=outer](7.6,-1.3045801)(0.8,0.6)
        \psellipse[linecolor=black, linewidth=0.04, fillstyle=solid,
        fillcolor=colour1, dimen=outer](7.6,1.49542)(0.8,0.6)
        \rput[bl](1.2,3.29542){$DBMS1$}
        \rput[bl](6.8,3.29542){$DBMS2$}
        \rput[bl](1.8,1.2954199){$t_{11}$}
        \rput[bl](1.8,-1.50458){$t_{21}$}
        \rput[bl](7.4,1.2954199){$t_{12}$}
        \rput[bl](7.4,-1.50458){$t_{22}$}
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm 2.0,
        arrowlength=1.4,arrowinset=0.0]{->}(2.0,-0.70458007)(2.0,0.8954199)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm 2.0,
        arrowlength=1.4,arrowinset=0.0]{->}(2.8,1.6954199)(6.8,1.6954199)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm 2.0,
        arrowlength=1.4,arrowinset=0.0]{->}(7.6,0.8954199)(7.6,-0.70458007)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm 2.0,
        arrowlength=1.4,arrowinset=0.0]{->}(6.8,-1.50458)(2.8,-1.50458)
        \rput[bl](4.4,1.2954199){RPC}
        \rput[bl](4.4,-1.9045801){RPC}
        \rput[bl](2.4,0.09541992){lock}
        \rput[bl](8.0,0.09541992){lock}
      \end{pspicture}
    }
    \caption{Grafico dell'esempio di deadlock distribuito}
    \label{esempio:1}
  \end{figure}
\end{esempio}
Per risolvere il problema del \textbf{deadlock distribuito} ogni nodo, ad un
certo punto con un suo ordine temporale, prende la sua sequenza di attesa e la
aggiunge ad alle condizioni di attesa locale degli altri nodi legati da
$EXT$. Dopodiché analizza la situazione, rilevando potenziali \textbf{deadlock
  locali}, e comunica le sequenze di attesa alle altre istanze dell'algoritmo,
ovvero agli altri nodi. Qualora si abbia un \textit{deadlock locale} si crea un
grafo dedicato allo stesso dove sarà possibile notare un ciclo, che rappresenta
il deadlock. Ovviamente è possibile evitare che due nodi scoprano
lo stesso deadlock, rendendo così quindi più efficiente l'algoritmo che invia le
sequenze di attesa solo in alcuni modi:
\begin{enumerate}
  \item \textbf{in avanti}, verso il nodo dove è attiva la sotto-transizione
  attesa (nodo nel quale vede che non ci siano deadlock (???)). Nei sistemi
  \textit{Peer-to-Peer} questi sono meccanismi \textit{coreografati}, decisi a
  priori.\\
  \textit{Esempio alla slide 68 del quarto PDF della costruzione di un grafo
    delle transazioni con presenza di ciclo}
  \item solamente quando l'identificatore del secondo nodo attende il
  rilascio della risorsa identificatore del primo nodo
\end{enumerate}
\subsection{Recovery management}
Approfondiamo quindi come garantire la \textbf{proprietà di atomicità}.\\
Abbiamo visto come uno dei guasti possibili in un sistema distribuito sia quello
legato alla perdita di messaggi sulla rete, nonché al partizionamento delle
stessa (comportando magari l'isolamento dei nodi). Ricapitolando abbiamo diversi
tipi di guasti: 
\begin{itemize}
  \item \textbf{guasti nei nodi}, sia \textit{soft} che hard
  \item \textbf{perdita di messaggi}, che lascia l'esecuzione di un protocollo
  in uno stato di \textit{indecisione}, in quanto ogni messaggio del protocollo
  è seguito da un \textit{ack} e la perdita o del messaggio o dell'\textit{ack}
  stesso genera incertezza (non potendo decidere se il messaggio sia arrivato o
  meno)
  \item \textbf{partizionamento della rete}, dove una transazione distribuita
  può essere attiva contemporaneamente su più sotto-reti temporaneamente
  isolate. In questa situazione i singoli nodi non riescono a capire bene chi
  sia isolato e la cosa può portare i nodi a fare scelte contraddittorie
\end{itemize}
Si è quindi studiato il \textbf{protocollo two phase commit (\textit{2PC})} che
cerca di funzionare in presenza di guasti di rete. Questo tipo di protocollo
consente ad una transizione di giungere ad un eventuale \textit{commit} o
\textit{abort} su ciascuno dei nodi che partecipano alla transazione. In questo
protocollo la decisione di \textit{commit} o \textit{abort} tra due o più
\textbf{resource managers (RM)} (i server) viene certificata da un
\textbf{transaction manager (TM)} (il coordinatore). Lo scambio dei messaggi (e
il salvataggio di un log per ciascuno) tra TM e RMs è ciò su cui si basa il
protocollo 2PC. Si ha quindi sempre un'architettura ``master-slave'' (in modo
metaforico si può rappresentare come il prete che unisce in matrimonio i due
sposi). Si ha quindi il TM che interroga i RMs riguardo allo stato della loro
esecuzione.
\subsubsection{2PC in assenza di guasti}
Si hanno diverse fasi:
\begin{enumerate}
  \item durante la prima fase il TM interroga (con un \textit{prepare} o
  \textit{ready\_to\_commit}) tutti i nodi per capire come 
  ciascun nodo intenda terminare la transazione, autonomamente o
  irrevocabilmente \textit{commit} o \textit{abort} (magari per violazione della
  concorrenza locale o per violazione di qualche vincolo di consistenza
  etc$\ldots$). I nodi risponderanno quindi o con \textit{ready\_to\_commit} o
  con \textit{not\_ready\_to\_commit}
  \item nella seconda fase il TM prende la decisione globale. Si ha che se anche
  solo un nodo richiede un \textit{abort} allora si avrà \textit{abort} per
  tutti i nodi, altrimenti \textit{commit}, chiudendo la transazione. Il TM si
  occupa anche di comunicare ai RMs la decisione finale per poter procedere con
  le azioni locali 
\end{enumerate} 
Come abbiamo detto precedentemente si ha la raccolta di \textit{log} nei quali
compaiono due tipi di record:
\begin{enumerate}
  \item \textbf{record di transazione}, con le informazioni sulle operazioni
  effettuate
  \item 
\end{enumerate}
\end{document}
% LocalWords:  Machine Learning DBMS DataBase System hashmap db workload system
% LocalWords:  storage Administrator DBA GUI SPARC performanti primis query SQL
% LocalWords:  join compiler DLL DDL Language step parsing Catalog metadati sql
% LocalWords:  tree parser plan select sottotabella FROM Where Stafford mgrssn
% LocalWords:  Bdate Pnumber l'ottimizzatore where Statistics Branch Bound work
% LocalWords:  transaction begin commit rollabck OLTP OnLine Processing ACID PL
% LocalWords:  rollback UNDO recovery serializzabile conflict equivalence locks
% LocalWords:  two phase locking shared deadlock timestamps lock serializzabili
% LocalWords:  unlock nothing vendor cloud DDBMS l'ottimizzatore Peer to client
% LocalWords:  object oriented OO example json warehouse LAV Local As View ODBC
% LocalWords:  routing processing vendors middleware DTP Distributed devices TM
% LocalWords:  GRID warehouses everything SMP Oracle RAC systems performances
% LocalWords:  big sottotabelle soft fail chunk ricostruibilità l'updates local
% LocalWords:  l'updates mapping rewriting replication decomposition global dur
% LocalWords:  optimization localization send receive semijoin runtime layer LM
% LocalWords:  monitoring response setup bytes gigabit throughput AssiGN eno RM
% LocalWords:  ename resp sse l'updates LocalWords l'updates fragment dell read
% LocalWords:  requests only transactions write insert update distribuited All
% LocalWords:  ottimizzatore reliability control concurrency schedules ROWA RPC
% LocalWords:  serializzabilità items primary copy stricted centralized wait
% LocalWords:  Call external slide PDF ack abort resource managers log RMs not
% LocalWords:  prepare ready

\message{ !name(archid.tex) !offset(-1321) }
