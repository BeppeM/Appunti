\documentclass[a4paper,12pt, oneside]{book}

% \usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{engrec}
\usepackage{rotating}
\usepackage{verbatim}
\usepackage[safe,extra]{tipa}
%\usepackage{showkeys}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{fontspec}
\usepackage{enumerate}
\usepackage{braket}
\usepackage{marginnote}
\usepackage{pgfplots}
\usepackage{cancel}
\usepackage{polynom}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage[cache=false]{minted}
\usepackage{mathtools}
\usepackage[noend]{algpseudocode}

\usepackage{tikz}\usetikzlibrary{er}\tikzset{multi  attribute /.style={attribute
    ,double  distance =1.5pt}}\tikzset{derived  attribute /.style={attribute
    ,dashed}}\tikzset{total /.style={double  distance =1.5pt}}\tikzset{every
  entity /.style={draw=orange , fill=orange!20}}\tikzset{every  attribute
  /.style={draw=MediumPurple1, fill=MediumPurple1!20}}\tikzset{every
  relationship /.style={draw=Chartreuse2,
    fill=Chartreuse2!20}}\newcommand{\key}[1]{\underline{#1}}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{decorations.markings}
  \usetikzlibrary{arrows,shapes,backgrounds,petri}
\tikzset{
  place/.style={
        circle,
        thick,
        draw=black,
        minimum size=6mm,
    },
  transition/.style={
    rectangle,
    thick,
    fill=black,
    minimum width=8mm,
    inner ysep=2pt
  },
  transitionv/.style={
    rectangle,
    thick,
    fill=black,
    minimum height=8mm,
    inner xsep=2pt
    }
  } 
\usetikzlibrary{automata,positioning}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}
\fancyfoot[C]{\thepage}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{epsfig}
\usepackage{pst-grad} % For gradients
\usepackage{pst-plot} % For axes
\usepackage[space]{grffile} % For spaces in paths
\usepackage{etoolbox} % For spaces in paths
\makeatletter % For spaces in paths
\patchcmd\Gread@eps{\@inputcheck#1 }{\@inputcheck"#1"\relax}{}{}
\makeatother

\title{Architetture Dati}
\author{UniShare\\\\Davide Cozzi\\\href{https://t.me/dlcgold}{@dlcgold}}
\date{}

\pgfplotsset{compat=1.13}
\begin{document}
\maketitle

\definecolor{shadecolor}{gray}{0.80}
\setlist{leftmargin = 2cm}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}
\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}
\tableofcontents
\renewcommand{\chaptermark}[1]{%
  \markboth{\chaptername
    \ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}%
\chapter{Introduzione}
\textbf{Questi appunti sono presi a lezione. Per quanto sia stata fatta
  una revisione è altamente probabile (praticamente certo) che possano
  contenere errori, sia di stampa che di vero e proprio contenuto. Per
  eventuali proposte di correzione effettuare una pull request. Link: }
\url{https://github.com/dlcgold/Appunti}.\\
\chapter{Sistemi centralizzati}
\begin{definizione}
  Un \textbf{DBMS (\textit{DataBase Management System})} è un sistema, ovvero un
  software, in grado di gestire collezioni di dati che siano:
  \begin{itemize}
    \item \textit{grandi}, ovvero di dimensioni maggiori della memoria centrale
    dei sistemi di calcolo usati (se ho a che fare con una quantità di dati non
    così grande e con un uso personale posso affidarmi ad una \textit{hashmap}
    piuttosto che ad un db)
    \item \textit{persistenti}, ovvero con un periodo di vita indipendente dalle
    singole esecuzioni dei programmi che le utilizzano e per molto tempo 
    \item \textit{condivise}, ovvero usate da diversi applicativi e diversi
    utenti (fattore che porta anche allo studio del carico di lavoro,
    \textit{workload}). L'accesso può essere sia \textit{in scrittura} che
    \textit{in lettura} (ovviamente anche entrambi) a seconda del caso. SI
    pongono quindi problemi di concorrenza e sicurezza
    \item \textit{affidabili}, sia resistente dal punto di vista hardware (un
    guasto non deve farmi perdere i dati) che dal punto di vista della sicurezza
    informatica. Le transazioni devono essere quindi \textbf{atomiche} (o tutto
    o niente) e \textbf{definitive} (che non verranno più dimenticate). Il
    software può cambiare mentre i dati no
  \end{itemize}
\end{definizione}
A livello di architettura per un \textit{sistema centralizzati} si hanno:
\begin{itemize}
  \item uno o più \textit{storage} per memorizzare i dati, a loro volta su uno o
  più file del \textit{file system}
  \item il \textit{DBMS}, il componente software che funge da componente logico
  \item diverse applicazioni che elaborano i dati provenienti dal db
  (\textit{lettura}) ed eventualmente scrivono dati sullo stesso
  (\textit{scrittura})
  \item il \textbf{DBA (\textit{DataBase Administrator})} che tramite riga di
  comando o GUI si occupa di manutenzione, sicurezza, ottimizzazione etc$\ldots$
  del DBMS 
\end{itemize}
L'\textit{architettura dati} di un DBMS è definita dall'ente \textit{ANSI/SPARC}
e è a tre livelli:
\begin{enumerate}
  \item diversi \textbf{schemi esterni}, porzioni di db messi a disposizione per
  le varie applicazioni
  \item uno \textbf{schema logico (o concettuale)}, che fa riferimento al
  \textit{modello relazionale} dei dati ed è indipendente dalla tecnologia
  usata. Avendo un unico schema logico si ha un'unica semantica (perlomeno a
  livello astratto). Si ha unica base di dati, quindi un unico insieme di record
  interrogati e aggiornati da tutti gli utenti. Non si ha nessuna forma di
  eterogeneità concettuale 
  \item uno \textbf{schema fisico}, che fa riferimento alla tecnologia usata per
  implementare le tabelle per salvare i dati. Si ha un'unica rappresentazione
  fisica dei dati e quindi nessuna distribuzione e nessuna eterogeneità fisica
\end{enumerate}
\textit{Un unico schema fisico è collegato ad un unico schema logico.}\\
Inoltre si hanno:
\begin{itemize}
  \item un \textbf{unico linguaggio di interrogazione} e quindi un'unica
  modalità di accesso ai dati
  \item un unico sistema di gestione per accesso, aggiornamento e gestione per
  la transazioni e le interrogazioni
  \item un'unica modalità di ripristino in caso d'emergenza
  \item un unico amministratore dei dati
  \item \textbf{nessuna autonomia gestionale}
\end{itemize}
Per il discorso della persistenza dei dati si ha necessità di una memoria
secondaria dove il DBMS salva le strutture dati, studiando un modo efficiente di
trasferimento dei dati nel \textit{buffer} in memoria centrale. Il
\textit{buffer} è un'area di memoria (o meglio un componente software) nella
memoria centrale che cerca, tramite una logica di ``vicinanza'', di mettere i
dati della memoria secondaria in quella centrale. Si usa il \textbf{principio di
  località}.\\
A causa degli accessi condivisi al db si hanno problemi di \textbf{concorrenza},
avendo accesso multi-utente alla stessa dei dati condivisa, accesso che
necessità anche di meccanismi di \textbf{autorizzazione}. In merito alla
concorrenza si ha che le transazioni sono corrette se \textbf{seriali} (ordinate
temporalmente) ma questo non è sempre applicabile e quindi si deve stabilire un
\textit{controllo della concorrenza}.\\
Per accedere ai dati di un db si hanno le \textbf{query
  (\textit{interrogazioni})} che fanno parte del modello logico a cui si
interfaccia l'utente. Essendo i dati nelle memorie secondarie bisogna cercare un
modo di rendere gli accessi performanti, in primis tramite opportune strutture
fisiche in quanto e strutture logiche non sarebbero efficienti in memoria
secondaria. Bisogna fare in modo che gli accessi alla memoria secondaria siano
il più limitati possibili e quindi bisogna ottimizzare l'esecuzione delle query.
Ovviamente una scansione lineare delle tabelle sarebbe troppo dispendiosa con
tabelle grosse, ricordando che i file sono ad accesso sequenziale. Inoltre un
ipotetico \textit{join} tra tabelle renderebbe ancora più complesso l'accesso,
soprattutto se \textit{full-join}.\\
Per poter garantire tutto ciò che è stato detto l'architettura del DBMS deve
essere organizzata in termini di \textit{funzionalità cooperanti}:
\begin{itemize}
  \item un \textbf{query compiler} che prende una query in SQL e la traduce con
  un compilatore
  \item un \textbf{gestore di interrogazioni e aggiornamenti} che trasforma le
  query in SQL in algebra relazionale facendo operazioni di ottimizzazione
  \item un \textbf{gestore dei metodi di accesso} per permettere il passaggio
  tra file e tabelle passando dal \textbf{gestore del buffer} e il
  \textbf{gestore della memoria secondaria} dove i dati non sono in forma
  tabellare ma di file e pagine
  \item un \textbf{DDL compiler}, dove DDL sta per Data Description Language,
  che si occupa dei comandi del DBA
  \item un \textbf{gestore della concorrenza}, che garantisce il controllo della
  concorrenza
  \item un \textbf{gestore dell'affidabilità}, che garantisce che un dato non
  vada perso
  \item un \textbf{gestore delle transazioni}
\end{itemize}
Gli ultimi quattro entrano in uso specialmente in fase di scrittura.\\
\textbf{Tutto deve essere veloce!}\\
In un sistema distribuito la parte di query compiler, gestore delle
interrogazioni, gestore delle transazioni e gestore della concorrenza resta
invariato mentre il resto cambia drasticamente (in quanto i dati sono
distribuiti) dovendo gestire diversamente l'accesso ai dati e la sua
sicurezza. Bisogna gestire anche come i vari nodi devono interagire coi dati.
\section{Ottimizzazione delle query}
Ottimizzare le query è tutt'altro che banale.\\
Il primo step è il \textbf{parsing}, che stabilisce se la query è sensata dal
punto di vista sintattico e se i vari nomi di tabelle e attributi sono coerenti
con lo schema. Per questo ultimo aspetta ci si appoggia al \textbf{Data
  Catalog}, un particolare db che contiene informazioni sui vari database, in
primis sui vari nomi delle tabelle e per ciascuna sui nomi di ogni attributo. SI
ha quindi una soluzione per gestire i \textit{metadati}. Il parser effettua
un'analisi lessicale, per la sintattica e la semantica, usando il dizionario e
l a traduzione in algebra relazionale, producendo un \textbf{query tree}. Si
calcola anche un \textbf{query plan logico}, utilizzando regole sintattiche di
buon senso, per capire cosa fare prima (per esempio se fare prima una
\textit{select} o un \textit{join}) per ottenere il risultato corretto nel minor
tempo possibile (prima di fare una \textit{join} magari seleziono prima una
sottotabella con i dati potenzialmente utili, togliendo quelli sicuramente
inutili$\ldots$ magari quel \textit{join} può anche essere evitato). La query
viene quindi rappresentata come un albero dove e foglie corrispondono alle
strutture dati logiche, ovvero le tabelle. I nodi interni sono invece le varie
\textbf{operazioni algebriche (\textit{select, join, proiezione, prodotto
    cartesiano} e \textit{operazioni insiemistiche})}.
\newpage
\begin{esempio}
  Vediamo una query:
  \begin{minted}{sql}
    SELECT Pnumber, Dnum, Lname, Address, Bdate
    FROM Project P, Dept D, Emp E
    Where P.dnum=D.dnumber and E.ssn = D.mgrssn
    and P.location = 'Stafford'
  \end{minted}
  che produce:
  \begin{center}
    \psscalebox{1.0 1.0} % Change this value to rescale the drawing.
    {
      \begin{pspicture}(0,-2.36)(10.7,2.36)
        \rput[bl](4.0,2.1249022){$\pi$ Pnumber, Dnum, Lname, Address, Bdate}
        \rput[bl](5.6,0.9249023){join mgrssn=ssn}
        \rput[bl](2.0,0.124902345){join dnum=dnumber}
        \rput[bl](8.4,0.124902345){emp}
        \rput[bl](0.0,-1.0750977){$\sigma$ plocation='stafford'}
        \rput[bl](6.4,-1.0750977){dept}
        \rput[bl](1.6,-2.2750976){project}
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm
        2.0,arrowlength=1.4,arrowinset=0.0]{<-}(6.8,1.3249023)(6.8,2.1249022)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm
        2.0,arrowlength=1.4,arrowinset=0.0]{<-}(8.8,0.52490234)(8.4,0.9249023)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm
        2.0,arrowlength=1.4,arrowinset=0.0]{<-}(5.2,0.52490234)(6.0,0.9249023)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm 2.0,
        arrowlength=1.4,arrowinset=0.0]{<-}(3.6,-0.67509764)(3.6,0.124902345)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm 2.0,
        arrowlength=1.4,arrowinset=0.0]{<-}(6.4,-0.67509764)(4.8,0.124902345)
        \psline[linecolor=black, linewidth=0.04, arrowsize=0.05291667cm
        2.0,arrowlength=1.4,arrowinset=0.0]{<-}(2.4,-1.8750976)(2.4,-1.0750977)
      \end{pspicture}
    }
  \end{center}
  ma l'ottimizzatore va oltre (magari invertendo i \textit{where} etc$\ldots$)
  con un query plan più efficiente che permette di cambiare automaticamente le
  query in altre più efficienti.\\
\end{esempio}
Si ha un db chiamato \textbf{Statistics} che contiene statistiche sulla storia
delle query nonché altre informazioni sui dati. L'uso di tale db permette di
ottimizzare le query.\\
Solo dopo questo processo si ha la trasformazione delle tabelle logiche in
strutture fisiche e metodi di accesso alla memoria e la trasformazione delle
operazioni algebriche nelle loro implementazioni sulle strutture fisiche. Per la
trasformazione si usano proprietà algebriche e una stima dei costi delle
operazioni fondamentali per diversi metodi di accesso (in poche parole le regole
della ricerca operativa). L'ottimizzazione ha complessità \textbf{esponenziale}
e quindi si introducono approssimazioni basate su euristiche, usando
un'\textbf{alberatura di costi} usando la tecnica del \textbf{Branch\&Bound}.
\section{Transazioni}
Una \textbf{transazione} è l'insieme di istruzioni di accesso in lettura e
scrittura ai dati, istruzioni eventualmente inserite in un linguaggio di
programmazione. Una transazione gode di proprietà che garantiscono la corretta
esecuzione anche in ambito di concorrenza e sicurezza, tanto che sono
paradigmatiche del modello relazionale. Le transazioni iniziano con un
\textbf{begin-transaction} (a volte finiscono con \textit{end-transaction},
opzionale) e all'interno deve essere eseguito tra:
\begin{itemize}
  \item \textbf{commit work}, per terminare correttamente la lettura e/o
  scrittura 
  \item \textbf{rollback work}, per abortire la transazione
\end{itemize}
Un \textbf{sistema transazionale OLTP (\textit{OnLine Transaction Processing})}
è in grado di definire ed eseguire transazioni per conto di un certo numero di
applicazioni concorrenti anche alto. 
\begin{esempio}
  Vediamo un esempio di transazione (esempio di addebito su un conto corrente e
  accredito su un altro):
  \begin{minted}{sql}
    start transaction;
    update ContoCorrente
      set Saldo = Saldo + 10 where
      NumConto = 12202;
    update ContoCorrente
      set Saldo = Saldo – 10 where
      NumConto = 42177;
    commit work;
  \end{minted}
  oppure, con anche la verifica che ci siano ancora soldi dopo il prelievo (con
  eventuale aborto):
  \begin{minted}{sql}
    start transaction;
    update ContoCorrente
      set Saldo = Saldo + 10 where
      NumConto = 12202;
    update ContoCorrente
      set Saldo = Saldo – 10 where
      NumConto = 42177;
    select Saldo into A
      from ContoCorrente
      where NumConto = 42177;
    if (A >= 0) then commit work
    else rollback work;
  \end{minted}
  Il controllo può essere fatto a posteriori grazie al rollback che permette di
  ``dimenticare'' tutte le operazioni precedenti
\end{esempio}
Le istruzioni commit work e rollback work possono comparire più volte
all'interno del programma ma esattamente una delle due deve essere eseguita. Si
ha un \textbf{approccio binario}.\\
Bisogna approfondire quindi le \textbf{unità di elaborazione} che hanno le
proprietà cosiddette \textit{ACID}:
\begin{itemize}
  \item Atomicità, ovvero una transazione è un'unità atomica di
  elaborazione. Non si può lasciare il db in uno ``stato 
  intermedio''. Un problema prima del commit cancella tutto le operazioni svolte
  (\textit{UNDO}) e un problema dopo il commit non deve avere conseguenze, se
  necessario vanno ripetute le operazioni (\textit{REDO}) 
  \item Consistenza, ovvero la transazione rispetta i vincoli di integrità (se
  lo stato iniziale è corretto lo è anche quello finale). Quindi se ci sono
  violazioni non devono restare alla fine (nel caso \textit{rollback})
  \item Isolamento, ovvero la transazione non risente delle altre transazioni
  concorrenti. Una transazione non espone i suoi stati intermedi evitando
  l'\textit{effetto domino} (si evita che il rollback di una transazione vada in
  cascata con le altre). L'esecuzione concorrente di una collezione di
  transazioni deve produrre un risultato che si potrebbe ottenere con una
  esecuzione sequenziale
  \item Durata (ovvero persistenza), ovvero gli effetti di una transazione
  andata in commit non vanno persi anche in presenza di guasti (a tal fine si
  sfrutta il \textbf{recovery manager}, che garantisce l'affidabilità, del DBMS)
\end{itemize}
\section{Gestore della concorrenza}
Il \textbf{gestore della concorrenza} permette di eseguire in parallelo più
operazioni.\\
Definiamo \textbf{schedule} come una sequenza di esecuzione di un insieme di
transazioni. Uno schedule è \textbf{seriale} se se una transazione  termina
prima che la successiva iniziale, altrimenti è \textbf{non seriale}. Qualora non
sia seriale si potrebbero avere problemi.\\
Si sfrutta quindi la \textbf{proprietà di isolamento} facendo in modo che ogni
transazione esegua come se non ci fosse concorrenza: \textit{un insieme di
  transazioni eseguite concorrentemente produce lo stesso risultato che
  produrrebbe una (qualsiasi) delle possibili esecuzioni sequenziali delle stesse
  transazioni allora si ha la proprietà di isolamento}.\\
Si ha quindi che uno schedule è serializzabile se l'esito della sua esecuzione è
lo stesso che si avrebbe con una qualsiasi sequenza seriale delle transazioni
contenute.\\
Si hanno quindi diversi algoritmi per il controllo della concorrenza secondo
varie tipologie:
\begin{itemize}
  \item controllo basato su \textit{conflict equivalence}
  \item controllo di concorrenza basato su \textit{locks} \textit{(protocollo
    2PL o two phase locking, shared locks e gestione dei deadlock}). Il
  protocollo 2PL è usato nei DBMS dove per costruzione si hanno schedule
  serializzabili usando i lock per  bloccare l'accesso alla risorse da parte di
  una transazione fino a che una risorsa non sia rilasciata. Si hanno quindi i
  concetti di \textit{lock} e \textit{unlock} che garantiscono l'uso esclusivo
  di una risorsa e l'autorizzazione esclusiva dell'uso di una risorsa viene dato
  dal gestore delle transazioni. Si hanno delle \textbf{tabelle di lock}. Si ha
  che, in ogni transazione, tutte le richieste di \textit{lock} precedono tutti
  gli \textit{unlock} (che comunque devono essere fatti dopo l'operazione di
  \textit{commit}) 
  \item controllo di concorrenza basato su \textit{timestamps}
\end{itemize}
\chapter{Sistemi distribuiti relazionali}
Abbiamo visto nei sistemi centralizzati come ci fosse una sola base dati. In un
sistema distribuito abbiamo diversi \textbf{basi dati locali}, diverse
applicazioni su ogni nodo di elaborazione (dove ogni nodo condivide varie
informazioni) con gli utenti che accedono alle varie applicazioni. Questo tipo
di architettura prende il nome di \textbf{architettura shared nothing}, in
quanto i DBMS di ogni singola macchina sono autonome (anche di vendor diversi)
ma che lavorano insieme.\\
Un sistema distribuito permette non solo di avere dati ``distribuiti'' tra vari
nodi ma anche di ``duplicarne'' alcuni per diversi scopi, coi nodi collegati in
rete (addirittura si hanno soluzioni interamente distribuite nel cloud).\\
Confrontando un db distribuito con un multi-database (ovvero vari database
completi da ``unificare'') notiamo come entrambi
abbiano un'alta distribuzione, il primo una bassa eterogeneità (a differenza del
secondo, dove nei vari db potrei avere forte differenza di tipologia dei dati
contenuti). Si ha anche bassa autonomia nel caso si db distribuiti a differenza
del multi-database (dove ogni db è singolarmente autonomo).\\
Bisogna capire cosa distribuire. Si hanno diverse condizioni (che possono essere
presenti simultaneamente):
\begin{itemize}
  \item le applicazioni, fra loro cooperanti, risiedono su più nodi elaborativi
  \textbf{(elaborazione distribuita})
  \item l'archivio informativo è distribuito su più nodi (\textbf{base di dati
  distribuita}) 
\end{itemize}
La distribuzione si dice essere \textbf{ortogonale e trasparente} agli altri.\\
Capire cosa distribuire è una parte consistente dello studio di come costruire
un'architettura distribuita (magari frutto di situazioni particolari come la
``fusione'' di due sistemi a causa di un'acquisizione aziendale etc$\ldots$ dove
diverse logiche applicative e diverse strutture dati possono creare situazioni
molto pericolose).\\
Possiamo classificare i db distribuiti. Si ha innanzitutto che un \textbf{DBMS
Distribuito Eterogeneo Autonomo} è in generale una federazione di DBMS che
collaborano nel fornire servizi di accesso ai dati con livelli di
\textit{trasparenza} definiti (infatti le diversità tra db nei nodi vengono
``nascosti'' a vari \textit{livelli di trasparenza} per distribuzione,
eterogeneità e autonomia). Come abbiamo visto esiste l'esigenza di integrare a
posteriori vari db preesistenti (anche a causa di integrazione di nuovi
applicativi o nuove cooperazioni di processi) e questa situazione è spinta
dallo sviluppo della rete.\\
Possiamo quindi dividere i livello di federazione su tre categorie tra loro
ortogonali (ovvero indipendenti):
\begin{itemize}
  \item autonomia
  \item distribuzione
  \item eterogeneità
\end{itemize}
\subsubsection{Autonomia}
L'\textbf{autonomia} fa riferimento al grado di indipendenza tra i nodi e si
hanno diverse forme:
\begin{itemize}
  \item \textbf{autonomia di progetto}, il livello ``massimo'' dove ogni nodo ha
  un proprio modello dei dati e di gestione delle transazioni
  \item \textbf{autonomia di condivisione}, dove ogni nodo sceglie la porzione
  di dati da condividere ma condividendo con gli altri nodi lo schema comune
  \item \textbf{autonomia di esecuzione}, dove ogni nodo sceglie in che modo
  eseguire le transazioni
\end{itemize}
Si hanno quindi:
\begin{itemize}
  \item \textbf{DBMS Strettamente integrati} con nessuna autonomia, con dati
  logicamente centralizzati, un unico data manager per le transazioni
  applicative e vari data manager locali che non operano in modo autonomo ma
  eseguono le direttive centrali
  \item \textbf{DBMS semi-autonomi}, dove ogni data manager è autonomo ma
  partecipa a transazioni globali, dove una parte dei dati è condivisa e dove
  sono richieste modifiche architetturali  per poter fare parte della
  federazione
  \item \textbf{DBMS Peer to Peer} completamente autonomi, dove ogni DBMS lavora
  in completa autonomia ed è inconsapevole dell'esistenza degli altri  
\end{itemize}
\subsubsection{Distribuzione}
Per la\textbf{ distribuzione} dei dati si hanno 3 livelli classici:
\begin{itemize}
  \item \textbf{distribuzione client/server}, in cui la gestione dei dati è
  concentrata nei server, mentre i client forniscono l'ambiente applicativo e la
  presentazione
  \item \textbf{distribuzione Peer to Peer}, in cui non c'è distinzione tra
  client e server, e tutti i nodi del sistema hanno identiche funzionalità DBMS
  \item \textbf{nessuna distribuzione}
\end{itemize}
Le prime due possono anche non essere distinte.
\subsubsection{Eterogeneità}
L'\textbf{eterogeneità} può invece riguardare vari aspetti:
\begin{itemize}
  \item \textbf{modello dei dati} (relazionale, XML, object oriented (OO), json)
  \item \textbf{linguaggio di query} (diversi dialetti SQL, query by example,
  linguaggi di interrogazione OO o XML)
  \item \textbf{gestione delle transazione} (protocolli diversi per il gestore
  della concorrenza o per il recovery)
  \item \textbf{schema concettuale e logico} (concetti rappresentati in uno
  schema come attributo e in altri come entità)
\end{itemize}
Quindi si hanno vari tipi di DBMS:
\begin{itemize}
  \item \textbf{DBMS distribuito omogeneo (DDBMS)} quando si ha alta
  distribuzione ma non si hanno autonomia ed eterogeneità (gestiti solitamente
  dallo stesso vendor)
  \item \textbf{DBMS eterogeneo logicamente integrato (data warehouse)} quando
  si ha alta eterogeneità ma non si hanno distribuzione e autonomia
  \item \textbf{DBMS distribuiti eterogenei} quando si ha alta eterogeneità e
  distribuzione ma non autonomia 
  \item \textbf{DBMS federati distribuiti} quando si ha alta
  distribuzione, semi autonomia e non eterogeneità
  \item \textbf{DBMS distribuiti federati eterogenei} quando si ha alta
  distribuzione ed eterogeneità e semi autonomia
  \item \textbf{multi db MS}, totalmente autonomi ed eventualmente omogenei o
  eterogenei 
\end{itemize}
\textit{Si hanno molti altri sistemi in base alle 3 categorie}.\\
\section{DDBMS}
Parliamo di \textbf{DBMS distribuito omogeneo (\textit{DDBMS})}.\\
Studiamo uno schema in cui si passa da un sistema centralizzato ad un sistema
distribuito.\\
Si hanno due architetture di riferimento:
\begin{itemize}
  \item l'\textbf{architettura dati}
  \item l'\textbf{architettura funzionale}, ovvero l'insieme di tecnologie a
  supporto dell'architettura dati
\end{itemize}
Non avendo eterogeneità mantengo lo stesso schema di un DBMS centralizzato ma
distribuisco dati bisogna prendere lo schema centralizzato e aggiungere
componenti tra lo schema logico e lo schema fisico. Infatti non si avrà più un
solo schema logico e un unisco schema fisico ma tanti schemi logici e fisici
locali (ad ogni logico corrisponde un fisico). I vari schemi logici inoltre si
interfacciano con uno \textbf{schema logico globale}, i vari schemi logici
locali non sono quindi altro che delle \textit{viste} dello schema logico
globale. Questa organizzazione tra schemi logici locali e schema logico globale
è la cosiddetta \textbf{organizzazione LAV (\textit{Local As View})}. In ogni
caso il progettista interroga lo schema logico globale e saranno varie
tecnologie ad interrogare gli schemi logici locali (si fa una sorta di routing
delle query).\\
Per ciascuna funzione (come query processing, transaction manager etc$\ldots$)
si possono avere vari tipi di gestione:
\begin{itemize}
  \item centralizzata/gerarchica o distribuita
  \item con assegnazione statica o dinamica dei ruoli
\end{itemize}
\textit{Lo schema globale viene progettato prima degli schemi locali.}\\
Ovviamente cambia il \textbf{processo di progettazione} nel caso dei
DDBMS. Normalmente si ha un approccio \textit{top-down} per la progettazione,
con:
\begin{enumerate}
  \item analisi dei requisiti
  \item progettazione concettuale
  \item progettazione logica
  \item progettazione fisica
\end{enumerate}
ma questo tipo di progettazione va cambiato e quindi si introduce una nuova
fase e si cambiano le ultime due:
\begin{enumerate}
  \item analisi dei requisiti
  \item progettazione concettuale
  \item \textbf{progettazione della distribuzione}, per capire dove mettere i
  dati
  \item progettazione logica \textbf{locale}, che traduce dallo schema
  concettuale globale allo schema logico locale solo alcuni concetti
  \item progettazione fisica \textbf{locale}
\end{enumerate}
Si introduce il concetto di \textbf{portabilità}, ovvero la capacità di
eseguire le stesse applicazioni DB su ambienti runtime diversi (anche con SQL
diversi e differenti dallo standard). La portabilità è a \textit{compile-time}\\
Si ha anche il concetto di \textbf{interoperabilità} (tra vendors diversi),
ovvero la capacità di eseguire applicazioni che coinvolgono contemporaneamente
sistemi diversi ed eterogenei (con zero autonomia). A tal fine sono stati
introdotti dei \textit{middleware}, tra cui \textbf{ODBC} che si occupa
dell'accesso a dati di diversi vendor. ODBC, a livello architetturale, si pone
sopra il DBMS e da un'immagine indipendente da ciò che c'è sotto (funziona come
una sorta di \textit{driver}), trasformando tutto in una sorta di SQL
standard. Si hanno anche dei protocolli, come \textbf{X-Open Distributed
  Transaction Processing (\textit{DTP})}, che consentono di eseguire delle
transazioni secondo una logica diversa. Questo protocollo stabilisce una serie
di API che vengono implementate da ogni singolo DBMS per offrire una
connettività standard (approccio molto usato per transazioni con vendor
diversi). Il protocollo funziona sia se si ha che fare con omogeneità che con
eterogeneità. \\
Si hanno altri approcci:
\begin{itemize}
  \item \textbf{basi dati parallele}, con incremento delle prestazione mediante
  parallelismo sia di storage devices che di processore (scalabilità
  orizzontale). Un esempio sono le \textbf{basi dati GRID}
  \item \textbf{basi dati replicate} dove si ha la
  replicazione della stessa informazione su diversi server per motivi di
  performance. Importanti per i temi della consistenza e della sicurezza
  \item \textbf{Data warehouses}, ovvero DBMS centralizzati, risultato
  dell'integrazione di fonti eterogenee, dedicati nel dettaglio alla gestione di
  dati per il supporto alle decisioni. Prevede la \textit{cristallizzazione} dei
  dati, acquisiti da varie sorgenti, creando un nuovo schema con la
  memorizzazione dei dati in formato nuovo (solitamente relazionale). Non usa un
  approccio LAV 
\end{itemize}
\subsection{Caratteristiche dei DDBMS}
Si hanno vari tipi di architetture DDBMS:
\begin{itemize}
  \item \textbf{shared-everything}, ad esempio \textit{SMP server}, dove il db
  management system e il disco sono in un unico nodo
  \item \textbf{shared-disk}, ad esempio \textit{Oracle RAC}, dove diversi db
  management systems 
  agiscono su una stessa \textbf{SAN (\textit{Storage Area Network})}, ovvero
  un'architettura dati di puro storage (con tanti dischi in raid). I vari db
  accedono ai dati secondo una certa regolazione. Viene distribuito il carico
  sui db ma si hanno problemi di concorrenza e hanno grandi problemi di
  scalabilità e costo economico
  \item \textbf{shared-nothing}, sempre più usati, dove ogni db management
  system ha il suo disco. È molto scalabile e, a patto di gestire la
  complessità, posso aggiungere nodi in modo illimitato (\textbf{scalabilità
    orizzontale}). Si presta molto all'ambiente cloud. Sono \textit{architetture
  federate}.
\end{itemize}
Vediamo quindi le proprietà generali di un DDBMS (facendo esplicito riferimento
alle architetture \textit{shared-nothing} per la loro scalabilità):
\begin{itemize}
  \item \textbf{località}, secondo il \textit{principio di località}, che
  garantisce un aumento di performances (nonché di sicurezza) tenendo i dati si
  trovano ``vicino'' 
  alle applicazioni che li utilizzano più frequentemente 
  \item \textbf{modularità}, permettendo di scalare orizzontalmente e
  permettendo modifiche a dati ed applicazioni a basso costo
  \item \textbf{resistenza ai guasti}
  \item \textbf{prestazioni ed efficienza}
\end{itemize}
Concentrandoci sulla \textbf{località} si ha che la partizione dei dati
corrisponde spesso ad una partizione naturale delle applicazioni e degli utenti.
I dati risiedono più vicino a dove vengono più usati ma possono comunque essere
raggiunti anche da lontano (\textit{globalmente}). Si cerca inoltre sempre di
più di spostare i dati verso le applicazioni (paradigma ribaltato nel caso di
\textit{big data}).\\
In merito alla \textbf{modularità} si nota come la distribuzione dinamica dei
dati si adatta meglio alle esigenze delle applicazioni (magari spostando solo
sottotabelle verso alcuni nodi etc$\ldots$, sia in modo trasparente rispetto
all'utente che altrimenti).\\
Parlando di \textbf{resistenza ai guasti} si ha una maggior fragilità a causa
delle unità che aumentano di numero ma si ha \textbf{ridondanza} e quindi
maggiore resistenza ai guasti di dati e applicazioni ridondate (\textit{fail
  soft}).\\
Discorso più interessante è da farsi sulle \textbf{prestazioni}. Ogni nodo in un
sistema shared-nothing gestisce db di dimensioni ridotte. Inoltre ogni nodo può
essere ottimizzato ad hoc ed è più semplice gestire e ottimizzare applicazioni
locali. Si ha inoltre distribuzione del carico totale e parallelismo  tra
transazioni locali che fanno parte di una stessa transazione distribuita (anche
se questo aspetta obbliga soluzioni di coordinamento e appesantisce il carico
sulla rete, che rischia di diventare un ``collo di bottiglia'').\\
I DDBMS hanno ovviamente \textbf{funzionalità} specifiche.\\
Ogni server ha buona capacità di gestire transazioni indipendentemente, anche se
le interazione distribuita tra server rappresentata un carico supplementare. Per
le interrogazioni si ha che le query arrivano dalle applicazioni e i risultati
dai server mentre per le transazioni le richieste transazionali arrivano dalle
applicazioni ma sono richiesti \textbf{dati di controllo} per il
coordinamento.\\’
La gestione della rete deve essere ottimizzata e serve uno studio sulla
distribuzione locale dei dati.\\
Ricapitolando si hanno le seguenti funzionalità specifiche:
\begin{itemize}
  \item \textbf{trasmissione} di query, transizioni, frammenti di db e dati di
  controllo tra i nodi
  \item \textbf{frammentazione, replicazione e trasparenza} (secondo vari
  livelli), fattori legati alla natura distribuita dei dati
  \item un \textbf{query processor} e un \textbf{query plan} per la previsione
  di una strategia globale accanto a strategie per le query locali. Si gestisce
  il passaggio tra schema logico globale e quelli locali. Chi esegue
  la query lo fa senza pensare alla frammentazione dei dati
  \item \textbf{controllo di concorrenza} tramite algoritmi distribuiti,
  fondamentale per gli accessi \textit{in scrittura}
  \item \textbf{strategie di recovery} e \textbf{gestione dei guasti}, sia in
  merito alla rete che all'hardware stesso
\end{itemize}
\subsection{Frammentazione e replicazione}
Si definisce \textbf{frammentazione} come la possibilità di allocare porzioni
(\textit{chunk}) diverse del db su nodi diversi.\\
Si definisce \textbf{replicazione} come la possibilità di allocare stesse
porzioni del db su nodi diversi.\\
Si definisce \textbf{trasparenza} come la possibilità per l'applicazione di
accedere ai dati senza sapere dove sono allocati (serve qualcosa che instradi le
query).
\subsubsection{frammentazione}
Esistono due tipi di frammentazione:
\begin{enumerate}
  \item \textbf{frammentazione orizzontale}, che prevede di prendere una tabella
  e frammentare in base alle righe (le prime $n$ da una parte, le seconde $m$
  dall'altra etc$\ldots$). Si mantiene quindi inalterato lo schema in quanto
  ottengo solamente delle tabelle più piccole in quanto pezzi. Per spezzare uso
  una \textit{select} (per la \textbf{selezione}) che selezioni ogni volta un
  certo ``blocco'' di tabella 
  \item \textbf{frammentazione verticale}, che consente di ridurre la
  dimensionalità della tabelle spezzandola in base alle colonne. In ogni nuova
  tabella però la prima colonna deve essere uguale alla prima della tabella
  originale (ovvero dove si ha la chiave primaria), questo per garantire che si
  possa ricomporre la tabella (e lo schema) originale (con operazioni di
  \textit{join}, o meglio un \textit{natural join}) e garantire la
  trasparenza. Anche in questo caso uso 
  una \textit{select} (per la \textbf{proiezione}) che selezioni ogni volta un
  certo numero di colonne da mettere nella nuova tabella
\end{enumerate}
Bisogna quindi garantire:
\begin{itemize}
  \item \textbf{completezza}, ovvero ogni record della relazione $R$ di partenza
  deve poter essere ritrovato in almeno uno dei frammenti
  \item \textbf{ricostruibilità}, ovvero la relazione $R$ di partenza deve poter
  essere ricostruita senza perdita di informazione a partire dai frammenti
  \item \textbf{disgiunzione}, ovvero ogni record della relazione $R$ deve
  essere rappresentato in uno solo dei frammenti
  \item \textbf{replicazione}, l'opposto della disgiunzione
\end{itemize}
Quindi possiamo definire meglio le proprietà dei due tipi di frammentazione per
la relazione $R$, frammentata in diversi $R_i$:
\begin{enumerate}
  \item \textbf{orizzontale}:
  \begin{itemize}
    \item $schema(R_i)=schema(R),\,\forall i$
    \item ogni $R_i$ contiene un sottoinsieme dei record di $R$
    \item è definita da una proiezione su una condizione $ci$: $\sigma_{ci}(R)$
    \item garantisce la completezza, infatti $R_1\cup R_2\cup\ldots R_n=R$
    \item l'unione garantisce la ricostruibilità
  \end{itemize}
  \item \textbf{verticale}:
  \begin{itemize}
    \item $schema(R)=L=(A_1,\ldots,A_m)$ e $schema(R_i) = L_i =
    (A_{i1},\ldots,A_{ik})$ 
    \item garantisce la completezza, infatti $L_1\cup L_2\cup\ldots L_n=L$, dove
    i vari $L_i$ sono i frammenti verticali ed $L$ è la tabella originale
    \item si garantisce la ricostruibilità in quanto $L_i\cap L_j \supseteq
    chiave\,\,\,primaria(R),\,\forall i\neq j$ (ovvero ogni frammento deve
    contenere la chiave primaria)
  \end{itemize}
\end{enumerate}
\subsubsection{Replicazione}
Approfondiamo ora la \textbf{replicazione}. Si hanno diversi aspetti positivi
per l'accesso \textit{in lettura},
come il miglioramento delle prestazioni in quanto consente la coesistenza di
applicazioni con requisiti operazionali diversi sugli stessi dati e aumenta la
\textit{località dei dati} usati da ogni applicazioni. Nel momento in cui si ha
l'accesso \textit{in scrittura} si hanno però diversi aspetti negativi. Si hanno
diverse complicazioni architetturali, tra cui la gestione della transazioni e
l'updates di copie multiple, che devono essere tutte aggiornate. Inoltre bisogna
studiare dal punto di vista progettuale cosa replicare, quanto replicare (ovvero
capire quante copie mantenere), dove allocare le copie e le politiche per
gestirle.\\
In merito all'allocazione studiamo anche gli \textbf{schemi di
  allocazione}. Ogni frammento può essere allocato su un nodo diverso. Lo schema
globale quindi è solo \textit{virtuale} (in quanto non materializzato in un
solo nodo) e lo \textbf{schema di allocazione} definisce il \textit{mapping} tra
un frammento e un nodo. Si ha quindi una tabella, un \textbf{catalogo}, che ci
da informazioni sul partizionamento, associando ogni frammento al nodo in cui è
allocato.
\subsubsection{Trasparenza}
Con la \textbf{trasparenza} si ha la separazione della semantica di alto livello
dalle modalità di frammentazione e allocazione. Si separa quindi la
\textit{logica applicativa} dalla \textit{logica dei dati} ma per farlo serve
uno strato software che gestisca la traduzione dallo schema unico ai
sottoschemi, comportando un aumento di complessità del sistema e una perdita di
prestazioni (problemi che si riducono con un \textit{mapping} integrato del
DDBMS).\\
Le applicazioni (transazioni, interrogazioni) non devono essere modificate a
seguito di cambiamenti nella definizione e organizzazione dei dati e si hanno
due tipi di trasparenza, che si applicano agli schemi ANSI-SPARC nel modello
distribuito (schema logico globale e schemi logici/fisici locali):
\begin{enumerate}
  \item \textbf{trasparenza logica (o indipendenza logica)}, ovvero in
  dipendenza dell'applicazione da modifiche dello schema logico. Un'applicazione
  che usa un frammento non viene modificata se vengono modificati altri
  frammenti
  \item \textbf{trasparenza fisica (o indipendenza fisica)}, ovvero in
  dipendenza dell'applicazione da modifiche dello schema fisico
\end{enumerate}
Frammentazione e allocazione sono tra lo schema logico globale e ogni schema
logico locale. \\
Si hanno quindi tre livelli di trasparenza:
\begin{itemize}
  \item \textbf{trasparenza di frammentazione}, che permette di ignorare
  l'esistenza dei frammenti ed è lo scenario migliore per la programmazione
  applicativa con un'applicazione scritta in SQL standard. Il sistema si occupa
  di convertire query globali in locali e relazioni in sotto-relazioni. La
  scomposizione delle query per ogni sotto-relazione è detta \textbf{query
    rewriting} 
  \item \textbf{trasparenza di replicazione/allocazione}, dove l'applicazione è
  consapevole dei frammenti ma non dei nodi in cui si trovano. In questo caso la
  query è già spezzata in quanto si sa di avere a che fare con un sistema
  frammentato
  \item \textbf{trasparenza di linguaggio}, dove l'applicazione specifica sia
  i frammenti che i nodi, nodi che possono offrire interfacce che non sono SQL
  standard. Tuttavia l'applicazione sarà scritta in SQL standard a prescindere
  dai linguaggi locali dei nodi. Le query vengono quindi tradotte
  ottimizzatone di query. \textit{Questo è il livello di trasparenza più
    basso}
\end{itemize}
\section{Query distribuite}
Analizzeremo prevalentemente DDBMS distribuiti \textit{shared-nothing} e, in
seguito, \textit{architetture di replica} (con un \textit{replication server}
atto a gestire al replica).\\
Le query sono ovviamente le operazioni più importanti. Possono essere di sola
\textit{lettura} (tramite operazioni come la \textit{select}) o anche di
\textit{scrittura}. Le due tipologie di operazioni vengono gestite in modo
molto differente (la lettura sincrona non è un problema, se non hardware
risolvibile con una distribuzione del carico, a differenza della scrittura
sincrona). Le operazioni devono essere eseguite \textbf{velocemente}.
\subsection{Query in lettura}
Esistono, in un sistema relazionale, una serie di attività che convertono la
query in SQL in algebra relazionale e solo dopo si ha la distribuzione. 
L'utente, ignaro dello schema distribuito, interroga lo schema
logico globale e il DDBMS decompone la query secondo una localizzazione
specifica in base ai singoli frammenti (ovvero deve distribuire la query in modo
sensato). Si ha anche un'ottimizzazione globale della query prima della
distribuzione in modo che anche la distribuzione stessa sia ottimizzabile
correttamente, infatti il gestore delle interrogazioni manda ai singoli nodi i
giusti frammenti di query che verranno ottimizzati localmente. Ho quindi nel
complesso 4 fasi che compongono il \textbf{query processor}:
\begin{enumerate}
  \item \textbf{query decomposition}
  \item \textbf{data localization}
  \item \textbf{global query optimization}
  \item \textbf{local optimization}
\end{enumerate}
\subsubsection{Query decomposition}
La \textit{query decomposition} opera sullo schema logico globale non tenendo
conto della distribuzione. In questo caso si hanno tecniche di ottimizzazione
algebrica (usando quindi l'algebra relazionale indipendentemente dalla
distribuzione) analoghe a quelle usati in sistemi centralizzati e si ha come
output un \textbf{query tree} non ottimizzato rispetto ai \textbf{costi di
comunicazione}. Il costo di comunicazione riguarda il costo di uso della
\textbf{rete} e dipende da vari fattori. Il costo di comunicazione è il vero
``collo di bottiglia'' in sistemi distribuiti.
\subsubsection{Data localization}
La \textit{data localization} considera la frammentazione delle tabelle e la
distribuzione, capendo ad esempio dove effettuare le \textit{select}
etc$\ldots$. Si procede quindi all'ottimizzazione delle operazioni rispetto 
alla frammentazione, tramite \textbf{tecniche di riduzione}. Viene quindi
prodotta una query efficiente per la frammentazione ma non
ottimizzata. Supponiamo per esempio di avere una tabella su 3 nodi (distribuita
tramite frammentazione orizzontalmente) e che di base
la query faccia la richiesta a tutti e tre (facendo l'unione dei
risultati). Usando la tecnica di riduzione, qualora, per esempio, effettivamente
sia necessaria solo in un nodo, si avrà che la query sarà distribuita unicamente
nel nodo corretto.
\subsubsection{Global query optimization}
La \textit{global query optimization} si basa sulle statistiche sui frammenti
per effettuare l'ottimizzazione. Viene arricchito il \textbf{query tree}, creato
con gli operatori dell'algebra relazionale, tramite gli \textbf{operatori di
  comunicazione} (ovvero \textit{send} e \textit{receive}), che vengono
effettuati tra nodi. Alcune query, dopo aver tenuto conto dei tempi di
comunicazione, potranno essere eseguite in parallelo (grazie all'indipendenza
data dallo \textit{shared-nothing}). In questo caso le decisione più rilevanti
riguardano le operazioni di \textit{join} (che è uno degli operatori più
complicati) e,in particolare (come vedremo più avanti), l'ordine tra i
\textit{join} n-ari e la scelta tra \textit{join} e \textit{semijoin} (un
operatore particolare per i sistemi distribuiti). L'operatore di \textit{join}
infatti ``ingrandisce'' i dati ``fondendo'' tabelle, che magari sono frammentate
in più tabelle su vari nodi. L'uso di \textit{send} e \textit{receive} permette
la comunicazione dei dati tra i nodi, anche se questo rischia di diventare
troppo esoso in termini di prestazioni. Si hanno quindi degli \textbf{algoritmi
  di calcolo del costo adattivi} e si deve studiare la rete e i suoi
ritardi, che dipendono dalla \textit{topologia} della rete stessa e dal carico
applicativo. Si ha quindi una fase di \textbf{ottimizzazione a runtime}, dove si
riadatta il \textbf{query plan}. Per riadattarlo si fa in primis monitoring
sull'esecuzione della query, si procede adattando il modello di costo
(eventualmente con software automatici) e, eventualmente, riadattando la query
se si calcola uno scarto di costo troppo elevato. È il DBA che stabilisce delle
soglie temporali entro le quali ottenere una risposta. Per questo conta la
trasparenza, in quanto non è l'applicazione che deve interessarsi di questo
aspetto. Si introduce un nuovo \textit{layer} di complessità.\\
In alcuni casi è impossibile ad avere un DDBMS che si occupi di questo tipo di
ottimizzazioni.\\
\textbf{La distribuzione non è predicibile a priori}.
Vediamo un semplice esempio:
\begin{esempio}
   \label{esempio:costi}
  Si supponga di avere il seguente schema:
  \begin{itemize}
    \item Employee (eno, ename, title), di cardinalità 400
    \item AssiGN(eno, projectno, resp, dur), di cardinalità 1000 e dove
    \emph{resp} rappresentata il tipo di responsabilità
  \end{itemize}
  Si ha la seguente query: \textit{trovare i nomi dei dipendenti che sono anche
    manager di progetti:}
  \begin{minted}{sql}
    SELECT ename
    FROM Employee E JOIN AssiGN A on E.eno=A.eno
    WHERE resp=''manager''
  \end{minted}
  Che, in algebra relazionale già abbastanza ottimizzata ipotizzando che ci
  siano pochi manager, sarebbe:
  \[\pi_{ename}(EMP><_{eno}(\sigma_{resp=''manager''}(ASG)))\]
  Supponiamo di avere poi 5 nodi uguali, il quinto per il risultato e i primi 4
  frammentati orizzontalmente secondo questo schema di divisione per nodo:
  \begin{enumerate}
    \item $ASG1=\sigma_{eno}\leq 'E3'(ASG)$
    \item $ASG2=\sigma_{eno}> 'E3'(ASG)$
    \item $EMP1=\sigma_{eno}\leq 'E3'(EMP)$
    \item $EMP2=\sigma_{eno}> 'E3'(EMP)$
  \end{enumerate}
  Vediamo quindi una prima esecuzione:
  \begin{itemize}
    \item chiedo al nodo 1 i manager e sposto i risultati di\\
    $\sigma_{resp=''manager''}(ASG1)$ sul nodo 3 (dove sono 
    descritti in modo più completo) come $(ASG'1)$. Il risultato di
    $EMP1><_{eno}(ASG1)$, calcolato sul nodo 4, lo porto sul nodo 5 $EMP'1$ 
    \item chiedo al nodo 2 i manager e sposto i risultati di\\
    $\sigma_{resp=''manager''}(ASG'2)$ sul nodo 4 (dove sono descritti in modo
    più completo) come $(ASG'2)$. Il risultato di $EMP2><_{eno}(ASG'2)$,
    calcolato sul nodo 4, lo porto sul nodo 5 come $EMP'2$ 
    \item sul nodo 5 il risultato sarà $EMP'1\cup EMP'2$
  \end{itemize}
  Vediamo una seconda soluzione:
  \begin{itemize}
    \item contemporaneamente chiedo al nodo 1 e la nodo 3 di mandare al nodo 5
    tutti i manager. Sempre contemporaneamente a queste due operazioni chiedo al
    nodo 2 e al nodo 4 di mandare al nodo 5 tutte le informazioni. I tempi
    saranno basati sul più lento dei quattro nodi, che determinerà il tempo
    massimo dell'operazione (che sono circa calcolabili a priori tramite la
    tabella delle statistiche)
    \item nel nodo 5 calcolo il risultato:
    \[(EMP1\cup EMP2)><_{eno}\sigma_{resp=''manager''}(ASG1\cup ASG2)\]
  \end{itemize}
  I tempi di trasporto detteranno quale soluzione tra le due è la più
  performante ma, viste le cardinalità esigue di dati, probabilmente vince la
  seconda (dove si ha un solo spostamento globale). Questa seconda strategia
  costringe a pensare a particolari strutture di accesso secondarie dette
  \textbf{indici}, che permettono interrogazioni efficaci ma che \textbf{non
    possono essere ``portati''} in sistemi distribuiti. Quindi nel nodo 5 non ho
  gli \textbf{indici} e quindi devo fare l'intero \textbf{prodotto cartesiano}
  per il \textit{join} (che però in questo caso ha un tempo trascurabile,
  grazie alla bassa cardinalità dei dati, rispetto ai costi di trasferimento,
  generalmente non trascurabili rispetto ai costi delle operazioni interne ad un
  nodo).
\end{esempio}
Riprendendo l'esempio definiamo:
\begin{itemize}
  \item \textbf{costo di messaggio} come il costo fisso di spedizione o
  ricezione di un messaggio (detto \textit{setup})
  \item \textbf{costo di trasmissione} come il costo, fisso rispetto alla
  topologia, di trasmissione dati
  \item \textbf{costo di comunicazione} come la somma tra il costo di messaggio,
  moltiplicato per il numero di messaggi, più il costo di trasmissione,
  moltiplicato per il numero di \textit{bytes} trasmessi
  \item \textbf{costo totale} come la somma dei costi delle operazioni
  (\textit{I/O} e \textit{CPU}) più i costi di comunicazione
  (\textit{comunicazione})
  \item \textbf{response time} come la somma dei costi qualora si tenga conto
  del \textit{parallelismo delle trasmissioni}, quindi come la somma tra il
  costo di messaggio, moltiplicato per il numero di messaggi comunicati in modo
  sequenziale, più il costo di trasmissione, moltiplicato per il numero di
  \textit{bytes} trasmessi in modo sequenziale. In questo conto volendo posso
  usare dei \textbf{pesi} basati sulla cardinalità delle unità da trasferire e
  tenere conto del massimo tempo di risposta che si ottiene
\end{itemize}
Si ha quindi che:
\begin{itemize}
  \item nelle \textbf{grandi reti geografiche} i costi di\textit{ comunicazione}
  sono molto maggiori del costo di \textit{I/O}, circa di 10 volte 
  \item nelle \textbf{reti locali} i costi di \textit{comunicazione} e
  \textit{I/O} sono paragonabili, grazie alle reti \textit{gigabit} in locale
\end{itemize}
Tendenzialmente il costo di comunicazione è ancora il \textbf{fattore critico}
ma sempre meno.\\
Bisogna scegliere cosa \textbf{minimizzare}:
\begin{itemize}
  \item il \textit{response time}, aumentando il parallelismo che però può
  portare ad un aumento del \textit{costo totale}, con un maggior numero di
  trasmissione e un maggior processing locale. Nell'esempio \ref{esempio:costi}
  potrebbe sembrare la seconda soluzione, che effettivamente parallelizza di più
  ma non minimizza i costi di risposta 
  \item il \textit{costo totale}, senza tener conto del parallelismo utilizzando
  meglio le risorse e aumentando il \textit{throughput} ma peggiorando così il
  \textit{response time}. Nell'esempio \ref{esempio:costi} è la prima soluzione
\end{itemize}
\subsubsection{Join e Semijoin}
Il \textbf{join} presenta il problema di portare alla perdita
dell'\textbf{indice}. Bisogna quindi studiare come effettuare l'operazione tra
due tabelle su due nodi diversi. Una prima operazione è data dell'operazione di
\textit{semijoin}.
\begin{definizione}
  Definiamo, in algebra relazionale, l'operazione \textit{semijoin}, tra due
  tabelle $R$ e $S$, sull'attributo $A$, come:
  \[R\,\,\,semijoin_A\,\,\,S\equiv \pi_{R^*}(R\,\,\,join_A \,\,\,A)\]
  dove $R^*$ è l'insieme degli attributi di $R$.\\
  In altre parole scelgo esplicitamente di tenere solo gli attributi di $R$ dopo
  il \textit{semijoin}.\\
  Quindi con $R\,\,\,semijoin_A\,\,\,S$ ho la proiezione sugli attributi di $R$
  operazione di \textit{join} e quindi ho che il \textit{semijoin} non è
  \textbf{commutativo}.\\
  Dalla seconda tabella porto solo la serie di attributi che mi servono
  esplicitamente ($\pi_A(S)$) riducendo il carico di lavoro.\\
 \textbf{ Alla fine il nostro $R'$ con i risultati del \textit{semijoin} sarà
  trasportato nel nodo di $S$}
\end{definizione}
Prese due tabelle allocate su nodi differenti, il \textit{joi}n tra di esse può
quindi essere calcolato tramite operazioni di \textit{semijoin}, valgono infatti
le seguenti equivalenze (che portano a diverse strategie a seconda della stima
dei costi):
\begin{itemize}
  \item
  $R\,\,\,join_{\theta}\,\,\,S \iff (R\,\,\,semijoin_{\theta}\,\,\,S)
  \,\,\,join_\theta\,\,\,S$
  \item $R\,\,\,join_{\theta}\,\,\,S \iff
  R\,\,\,join_\theta\,\,\,(S\,\,\,semijoin_{\theta}\,\,\,R)$ 
  \item $R\,\,\,join_{\theta}\,\,\,S \iff (R\,\,\,semijoin_{\theta}\,\,\,S)
  \,\,\,join_\theta\,\,\,(A\,\,\,semijoin_{\theta}\,\,\,R)$
\end{itemize}
In tutti i casi si riduce lo spostamento dei dati.\\
L'uso del \textit{semijoin} è conveniente sse il costo del suo calcolo e del
trasferimento del risultato è inferiore al costo del trasferimento dell'intera
relazione e del costo dell'intero \textit{join} (e questo dipende dal numero di
attributi coinvolti).\\
\textit{Avere più di un \textit{join} complica la situazione, anche solo per la
  scelta dell'ordine in cui eseguirli.}
\subsubsection{Local optimization}
La \textit{local optimization} si occupa dell'ottimizzazione degli schemi
locali. Ogni nodo riceve una \textit{fragment query} e la ottimizza, con
tecniche analoghe ai sistemi centralizzati, in modo completamente
indipendente. Si hanno comunque operazioni di ottimizzazione locale a priori
sul fatto che il \textit{global query optimization} punti a ridurre i costi di
comunicazione (nel caso di un DDBMS in rete geografica) o ad aumentare il
parallelismo (in caso di DDBMS in rete locale).\\
In ogni caso nella progettazione di sistemi di gestione dati distribuiti bisogna
tener conto di:
\begin{itemize}
  \item tipologie di query distribuite
  \item stime o statistiche sullo storico query distribuite già eseguite (fatto
  periodicamente dal DDBMS)
  \item topologia della rete
  \item carico aspettato e workload previsto
\end{itemize}
\subsection{Query in scrittura e controllo di concorrenza}
\end{document}
% LocalWords:  Machine Learning DBMS DataBase System hashmap db workload system
% LocalWords:  storage Administrator DBA GUI SPARC performanti primis query SQL
% LocalWords:  join compiler DLL DDL Language step parsing Catalog metadati sql
% LocalWords:  tree parser plan select sottotabella FROM Where Stafford mgrssn
% LocalWords:  Bdate Pnumber l'ottimizzatore where Statistics Branch Bound work
% LocalWords:  transaction begin commit rollabck OLTP OnLine Processing ACID PL
% LocalWords:  rollback UNDO recovery serializzabile conflict equivalence locks
% LocalWords:  two phase locking shared deadlock timestamps lock serializzabili
% LocalWords:  unlock nothing vendor cloud DDBMS l'ottimizzatore Peer to client
% LocalWords:  object oriented OO example json warehouse LAV Local As View ODBC
% LocalWords:  routing processing vendors middleware DTP Distributed devices
% LocalWords:  GRID warehouses everything SMP Oracle RAC systems performances
% LocalWords:  big sottotabelle soft fail chunk ricostruibilità l'updates local
% LocalWords:  l'updates mapping rewriting replication decomposition global dur
% LocalWords:  optimization localization send receive semijoin runtime layer
% LocalWords:  monitoring response setup bytes gigabit throughput AssiGN eno
% LocalWords:  ename resp sse l'updates LocalWords l'updates fragment dell
