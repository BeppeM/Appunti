\documentclass[a4paper,12pt, oneside]{article}
% \usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{engrec}
\usepackage{rotating}
\usepackage[safe,extra]{tipa}
\usepackage{showkeys}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{sectsty}
\usepackage{mathtools}
\usepackage{microtype}
\usepackage{enumerate}
\usepackage{braket}
\usepackage{marginnote}
\usepackage{pgfplots}
\usepackage{cancel}
\usepackage{polynom}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage[cache=false]{minted}


\title{}

\author{}
\date{}

\pgfplotsset{compat=1.13}
\begin{document}
% \maketitle

\definecolor{shadecolor}{gray}{0.80}
\setlist{leftmargin = 2cm}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}

\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\allsectionsfont{\centering}
\section*{Formule}
\begin{itemize}
  \item Cardinalità spazio delle ipotesi:
  \[|X|=\prod |A_i|\]
  \item Cardinalità spazio dei concetti:
  \[|C|=|\mathcal{P}(X)|=2^{|X|}\]
  \item Cardinalità spazio delle ipotesi, semanticamente:
  \[|H|_{sem}=1+\prod_{A} (|A_i|+1)\]
  \item Cardinalità spazio delle ipotesi, sintatticamente:
  \[|H|_{sint}=\prod (|A_i|+2)\]
  \item Aspettativa di $G(X)$ su $P$ ($Val(X)$ = range di valori di $X$):
  \[E_P[g(X)]=\sum_{x\in Val(X)} g(x)\cdot P_X(x)\]
  \item Entropia di una variabile $X$:
  \[H[X]=-\sum_{i=1}^n p_i\cdot\log_2 p_i=E_P[\log_2(p)]\]
  \item Entropia di una distribuzione condizionale, con target $T$:
  \[H[T|X=x_i]=-\sum_{j=1}^m P_{T|X}(t_j|x_i)\cdot \log_2 P_{T|X}(t_j|x_i)\]
  \item Entropia condizionale, con target $T$:
  \[H[T|X]=\sum P(x)\cdot H(T|X=x)\]
  \item Information Gain su variabile $X$ e target $T$:
  \[IG[T|X]=H[T]-H[T|X]\]

\end{itemize}
\newpage
\section*{Definizioni}
\begin{itemize}
  \item \textbf{learner}, la parte di programma che impara dagli esempi in modo
  automatico
  \item \textbf{trainer}, il \textit{dataset} che fornisce esperienza al
  \textit{learner}
  \item \textbf{esperienza diretta} dove il learner può acquisire informazione
  utile direttamente dagli esempi o dover inferire indirettamente da essi
  l’informazione necessaria (può essere chiaramente più complicato). Altrimenti
  è indiretta
  \item \textbf{apprendimento supervisionato}, dove vengono forniti a priori
  esempi di comportamento e si suppone che il \textit{trainer} dia la risposta
  corretta per ogni input (mentre il learner usa gli esempi forniti per
  apprendere). L'esperienza è fornita da un insieme di coppie:
  \[S\equiv\{(x_1,y_1),(x_2,y_2),\ldots,(x_n,y_n)\}\]
  e, per ogni input ipotetico $x_i$ l'ipotetico trainer restituisce il corretto
  $y_i$
  \item \textbf{apprendimento non supervisionato}, dove si riconosce
  \textit{schemi} nell'input senza indicazioni sui valori in uscita. Non c'è
  target e si ha \textit{libertà di classificazione}. Si cerca una
  \textit{regolarità} e una \textit{struttura} insita nei dati. In questo caso
  si ha: 
  \[S\equiv\{x_1,x_2,\ldots,x_n\}\]
  Il clustering è un tipico problema di apprendimento non supervisionato. Non si
  ha spesso un metodo oggettivo per stabilire le prestazioni che vengono quindi
  valutate da umani
  \item \textbf{apprendimento per rinforzo}, dove bisogna apprendere, tramite il
  \textit{learner} sulla base
  della risposta dell’ambiente alle proprie azioni. Si lavora con
  un\textit{addestramento continuo}, aggiornando le ipotesi con l'arrivo dei
  dati (ad esempio per una macchina che deve giocare ad un gioco). Durante la
  fase di test bisogna conoscere le prestazioni e valutare la correttezza di
  quanto appreso. Il learner viene addestrato tramite \textit{rewards} e quindi
  apprende una strategia per massimizzare i \textit{rewards}, detta
  \textbf{strategia di comportamento} e per valutare la prestazione si cerca di
  massimizzare ``a lungo termine'' la ricompensa complessivamente ottenuta
  \item \textbf{apprendimento attivo}, dove il \textit{learner} può
  ``domandare'' sui dati 
  disponibili 
  \item \textbf{apprendimento passivo}, dove il \textit{learner} apprende solo a
  partire dai dati disponibili
  \item $X$, \textbf{spazio delle istanze}, ovvero la collezione di tutte le
  possibili \textbf{istanze} utili per qualche compito di
  \textit{learning}. In termini statistici lo \textit{spazio delle istanze}
  non è altro che lo \textbf{spazio campione} (ovvero lo spazio degli esiti
  fondamentali di un esperimento concettuale)
  \item $x\in X$, \textbf{istanza}, ovvero un singolo ``oggetto'' preso dallo
  \textbf{spazio delle istanze}. Ogni \textbf{istanza} è rappresentata tramite
  un \textbf{vettore di attributi unici} (un attributo per posizione del
  vettore)
  \item $c$, \textbf{concetto}, $c\subseteq X$, ovvero un sottoinsieme dello
  \textit{spazio delle istanze} che descrive una \textit{classe} di oggetti
  (ovvero di istanze) alla quale siamo interessati per costruire un modello di
  \textit{machine learning}. In pratica raccolgo quel sottoinsieme di istanze
  che mi garantiscono, per esempio, uno o più attributi. La nozione statistica
  equivalente è quella di \textit{evento} (ovvero un sottoinsieme dello
  \textit{spazio campione}). Si ha quindi che, preso un concetto $A\subseteq
  X$:
  \[f_A:X\to\{0,1\}\]
  \[f_a(x)=
    \begin{cases}
      1& \mbox{ se } x\in A\\
      0& \mbox{ altrimenti}
    \end{cases}
  \]
  \item $h$, \textbf{ipotesi}, $h\subseteq X$
  \item $H$, \textbf{spazio delle ipotesi}
  \item $(x, f(x))$, \textbf{esempio},
  ovvero prendo un'istanza e la vado ad etichettare con la sua classe di
  appartenenza. La funzione $f$ è detta \textbf{funzione target}
  \item $D=\{(x_1,f(x_1)),\ldots,(x_n,f(x_n))\}$, \textbf{training set},
  ovvero è la raccolta degli esempi. Qualora si avesse a che fare con un 
  \textit{training non supervisionato} si avrebbe:
  $D=\{x_1,\ldots,x_n\}$
  \item $\{(x_1',f(x_1')),\ldots,(x_n',f(x_n'))\}$, \textbf{test}
  \item un \textbf{modello di machine learning} (dove \textit{machine
    learning} viene anche definito come lo studio di diverse strategie, più
  precisamente di ottimizzazione, per
  cercare ipotesi soddisfacenti/efficienti nello spazio delle ipotesi) è
  quindi l'\textit{ipotesi migliore}. Questo \textbf{modello predittivo} viene
  addestrato tramite il \textit{training set} e servirà per inferire nuove
  informazioni mai state osservate nel \textit{training set}. Lo
  \textit{spazio delle ipotesi} può quindi essere chiamato anche
  \textbf{spazio dei modelli} (come del resto \textit{ipotesi} e
  \textbf{modello} intendono la stessa cosa)
  \item \textbf{linguaggio delle ipotesi}, è il linguaggio che definisce lo
  \textit{spazio delle ipotesi/modelli}
  
  \item \textbf{cross validation}, ovvero ripeto $m$ volte la validazione su
  campioni diversi di input per evitare che un certo risultato derivi dalla
  fortuna 
  \item \textbf{ipotesi H}, ovvero una congiunzione $\land$ di vincoli sugli
  attributi. Tale ipotesi è \textbf{consistente}, ovvero è coerente con tutti
  gli esempi
  \item \textbf{soddisfazione di un'ipotesi}: un'istanza $x$ soddisfa
  un'ipotesi $h$ sse tutti i vincoli espressi da $h$ sono soddisfatti dai
  valori di $x$ e si indica con:
  \[h(x)=1\]
  \item \textbf{concept learning} è la ricerca, nello spazio delle ipotesi,
  di funzioni che assumano valori all'interno di $\{0,1\}$. In altre parole si
  parla di funzioni che hanno come dominio lo \textbf{spazio delle ipotesi} e
  come codominio $\{0,1\}$:
  \[f:X\to\{0,1\}\]
  Volendo si possono usare insiemi e non funzioni.\\
  Si cerca quindi con opportune procedure la miglior ipotesi che si adatta
  meglio al concetto implicato dal \textit{training set}. Valori del concept
  learning:
  \begin{itemize}
    \item \item specificato
    \item non importante, che si indica con ``?'', e che può assumere
    qualsiasi valore. Avere un'ipotesi con tutti i valori del vettore pari a
    ``?'' implica avere l'ipotesi più generale, avendo classificato tutte le
    istanze solo come esempi positivi 
    \item nullo e si indica con $\emptyset$. Avere un'ipotesi con tutti i
    valori del vettore pari a $\emptyset$ implica avere l'ipotesi più
    specifica, avendo classificato tutte le istanze solo come esempi negativi
  \end{itemize}
  \item \textbf{inductive learning} quando voglio apprendere una funzione da
  un esempio (banalmente una funzione target $f$ con esempio $(x, f(x))$,
  ovvero una coppia). Si cerca quindi un'ipotesi $h$, a partire da un insieme
  d'esempi di apprendimento, tale per cui $h\approx f$
  
  \item \textbf{soddisfacibilità} quando un esempio $x$ soddisfa un'ipotesi
  $h$, evento indicato con:
  \[h(x)=1\]
  a priori sul fatto che $x$ sia un esempio positivo o negativo del
  \textit{target concept}. Si ha quindi
  che i valori $x$ soddisfano i vincoli $h$
  \item Si dice che $h$ è \textbf{consistente} con il training set $D$ di
  concetti target sse: 
  \[Consistent(h,D):=h(x)=c(x),\,\,\forall \langle x,c(x)\rangle\in D\]
  \item Si definisce \textbf{version space}, rispetto ad $H$ e $D$, come il
  sottoinsieme delle ipotesi da $H$ consistenti con $D$ e si indica con:
  \[VS_{H,D}=\{h\in H|\,Consistent(h,D)\]
  \item Date $h_j,h_k\in H$ booleane e definite su $X$. Si ha che $h_j$ è
  \textbf{più generale o uguale a} $h_k$ (e si scrive con $h_j\geq h_k$) sse:
  \[(h_k(x)=1)\longrightarrow (h_j(x)=1),\,\,\forall x\in X\]
  \textbf{Si impone quindi un ordine parziale}.\\
  Si ha che $h_j$ è \textbf{più generale di} $h_k$ (e si scrive con $h_j> h_k$)
  sse:
  \[(h_j\geq h_k)\land (h_k\not\geq h_j)\]
  Riscrivendo dal punto di vista insiemistico si ha che $h_j$ è \textbf{più
    generale o uguale a} $h_k$ sse:
  \[h_k\supseteq h_j\]
  e che è \textbf{più generale di} $h_k$ sse:
  \[h_k\supset h_j\]
  Dal punto di vista logico si ha che $h_j$ è \textbf{più generale di} $h_k$
  sse impone meno vincoli di $h_k$
  \item \textbf{Find-S} permette di partire dall'ipotesi più specifica
  (attributi nulli, indicati con $\emptyset$) e generalizzarla, trovando ad
  ogni passo un'ipotesi più specifica e consistente con il training set
  $D$. L'ipotesi in uscita sarà anche consistente con gli esempi negativi
  dando prova che il target è effettivamente in $H$. Con questo algoritmo non
  si può dimostrare di aver trovato l'unica ipotesi consistente con gli esempi
  e, ignorando gli esempi negativi non posso capire se $D$ contiene dati
  inconsistenti. Inoltre non ho l'ipotesi più generale
  \item  Il \textbf{bias induttivo} (con \textbf{bias} che normalmente denota
  una \emph{distorsione} o un \emph{scostamento} dei dati) di $L$ è un insieme
  minimale di asserzioni $B$ tale 
  che, per ogni concetto target $c$ e $D_c$ corrispondente si ha che:
  \[[B\land D_c\land x_i]\,\vdash\,L(x_i,D_c),\,\,\forall x_i\in X\]
  con $\vdash$ che rappresenta l'implicazione logica

  Possiamo quindi distinguere:
  \begin{itemize}
    \item \textbf{sistema induttivo}, dove si hanno in input gli esempi di
    training e la nuova istanza, viene usato l'algoritmo \textit{candidate
      eliminate} con $H$ e si ottiene o la classificazione della nuova istanza
    nulla
    \item \textbf{sistema deduttivo} equivalente al sistema induttivo sopra
    descritto dove in input si aggiunge l'asserzione ``$H$ contiene il concetto
    target'' e si produce lo stesso output tramite un \textbf{prover di teoremi}
  \end{itemize}
  \item 
\end{itemize}
\newpage
\section*{Procedimenti comodi}
\begin{itemize}
  \item Per \textbf{find-S} parto da tutti $\emptyset$, prendo solo esempi
  positivi e procedo sistemando attributo per attributo
  
\end{itemize}
\end{document}