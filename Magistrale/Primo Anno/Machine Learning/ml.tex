\documentclass[a4paper,12pt, oneside]{book}

% \usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{engrec}
\usepackage{rotating}
\usepackage{verbatim}
\usepackage[safe,extra]{tipa}
%\usepackage{showkeys}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{fontspec}
\usepackage{enumerate}
\usepackage{braket}
\usepackage{marginnote}
\usepackage{pgfplots}
\usepackage{cancel}
\usepackage{polynom}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage[cache=false]{minted}
\usepackage{mathtools}
\usepackage[noend]{algpseudocode}

\usepackage{tikz}\usetikzlibrary{er}\tikzset{multi  attribute /.style={attribute
    ,double  distance =1.5pt}}\tikzset{derived  attribute /.style={attribute
    ,dashed}}\tikzset{total /.style={double  distance =1.5pt}}\tikzset{every
  entity /.style={draw=orange , fill=orange!20}}\tikzset{every  attribute
  /.style={draw=MediumPurple1, fill=MediumPurple1!20}}\tikzset{every
  relationship /.style={draw=Chartreuse2,
    fill=Chartreuse2!20}}\newcommand{\key}[1]{\underline{#1}}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{decorations.markings}
  \usetikzlibrary{arrows,shapes,backgrounds,petri, trees}
\tikzset{
  place/.style={
        circle,
        thick,
        draw=black,
        minimum size=6mm,
    },
  transition/.style={
    rectangle,
    thick,
    fill=black,
    minimum width=8mm,
    inner ysep=2pt
  },
  transitionv/.style={
    rectangle,
    thick,
    fill=black,
    minimum height=8mm,
    inner xsep=2pt
  }
} 
\usetikzlibrary{automata,positioning}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}
\fancyfoot[C]{\thepage}
\definecolor{darkgreen}{rgb}{0.03,0.43, 0.30}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{epsfig}
\usepackage{pst-grad} % For gradients
\usepackage{pst-plot} % For axes
\usepackage[space]{grffile} % For spaces in paths
\usepackage{etoolbox} % For spaces in paths
\makeatletter % For spaces in paths
\patchcmd\Gread@eps{\@inputcheck#1 }{\@inputcheck"#1"\relax}{}{}
\makeatother
\title{Machine Learning}
\author{UniShare\\\\Davide Cozzi\\\href{https://t.me/dlcgold}{@dlcgold}}
\date{}

\pgfplotsset{compat=1.13}
\begin{document}
\maketitle

\definecolor{shadecolor}{gray}{0.90}
\setlist{leftmargin = 2cm}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}
\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}
\tableofcontents
\renewcommand{\chaptermark}[1]{%
  \markboth{\chaptername
    \ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}%
\chapter{Introduzione}
\textbf{Questi appunti sono presi a lezione. Per quanto sia stata fatta
  una revisione è altamente probabile (praticamente certo) che possano
  contenere errori, sia di stampa che di vero e proprio contenuto. Per
  eventuali proposte di correzione effettuare una pull request. Link: }
\url{https://github.com/dlcgold/Appunti}.\\
\textbf{Si segnala che le immagini sono tratte dalle slide del corso.}
\chapter{Introduzione al ML}
Il \textbf{Machine Learning (\textit{ML})} è sempre più diffuso nonostante sia
nato diversi anni fa.\\
Un \textbf{sistema di apprendimento automatico} ricava da un \textit{dataset}
una conoscenza non fornita a priori, descrivendo dati non forniti in
precedenza. Si estrapolano informazioni facendo assunzioni sulle informazioni
sistema già conosciute, creando una \textbf{classe delle ipotesi H}. Si cercano
ipotesi coerenti per guidare il sistema di apprendimento automatico. Bisogna
però mettere in conto anche eventuali errori, cercando di capire se esiste
davvero un'ipotesi coerente e, in caso di assenza, si cerca di approssimare. In
quest'ottica bisogna mediare tra \textbf{fit} e \textbf{complessità}. Ogni
sistema dovrà cercare di mediare tra questi due aspetti, un \textit{fit}
migliore comporta alta \textit{complessità}. Si ha sempre il rischio di
\textbf{overfitting}, cercando una precisione dei dati che magari non esiste. Si
ha un \textbf{generatore di dati} ma il sistema non ha conoscenza della totalità
degli stessi.\\
Definiamo alcuni concetti base:
\begin{itemize}
  \item \textbf{task (\textit{T})}, il compito da apprendere. È più acile
  apprendere attraverso esempi che codificare conoscenza o definire alcuni
  compiti. Inoltre il comportamento della macchina in un ambiente può essere
  diverso da quello desiderato, a causa della mutabilità dell'ambiente ed è più
  semplice cambiare gli esempi che ridisegnare un sistema 
  \item \textbf{performance (\textit{P})}, la misura della bontà
  dell'apprendimento (e bisognerà capire come misurare la cosa)
  \item \textbf{experience (\textit{E})}, l'esperienza sui cui basare
  l'apprendimento. Il tipo di esperienza scelto può variare molto il risultato e
  il successo dell'apprendimento
\end{itemize}
In merito alle parti ``software'' distinguiamo:
\begin{itemize}
  \item \textbf{learner}, la parte di programma che impara dagli esempi in modo
  automatico
  \item \textbf{trainer}, il \textit{dataset} che fornisce esperienza al
  \textit{learner}
\end{itemize}
Durante l'\textbf{apprendimento} si estrapolano dati da \textbf{istanze di
  addestramento o test}. Quindi:
\begin{itemize}
  \item si ricevono i dati di addestramento
  \item il sistema impara ad estrapolare partendo da quei dati
  \item si ricevono dati di test su cui si estrapola
\end{itemize}
L'ipotesi da apprendere viene chiamata \textbf{concetto target} (tra tutte le
ipotesi possibili identifico quella giusta dai dati di addestramento).\\
Approfondiamo il discorso relativo all'\textit{esperienza}. Innanzitutto nel
momento della scelta bisogna valutare la rappresentatività esperienza. SI ha
inoltre un controllo dell'esperienza da parte del \textit{learner}:
\begin{itemize}
  \item l'esperienza può essere fornita al learner senza che esso possa
  interagire
  \item il learner può porre domande su quegli esempi che non risultano chiari 
\end{itemize}
\textbf{L'esperienza deve essere presentata in modo causale.}\\
Si hanno due tipi di esperienza:
\begin{enumerate}
  \item \textbf{diretta}, dove i learner può acquisire informazione utile
  direttamente dagli esempi o dover inferire indirettamente da essi
  l’informazione necessaria (può essere chiaramente più complicato)
  \item \textbf{indiretta}
\end{enumerate}
Il tipo di dato che studieremo comunemente sarà il \textbf{vettore booleano} e
la risposta sarà anch'essa di tipo booleano. In questo contesto l'ipotesi è una
\textbf{congiunzione di variabili}.\\
Per ogni istanza di addestramento cerchiamo una risposta eventualmente
corrispondente al nostro \textit{target} (ovvero 1), qualora esista.\\
Si hanno tre tipi di apprendimento:
\begin{enumerate}
  \item \textbf{apprendimento supervisionato}, dove vengono forniti a priori
  esempi di comportamento e si suppone che il \textit{trainer} dia la risposta
  corretta per ogni input (mentre il learner usa gli esempi forniti per
  apprendere). L'esperienza è fornita da un insieme di coppie:
  \[S\equiv\{(x_1,y_1),(x_2,y_2),\ldots,(x_n,y_n)\}\]
  e, per ogni input ipotetico $x_i$ l'ipotetico trainer restituisce il corretto
  $y_i$
  \item \textbf{apprendimento non supervisionato}, dove si riconosce
  \textit{schemi} nell'input senza indicazioni sui valori in uscita. Non c'è
  target e si ha \textit{libertà di classificazione}. Si cerca una
  \textit{regolarità} e una \textit{struttura} insita nei dati. In questo caso
  si ha: 
  \[S\equiv\{x_1,x_2,\ldots,x_n\}\]
  Il clustering è un tipico problema di apprendimento non supervisionato. Non si
  ha spesso un metodo oggettivo per stabilire le prestazioni che vengono quindi
  valutate da umani
  \item \textbf{apprendimento per rinforzo}, dove bisogna apprendere, tramite il
  \textit{learner} sulla base
  della risposta dell’ambiente alle proprie azioni. Si lavora con
  un\textit{addestramento continuo}, aggiornando le ipotesi con l'arrivo dei
  dati (ad esempio per una macchina che deve giocare ad un gioco). Durante la
  fase di test bisogna conoscere le prestazioni e valutare la correttezza di
  quanto appreso. Il learner viene addestrato tramite \textit{rewards} e quindi
  apprende una strategia per massimizzare i \textit{rewards}, detta
  \textbf{strategia di comportamento} e per valutare la prestazione si cerca di
  massimizzare ``a lungo termine'' la ricompensa complessivamente ottenuta
\end{enumerate}
Possiamo inoltre distinguere due tipi di apprendimento:
\begin{enumerate}
  \item \textbf{attivo}, dove il \textit{learner} può ``domandare'' sui dati
  disponibili 
  \item \textbf{passivo}, dove il \textit{learner} apprende solo a partire dai
  dati disponibili 
\end{enumerate}
Si parla di \textbf{inductive learning} quando voglio apprendere una funzione da
un esempio (banalmente una funzione target $f$ con esempio $(x, f(x))$, ovvero
una coppia). Si cerca quindi un'ipotesi $h$, a partire da un insieme d'esempi di
apprendimento, tale per cui $h\approx f$. Questo è un modello semplificato
dell'apprendimento reale in quanto si ignorano a priori conoscenze e si assume
di avere un insieme di dati. Viene usato un approccio che sfrutta anche il
\textit{Rasoio di Occam}.
\begin{shaded}
  \textbf\textit{{Terminologia:}}
  \begin{itemize}
    \item $X$, \textbf{spazio delle istanze}, ovvero la collezione di tutte le
    possibili \textbf{istanze} utili per qualche compito di
    \textit{learning}. In termini statistici lo \textit{spazio delle istanze}
    non è altro che lo \textbf{spazio campione} (ovvero lo spazio degli esiti
    fondamentali di un esperimento concettuale)
    \item $x\in X$, \textbf{istanza}, ovvero un singolo ``oggetto'' preso dallo
    \textbf{spazio delle istanze}. Ogni \textbf{istanza} è rappresentata tramite
    un \textbf{vettore di attributi unici} (un attributo per posizione del
    vettore)
    \item $c$, \textbf{concetto}, $c\subseteq X$, ovvero un sottoinsieme dello
    \textit{spazio delle istanze} che descrive una \textit{classe} di oggetti
    (ovvero di istanze) alla quale siamo interessati per costruire un modello di
    \textit{machine learning}. In pratica raccolgo quel sottoinsieme di istanze
    che mi garantiscono, per esempio, uno o più attributi. La nozione statistica
    equivalente è quella di \textit{evento} (ovvero un sottoinsieme dello
    \textit{spazio campione}). Si ha quindi che, preso un concetto $A\subseteq
    X$:
    \[f_A:X\to\{0,1\}\]
    \[f_a(x)=
      \begin{cases}
        1& \mbox{ se } x\in A\\
        0& \mbox{ altrimenti}
      \end{cases}
    \]
    \item $h$, \textbf{ipotesi}, $h\subseteq X$
    \item $H$, \textbf{spazio delle ipotesi}
    \item $(x, f(x))$, \textbf{esempio},
    ovvero prendo un'istanza e la vado ad etichettare con la sua classe di
    appartenenza. La funzione $f$ è detta \textbf{funzione target}
    \item $D=\{(x_1,f(x_1)),\ldots,(x_n,f(x_n))\}$, \textbf{training set},
    ovvero è la raccolta degli esempi. Qualora si avesse a che fare con un 
    \textit{training non supervisionato} si avrebbe:
    $D=\{x_1,\ldots,x_n\}$
    \item $\{(x_1',f(x_1')),\ldots,(x_n',f(x_n'))\}$, \textbf{test}
    \item un \textbf{modello di machine learning} (dove \textit{machine
      learning} viene anche definito come lo studio di diverse strategie, più
    precisamente di ottimizzazione, per
    cercare ipotesi soddisfacenti/efficienti nello spazio delle ipotesi) è
    quindi l'\textit{ipotesi migliore}. Questo \textbf{modello predittivo} viene
    addestrato tramite il \textit{training set} e servirà per inferire nuove
    informazioni mai state osservate nel \textit{training set}. Lo
    \textit{spazio delle ipotesi} può quindi essere chiamato anche
    \textbf{spazio dei modelli} (come del resto \textit{ipotesi} e
    \textbf{modello} intendono la stessa cosa)
    \item \textbf{linguaggio delle ipotesi}, è il linguaggio che definisce lo
    \textit{spazio delle ipotesi/modelli}
    \begin{esempio}
      Prendiamo un problema semplice di \textit{regressione lineare}.\\
      In questo contesto un'istanza è un punto $(x,y)$, lo spazio delle ipotesi
      è quello formato dalle rette $y=a+bx$ (dove $a$ è il nostro
      \textbf{bias}). Tra tutte queste rette cerco quella che sarà il
      \textbf{modello predittivo}, tramite la quale poter prevedere l'andamento
      dei vari punti (di modo che dato un $x$ sia in grado di stabilire un buon
      $y$)
    \end{esempio}
    
    \item \textbf{cross validation}, ovvero ripeto $m$ volte la validazione su
    campioni diversi di input per evitare che un certo risultato derivi dalla
    fortuna 
    \item \textbf{ipotesi H}, ovvero una congiunzione $\land$ di vincoli sugli
    attributi. Tale ipotesi è \textbf{consistente}, ovvero è coerente con tutti
    gli esempi
    \item \textbf{soddisfazione di un'ipotesi}: un'istanza $x$ soddisfa
    un'ipotesi $h$ sse tutti i vincoli espressi da $h$ sono soddisfatti dai
    valori di $x$ e si indica con:
    \[h(x)=1\]
    \begin{esempio}
      Avendo:
      \[x=\langle S,W,N,S,W,S\rangle \mbox{ \textnormal{e}
        }h=\langle S,?,?,S,?,S\rangle\]
      posso dire che $x$ soddisfa $h$.\\
      se invece ho che:
      \[h=\langle S,?,?,\emptyset,?,S\rangle\]
      posso dire che $x$ non soddisfa $h$.
    \end{esempio}
  \end{itemize}
\end{shaded}
Si avrà, in realtà, a che fare con dati, di target e ipotesi,
booleani e questo ambito è propriamente chiamato \textbf{concept learning}.
\begin{definizione}
  Il \textbf{concept learning} è la ricerca, nello spazio delle ipotesi, di
  funzioni che assumano valori all'interno di $\{0,1\}$. In altre parole si
  parla di funzioni che hanno come dominio lo \textbf{spazio delle ipotesi} e
  come codominio $\{0,1\}$:
  \[f:X\to\{0,1\}\]
  Volendo si possono usare insiemi e non funzioni.\\
  Si cerca quindi con opportune procedure la miglior ipotesi che si adatta
  meglio al concetto implicato dal \textit{training set}
\end{definizione}
In questo contesto si cerca di capire quale funzione booleana è adatta al mio
addestramento. In altre parole si cerca di apprendere un'ipotesi booleana
partendo da esempi di training composti da input e output della
funzione. Qualora nel concept learning si abbia a che fare con più di due 
possibilità si aumentano i bit usati.\\
Nel concept learning un'ipotesi è un insieme di valori di attributi e ogni
valore può essere:
\begin{itemize}
  \item specificato
  \item non importante, che si indica con ``?'', e che può assumere qualsiasi
  valore. Avere un'ipotesi con tutti i valori del vettore pari a ``?'' implica
  avere l'ipotesi più generale, avendo classificato tutte le istanze solo come
  esempi positivi 
  \item nullo e si indica con $\emptyset$. Avere un'ipotesi con tutti i valori
  del vettore pari a $\emptyset$ implica avere l'ipotesi più specifica, avendo
  classificato tutte le istanze solo come esempi negativi 
\end{itemize}
\begin{esempio}
  Vediamo quindi la rappresentazione di una ipotesi (ipotizzando di avere a che
  fare con solo 4 attributi $A_i$, sempre in prospettiva booleana):
  \[h=\langle 0, 1, ?, 1\rangle = \langle A_1=0, A_2=1, A_3=\,?, A_4=1\rangle\]
  nella realtà, grazie al ``?'' riferito all'istanza, l'ipotesi $h$ è un insieme
  di due ipotesi: 
  \[h\in\{(0, 1, 0, 1),\,(0, 1, 1, 1)\}\]
  \textbf{passando quindi da una notazione per ipotesi ad una insiemistica}.\\
  Ricordiamo inoltre che lo spazio delle istanze $X$, dal punto di vista
  insiemistico è:
  \[X=\{(x_1,x_2,x_3,x_3): \,\,x_1\in A_1,x_2\in A_2, x_3\in A_3, x_4\in A_4\}\]
  Se un'istanza $x$ soddisfa i vincoli di $h$ allora $h$ classifica $x$ come
  esempio positivo:
  \[h(x)=1\]
\end{esempio}
Quindi, dato un \textit{training set} $D$, cerco di determinare un'ipotesi $h\in
H$ tale che: 
\[h(x)=c(x),\,\forall x\in D\]
Si ha la teoria delle \textbf{ipotesi di apprendimento induttivo} che dice che
se la mia $h$ approssima bene nel \textit{training set} allora approssima bene
su tutti gli esempi non ancora osservati.\\
Il concept learning è quindi una ricerca del \textit{fit} migliore.
\begin{definizione}
  Date $h_j,h_k\in H$ booleane e definite su $X$. Si ha che $h_j$ è \textbf{più
    generale o uguale a} $h_k$ (e si scrive con $h_j\geq h_k$) sse:
  \[(h_k(x)=1)\longrightarrow (h_j(x)=1),\,\,\forall x\in X\]
  \textbf{Si impone quindi un ordine parziale}.\\
  Si ha che $h_j$ è \textbf{più generale di} $h_k$ (e si scrive con $h_j> h_k$)
  sse:
  \[(h_j\geq h_k)\land (h_k\not\geq h_j)\]
  Riscrivendo dal punto di vista insiemistico si ha che $h_j$ è \textbf{più
    generale o uguale a} $h_k$ sse:
  \[h_k\supseteq h_j\]
  e che è \textbf{più generale di} $h_k$ sse:
  \[h_k\supset h_j\]
  Dal punto di vista logico si ha che $h_j$ è \textbf{più generale di} $h_k$ sse
  impone meno vincoli di $h_k$
\end{definizione}
\textit{Lo spazio delle ipotesi è descritto da una congiunzione di attributi.}
\begin{esempio}
  Facciamo un esempio ``giocattolo'' di situazione di \textbf{concept
    learning}.\\ 
  Il \textbf{target concept}, ovvero la domanda che ci si pone, è:\\
  \begin{center}
    \textit{In quali tipologie di giorni $A$ apprezza fare sport acquatici?}
  \end{center}
  Abbiamo quindi una serie di attributi per il meteo con i vari valori che
  possono assumere:
  \begin{table}[H]
    \centering
    \begin{tabular}[H]{|c|c|}
      \hline
      \textbf{Attributo} & \textbf{\textit{Possibili valori}}\\
      \hline
      sky & \textit{Sunny, Cloudy, Rainy}\\
      temp & \textit{Warm, Cold}\\
      humid & \textit{Normal, High}\\
      wind & \textit{Strong, Weak}\\
      water & \textit{Warm, Cold}\\
      forecast & \textit{Same, Change}\\
      \hline
    \end{tabular}
  \end{table}
  In ottica \textit{concept learning} si cerca quindi la \textbf{funzione
    target} $enjoySport$ (che sarebbe la nostra funzione $c$): 
  \[enjoySport:X\to\{0,1\}\]
  Vediamo quindi anche un esempio di \textit{training set} $D$ (per praticità i
  valori degli attributi sono indicati con la sola iniziale):
  \begin{table}[H]
    \centering
    \begin{tabular}[H]{|c|c|c|c|c|c|c|}
      \hline
      \textbf{sky} & \textbf{temp} & \textbf{humid} & \textbf{wind} &         
      \textbf{water} & \textbf{forecast} & \textbf{enjoySport}\\
      \hline
      S & W & N & S & W & S & \color{darkgreen} yes\\
      S & W & H & S & W & S & \color{darkgreen} yes\\
      R & C & H & S & W & C & \color{red} no\\
      S & W & H & S & C & C & \color{darkgreen} yes\\
      \hline
    \end{tabular}
  \end{table}
  Dove nella colonna finale si ha la risposta booleana al problema, è infatti
  l'\textbf{etichetta target}.\\
  Bisogna quindi cercare un'ipotesi $h$ tale che $h(x)=c(x)$,
  per tutte le istanze nel \textit{training set}.\\
  Un'ipotesi $h$, anch'essa rappresentata come vettore, sarà quindi una
  congiunzione $\land$ di vincoli di valore sugli attributi.
  \label{es:tab}
\end{esempio}
\begin{esempio}
  Vediamo un esempio anche relativo alle nozioni di \textbf{più generale di}.\\
  Si hanno due ipotesi:
  \[h_J=\langle S,?,?,?,?,?\rangle\]
  \[h_k=\langle S,?,?,S,?,?\rangle\]
  e quindi si ha che:
  \[h_J\geq h_k \mbox{ \textnormal{ovvero} }h_k(x)=1\implies h_j(x)=1\]
  infatti un'istanza positiva per $h_k$ è sicuramente positiva anche per $h_j$,
  in quanto $h_k$ ha un vincolo più restrittivo sul quarto attributo, che deve
  assumere il valore $S$, mentre il quarto attributo di $h_j$ può assumere
  qualsiasi valore. Questo aspetto si potrebbe rappresentare con un
  \textbf{diagramma di Eulero-Venn} dal punto di vista insiemistico (con il
  ``cerchio'' di $h_j$ che conterrebbe quello di $h_k$ (essendo un insieme più
  esterno e quindi più generale), nello spazio delle istanze).
  \begin{figure}
    \centering
    
    \psscalebox{1 1} % Change this value to rescale the drawing.
    {
      \begin{pspicture}(0,-2.3375487)(4.0,2.3375487)
        \definecolor{colour0}{rgb}{0.99607843,0.30980393,0.30980393}
        \definecolor{colour1}{rgb}{0.25490198,0.41960785,0.94509804}
        \definecolor{colour2}{rgb}{0.4117647,0.6784314,0.31764707}
        \psframe[linecolor=colour0, linewidth=0.04, dimen=outer]
        (4.0,1.6624511)(0.0,-2.3375487)
        \pscircle[linecolor=colour1, linewidth=0.04, dimen=outer]
        (2.0,-0.33754882){1.6}
        \rput{-271.73}(1.0203394,-1.7267202){
          \psellipse[linecolor=colour2, linewidth=0.04, dimen=outer]
          (1.4,-0.33754882)(0.6,0.4)}
        \psdots[linecolor=black, dotsize=0.1](2.4,-0.33754882)
        \psdots[linecolor=black, dotsize=0.1](2.4,-0.7375488)
        \psdots[linecolor=black, dotsize=0.1](1.6,-1.1375488)
        \psdots[linecolor=black, dotsize=0.1](1.2,-0.33754882)
        \psdots[linecolor=black, dotsize=0.1](0.4,1.2624512)
        \psdots[linecolor=black, dotsize=0.1](3.6,1.2624512)
        \psdots[linecolor=black, dotsize=0.1](3.6,0.8624512)
        \psdots[linecolor=black, dotsize=0.1](3.2,-1.9375489)
        \psdots[linecolor=black, dotsize=0.1](0.4,-1.9375489)
        \psdots[linecolor=black, dotsize=0.1](0.8,-1.9375489)
        \psdots[linecolor=black, dotsize=0.1](2.8,0.46245116)
        \psdots[linecolor=black, dotsize=0.1](3.2,-0.33754882)
        \psdots[linecolor=black, dotsize=0.1](3.2,-0.33754882)
        \psdots[linecolor=black, dotsize=0.1](2.8,-0.7375488)
        \psdots[linecolor=black, dotsize=0.1](2.0,0.8624512)
        \rput[bl](0.1,1.8624511){Spazio delle ipotesi $X$}
        \rput[bl](0.28,0.46245116){$h_j$}
        \rput[bl](1.7,0.062451173){$h_k$}
      \end{pspicture}
    }
    \label{fig:eulero}
    \caption{Rappresentazione di \textbf{più generale di} con i diagrammi di
      Eulero-Venn, dove si nota come, in $X$, $h_j\geq h_k$} 
  \end{figure}
\end{esempio}
\begin{esempio}
  Consideriamo un'ipotesi $h$, con quattro attributi, dal punto di vista
  insiemistico: 
  \[h\in\{( 0, 1, 1, 1)\,(0, 1, 0, 0)\}\]
  e ci si chiede se $h\in H$.\\
  In primis possiamo ``comprimere'' questa rappresentazione insiemistica in:
  \[h=\langle 0, 1, ?, ?\rangle\]
  $h$ ora è rappresentata come tipicamente fatto nel \textit{concept
    learning}.\\
  Quindi $h\in H$, avendo un'ipotesi con quattro attributi. 
\end{esempio}
\begin{esempio}
  Consideriamo un concetto $c$, con cinque attributi, dal punto di vista
  insiemistico:
  \[c\in
    \begin{cases}
      \begin{rcases}
        (0,1,0,1,0),\\
        (0,1,1,1,0),\\
        (0,1,0,1,1),\\
        (0,1,1,1,1)
      \end{rcases}
    \end{cases}
  \]
  e ci si chiede se $c\in H$, quindi se la strategia è di ricerca è buona esso
  può essere ritrovato (altrimenti nessuna strategia lo potrebbe riconoscere).\\
  Studiando $c$ otteniamo che:
  \[c=\langle 0,1,?,1,?\rangle\]
  \textbf{Usiamo la stessa rappresentazione usata per le ipotesi}
\end{esempio}
\begin{esempio}
  Vediamo un esempio di studio dello spazio delle istanze $X$.\\
  Considero che le istanze sono specificate da due attributi: $A_1=\{0,1,2\}$ e
  $A_2=\{0,1\}$.
  Quindi, sapendo che $X=A_1\times A_2$ (con $\times$ \textbf{prodotto
    cartesiano}), ho che: 
  \[|X|=|A_1\times A_2|\]
  e quindi in questo caso $|X|=6$
\end{esempio}
\begin{esempio}
  Vediamo un esempio di studio del numero di concetti.\\
  in $X$ abbiamo 3 attributi, ciascuno con 3 possibili valori:
  $A_i=\{0,1,2\},\,\,i= 1,2,3$
  Abbiamo già visto come calcolare $|X|$ e quindi sappiamo che:
  \[|X|=3^3=27\]
  
  Sappiamo che un concetto $c$ è un sottoinsieme di $X$, quindi, chiamato
  $C=\{c_i\subseteq X\}$ l'insieme di tutti i concetti so che la sua cardinalità
  è pari alla cardinalità dell'\textbf{insieme delle parti} di $X$:
  \[|C|=|\mathcal{P}(X)|=|2^{|X|}|=2^{27}\]
\end{esempio}
\begin{esempio}
  Vediamo un esempio di studio del numero delle ipotesi, ovvero si studia la
  cardinalità dello spazio delle ipotesi (che altro non è che il numero di
  differenti combinazioni di tutti i possibili valori per ogni possibile
  attributo).\\
  Bisogna notare che l'uso di $\emptyset$ come valore di un attributo in
  un'ipotesi rende tale ipotesi \textbf{semanticamente equivalente} a qualsiasi
  altra che contenga un $\emptyset$ (anche non per lo stesso attributo). Inoltre
  tutte queste sono ipotesi che rifiutano tutto. Tutte queste ipotesi conteranno
  come un unico caso nel conteggio delle ipotesi.\\
  Quindi per conteggiare tutte ipotesi \textbf{semanticamente differenti} dovrò
  fare (indicando con $|A|$ il numero di valori possibili per l'attributo $A$):
  \[|H|_{sem}=1+\prod_{A\in A_i} (|A|+1)\]
  quindi moltiplicare tutti il numero di valori di ogni attributo più 1
  (indicante ``?'' e che quindi va conteggiato come possibile valore per ogni
  attributi) e sommare 1 (indicante $emptyset$ che va conteggiato solo una volta
  per il discorso fatto sopra in merito all'equivalenza semantica di tali
  ipotesi) a questo risultato finale.\\
  \textbf{La seguente affermazione è un esercizio dato a casa, che io risolverei
  come scritto.}\\
  Qualora volessi conteggiare tutte ipotesi \textbf{sintatticamente differenti}
  dovrò contare $\emptyset$ come ipotetico valore per ogni attributo e quindi:
   \[|H|_{sint}=\prod_{A\in A_i} (|A|+2)\]
\end{esempio}
\section{Primi algoritmi}
\subsection{Algoritmo find-S}
Parliamo ora dell'algoritmo \textbf{Find-S}. Questo algoritmo permette di
partire dall'ipotesi più specifica (attributi nulli, indicati con
$\emptyset$) e generalizzarla, 
trovando ad ogni passo un'ipotesi più specifica e consistente con il training
set $D$. L'ipotesi in uscita sarà anche consistente con gli esempi negativi
dando prova che il target è effettivamente in $H$. Con questo algoritmo non si
può dimostrare di aver trovato l'unica ipotesi consistente con gli esempi e,
ignorando gli esempi negativi non posso capire se $D$ contiene dati
inconsistenti. Inoltre non ho l'ipotesi più generale.
\begin{algorithm}[H]
  \begin{algorithmic}
    \Function{findS}{}
    \State $h\gets \mbox{ l'ipotesi più specifica in } H$
    \For {\textit{ogni istanza di training positiva $x$}}
    \For {\textit{ogni vincolo di attributo $a_i$ in $h$}}
    \If { il vincolo di attributo $a_i$ in $h$ è soddisfatto da $x$}
    \State \textit{non fare nulla}
    \Else
    \State \textit{sostituisci $a_i$ in $h$ con il successivo vincolo più}
    \State \textit{generale che è soddisfatto da $x$}
    \EndIf
    \EndFor
    \EndFor
    \Return \textit{ipotesi $h$}
    \EndFunction
  \end{algorithmic}
  \caption{Algoritmo Find-S}
\end{algorithm}
\subsection{Algoritmi di eliminazione}
\begin{definizione}
  Si dice che $h$ è \textbf{consistente} con il training set $D$ di concetti
  target sse: 
  \[Consistent(h,D):=h(x)=c(x),\,\,\forall \langle x,c(x)\rangle\in D\]
\end{definizione}
\begin{definizione}
  Si definisce \textbf{version space}, rispetto ad $H$ e $D$, come il
  sottoinsieme delle ipotesi da $H$ consistenti con $D$ e si indica con:
  \[VS_{H,D}=\{h\in H|\,Consistent(h,D)\]
\end{definizione}
\begin{esempio}
  Vediamo un esempio per capire la consistenza. Riprendiamo la situazione
  dell'esempio \ref{es:tab} con un \textit{training set} $D$ leggermente
  diverso: 
  \begin{table}[H]
    \centering
    \begin{tabular}[H]{|c|c|c|c|c|c|c|c|}
      \hline
      \textbf{example} & \textbf{sky} & \textbf{temp} & \textbf{humid}
      & \textbf{wind} & \textbf{water} & \textbf{forecast} &
      \textbf{enjoySport}\\
      \hline
      1 & S & W & N & S & W & S & \color{darkgreen} yes\\
      2 & S & W & H & S & W & S & \color{darkgreen} yes\\
      3 & R & C & H & S & W & C & \color{red} no\\
      4 & S & W & H & S & C & C & \color{darkgreen} yes\\
      \hline
    \end{tabular}
  \end{table}
  e prendiamo l'ipotesi:
  \[h=\langle S,W, ?, S, ?, ?\rangle\]
  e studiamo se $h$ sia \textbf{consistente} con $D$.\\
  Studio l'esempio 1: ($\langle S,W, N, S, W, S\rangle$,\textit{yes}). Vedo che
  ogni valore va bene e, avendo la classificazione 
  \textit{yes}, ho la stessa etichetta assegnata dalla \textbf{funzione target}
  $enjoySport$, quindi l'ipotesi è consistente con l'esempio. \\
  Questo vale per tutti e quattro gli esempi (il terzo non ``appaia'' ma questo
  è confermato dalla label \textit{no}) e quindi la mia ipotesi è
  \textbf{consistente} con il \textit{training set}.
\end{esempio}

Vediamo quindi algoritmo \textbf{List-Then Eliminate}:
\begin{algorithm}[H]
  \begin{algorithmic}
    \Function{LTE}{}
    \State $vs \gets$ \textit{una lista connettente tutte le ipotesi di } $H$
    \For {\textit{ogni esempio di training $\langle x,c(x)\rangle$}}
    \State \textit{rimuovi da $vs$ ogni ipotesi $h$ non consistente con}
    \State \textit{l'esempio di training, ovvero $h(x)\neq c(x)$}
    \EndFor
    \Return \textit{la lista delle ipotesi in $vs$}
    \EndFunction
  \end{algorithmic}
  \caption{Algoritmo List-Then Eliminate}
\end{algorithm}
Questo algoritmo è irrealistico in quanto richiese un numero per forza esaustivo
di ipotesi.
\newpage
\begin{definizione}
  Definiamo:
  \begin{itemize}
    \item $G$ come il confine generale di $VS_{H,D}$, ovvero l'insieme dei
    membri generici al massimo. È l'insieme delle ipotesi più generali:
    \[G=\{g\in H|\, g\mbox{ è consistente con }D \land\]
    \[ (\nexists g'\in H \mbox{ t.c } g'\geq q \land g'\mbox{ è consistente con
      }D\})\]
    Possiamo dire che $G=\langle ?,?,?,\ldots ?\rangle$
    \item $S$ come il confine specifico di $VS_{H,D}$, ovvero l'insieme dei
    membri specifici al massimo. È l'insieme delle ipotesi più specifiche:
     \[S=\{s\in H|\, s\mbox{ è consistente con }D \land\]
    \[ (\nexists s'\in H \mbox{ t.c } s'\geq s \land s'\mbox{ è consistente con
      }D\})\]
    Possiamo dire che $S=\langle \emptyset,\emptyset,\emptyset,\ldots \emptyset
    \rangle$ 
  \end{itemize}
  Ogni elemento di $VS_{H,D}$ si trova tra questi confini:
  \[VS_{H,D}=\{h\inH|\,(\exists s\in S)\,\,(\exists g\in G)\,\,(g\geq h\geq
    s)\}\]
  con $\geq$ che specifica che è \textit{più generale o uguale}
\end{definizione}
Vediamo quindi algoritmo \textbf{candidate eliminate}
\begin{algorithm}[H]
  \begin{algorithmic}
    \Function{CE}{}
    \State $G\gets$ \textit{insieme delle ipotesi più generali in $H$}
    \State $S\gets$ \textit{insieme delle ipotesi più specifiche in $H$}
    \For {\textit{ogni esempio di training $d=\langle x,c(x)\rangle$}}
    \If {\textit{d è un esempio positivo}}
    \State \textit{rimuovi da $G$ ogni ipotesi inconsistente con $d$}
    \For {\textit{ogni ipotesi $s$ in $S$ inconsistente con $d$}}
    \State \textit{rimuovi $s$ da $S$}
    \State
    \State \textit{aggiungi a $S$ tutte le generalizzazioni minime $h$ di $s$}
    \State \textit{tali che $h$ sia consistente con $d$ e qualche membro di $G$}
    \State \textit{sia più generale di $h$}
    \EndFor
    \State \textit{rimuovi da $S$ ogni ipotesi più generale di un'altra in $S$}
    \Else
    \State \textit{rimuovi da $S$ ogni ipotesi inconsistente con $d$}
    \For {\textit{ogni ipotesi $g$ in $G$ inconsistente con $d$}}
    \State \textit{rimuovi $g$ da $G$}
    \State
    \State \textit{aggiungi a $G$ tutte le generalizzazioni minime $h$ di $g$}
    \State \textit{tali che $h$ sia consistente con $d$ e qualche membro di $S$}
    \State \textit{sia più generale di $h$}
    \EndFor
    \State \textit{rimuovi da $G$ ogni ipotesi più generale di un'altra in $G$}
    \EndIf
    \EndFor
    \Return \textit{la lista delle ipotesi in $vs$}
    \EndFunction
  \end{algorithmic}
  \caption{Algoritmo Candidate Eliminate}
\end{algorithm}
Questo algoritmo ha alcune proprietà:
\begin{itemize}
  \item converge all'ipotesi $h$ corretta provando che non ci sono errori in $D$
  e che $c\in H$
  \item se $D$ contiene errori allora l'ipotesi corretta sarà eliminata dal
  \textit{version space}
  \item si possono apprendere solo le congiunzioni
  \item se $H$ non contiene il concetto corretto $c$, verrà trovata l'ipotesi
  vuota
\end{itemize}
Il nostro spazio delle ipotesi non è in grado di rappresentare un semplice
concetto di target disgiuntivo, si parla infatti di \textbf{Biased Hypothesis
  Space}. \\
Studiamo quindi un \textbf{unbiased learner}. Si vuole scegliere un $H$ che
esprime ogni concetto insegnabile, ciò significa che $H$ è l'insieme di tutti i
possibili sottoinsiemi di $X$. $H$ sicuramente contiene il concetto target. $S$
diventa l'unione degli esempi positivi e $G$ la negazione dell'unione di quelli
negativi. Per apprendere il concetto di target bisognerebbe presentare ogni
singola istanza in $X$ come esempio di training.\\
Un learner che non fa assunzioni a priori in merito al concetto target non ha
basi ``razionali'' per classificare istanze che non vede.\\
Introduciamo quindi il \textbf{bias induttivo} considerando:
\begin{itemize}
  \item un algoritmo di learning del concetto $L$
  \item degli esempi di training $D_C=\{\langle x,c(x)\rangle\}$
\end{itemize}
Si ha che $L(x_i,D_c$) denota la classificazione assegnata all'istanza $x_1$, da
$L$, dopo il training con $D_c$.
\begin{definizione}
  Il \textbf{bias induttivo} (con \textbf{bias} che normalmente denota una
  \emph{distorsione} o un \emph{scostamento} dei dati) di $L$ è un insieme
  minimale di asserzioni $B$ tale 
  che, per ogni concetto target $c$ e $D_c$ corrispondente si ha che:
  \[[B\land D_c\land x_i]\,\vdash\,L(x_i,D_c),\,\,\forall x_i\in X\]
  con $\vdash$ che rappresenta l'implicazione logica
\end{definizione}
Possiamo quindi distinguere:
\begin{itemize}
  \item \textbf{sistema induttivo}, dove si hanno in input gli esempi di
  training e la nuova istanza, viene usato l'algoritmo \textit{candidate
    eliminate} con $H$ e si ottiene o la classificazione della nuova istanza
  nulla
  \item \textbf{sistema deduttivo} equivalente al sistema induttivo sopra
  descritto dove in input si aggiunge l'asserzione ``$H$ contiene il concetto
  target'' e si produce lo stesso output tramite un \textbf{prover di teoremi}
\end{itemize}
Abbiamo quindi visto tre tipi di \textit{learner}:
\begin{enumerate}
  \item il \textbf{rote learner}, dove si ha classificazione sse $x$ corrisponde
  ad un esempio osservato precedentemente. Non si ha \textit{bias induttivo}
  \item l'algoritmo \textbf{candidare eliminate} con \textbf{version space},
  dove il \textit{bias} corrisponde al fatto che lo spazio delle ipotesi
  contiene il concetto target 
  \item l'algoritmo \textbf{Find-S}, dove il \textit{bias} corrisponde al fatto
  che lo spazio delle ipotesi contiene il concetto target e tutte le istanze
  sono negative a meno che il target opposto sia implicato in un altro modo 
\end{enumerate}
\section{Alberi decisionali}
Vediamo come sfruttare una struttura dati discreta, l'\textbf{albero di
  decisione}, per affrontare problemi di \textit{concept learning}. Su questa
struttura implementeremo l'algoritmo chiamato \textbf{ID3} che tra le ipotesi
sceglie il risultato dell'apprendimento tramite esempi di addestramento. La
lista delle ipotesi in questo caso è enorme e la scelta è guidata dal cosiddetto
\textit{information gain}.\\
Possiamo quindi scegliere, al posto delle classiche funzioni booleane,
\textbf{alberi di decisione} per rappresentare un modello che applicato ad
esempi non visti ci dirà se applicare in output un'etichetta vera o falsa in
base a quanto appreso. Siamo in ambito di \textbf{apprendimento
  supervisionato}.\\
Si hanno attributi che hanno anche più di due valori. Per ogni ipotesi si ha un
albero di decisione, come quello in figura \ref{dt}. In rosso si hanno gli
attributi, in blu i valori degli attributi e in arancione le foglie coi
risultati. Le foglie sono le risposte booleane.\\
\begin{figure}
  \centering
  \begin{tikzpicture}[nodes={draw}, --, sibling distance=70pt, level
      distance=30pt]  
      \node{\color{red} outlook}
      child { node {\color{blue} sunny}
        child{ node {\color{red} humidity}
          child{ node {\color{blue} high}
            child{ node {\color{orange} yes}}}
          child{ node {\color{blue} normal}
            child{ node {\color{orange} no}}}}}
      child { node {\color{blue} overcast}
        child { node {\color{orange} yes}}}
      child { node {\color{blue} rain}
        child{ node {\color{red} wind}
          child{ node {\color{blue} strong}
            child{ node {\color{orange} no}}}
          child{ node {\color{blue} weak}
            child{ node {\color{orange} yes}}}}};
    \end{tikzpicture}
  \caption{Esempio di albero decisionale}
  \label{dt}
\end{figure}
Avanzando nell'albero cerchiamo una risposta (che ci deve essere).\\
La flessibilità nella costruzione dell'albero sta nel scegliere gli attributi e
i valori di ognuno. Con l'algoritmo \textbf{ID3} si costruiscono alberi
decisionali in base alle istanze che ricevo (per avere un albero coerente con le
istanze ricevute).\\
Formule booleane possono essere rappresentate in un albero decisionale (figura
\ref{dt2} e figura \ref{dt3}), costruendo un albero che sia \textit{yes}
solo nei casi la formula booleana 
sia vera.
\begin{figure}[H]
  \centering
  \begin{tikzpicture}[nodes={draw}, --, sibling distance=70pt, level
    distance=30pt]  
    \node{\color{red} outlook}
    child { node {\color{blue} sunny}
      child{ node {\color{red} wind}
        child{ node {\color{blue} strong}
          child{ node {\color{orange} no}}}
        child{ node {\color{blue} weak}
          child{ node {\color{orange} yes}}}}}
    child { node {\color{blue} overcast}
      child { node {\color{orange} no}}}
    child { node {\color{blue} rain}
      child{ node {\color{orange} no}}};
  \end{tikzpicture}
  \caption{Esempio di albero decisionale per la formula $(Outlook=Sunny)\land
    (Wind=Weak)$} 
  \label{dt2}
\end{figure}
\begin{figure}[H]
  \centering
  \begin{tikzpicture}[nodes={draw}, --, sibling distance=70pt, level
    distance=30pt]  
    \node{\color{red} outlook}
    child { node {\color{blue} overcast}
      child{ node {\color{red} wind}
        child{ node {\color{blue} strong}
          child{ node {\color{orange} no}}}
        child{ node {\color{blue} weak}
          child{ node {\color{orange} yes}}}}}
    child { node {\color{blue} sunny}
      child{ node {\color{orange} yes}}}
    child { node {\color{blue} rain}
      child{ node {\color{red} wind}
        child{ node {\color{blue} strong}
          child{ node {\color{orange} no}}}
        child{ node {\color{blue} weak}
          child{ node {\color{orange} yes}}}}};
  \end{tikzpicture}
  \caption{Esempio di albero decisionale  per la formula $(Outlook=Sunny)\lor
    (Wind=Weak)$}
  \label{dt3}
\end{figure}
Notiamo a questo punto come l'albero decisionale in figura \ref{dt} è la
rappresentazione di:
\[(Outlook=Sunny\,\land\, Humidity=Normal)\]
\[\lor(Outlook=Overcast)\]
\[\lor(Outlook=Rain \land Wind=Weak) \] 
Possiamo dire che gli alberi decisionali descrivono tutte le funzioni
booleane. Avendo $n$ funzioni booleane avremo un numero distinto di tabelle di
verità (e quindi di alberi decisionali), ciascuna con $2^n$ righe, pari a
$2^{2^{n}}$.\\
Riassumiamo alcune caratteristiche degli alberi decisionali:
\begin{itemize}
  \item abbiamo attributi con valori discreti
  \item abbiamo un target di uscita discreto, le foglie hanno valori precisi
  \item posso costruire ipotesi anche con disgiunzioni
  \item può esserci ``rumore'' nel training dei dati
  \item possono esserci attributi di cui non ho informazioni
\end{itemize}
\subsection{Algoritmo ID3}
Vista la difficoltà di scegliere l'albero si ha l'idea di scegliere un piccolo
albero di partenza (o più piccoli) e ricorsivamente l'attributo più
significativo (sia nei nodi rossi intermedi che nelle foglie) come radice per il
sotto-albero. Si fanno quindi crescere in modo 
coerente gli alberi piccoli scelti in partenza. Si punta ad arrivare ad un
albero valido per tutti gli esempi ricevuti e anche per quelli non visti.\\
Iniziamo a vedere l'algoritmo anche se saranno necessarie molte specifiche:
\begin{algorithm}[H]
  \begin{algorithmic}
    \Function{ID3}{}
    \State $A \gets$ \textit{il ``miglior'' attributo di decisione per il
    prossimo nodo}
    \State \textit{assegno A come attributo di decisione per il nodo, che sarà
    rosso}
    \For {\textit{ogni valore dell'attributo A}}
    \State \textit{creo un discendente}
    \EndFor
    \State \textit{ordina gli esempi di training alla foglia}
    \State \textit{in base al valore dell'attributo del branch}
    \If {\textit{ho classificato tutti gli esempi di training}}
    \State \textit{mi fermo}
    \Else
    \State \textit{itero sulle foglie appena create}
    \EndFunction
  \end{algorithmic}
  \caption{Algoritmo ID3}
\end{algorithm}
Bisogna in primis capire cosa si intende come \textbf{attributo migliore}. Per
farlo introduciamo la seguente notazione:
\[[esempi\,\,\,positivi+,\,\,esempi\,\,\,negativi-]\]
entrambi rappresentati con un valore intero. Gli esempi positivi sono gli esempi
che già mi hanno restituito \textit{yes} mentre quelli negativi. In generale
sono tutti esempi su cui devo ancora valutare l'attributo. E proseguo così
assegnando etichette positive e negative.
Vediamo quanto detto:

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[nodes={draw}, --, sibling distance=70pt, level
    distance=30pt]  
    \node{\color{red} $A_1=\,?$ \color{black} [29+, 35-]}
    child { node {\color{blue} True}
      child{ node {\color{orange} [21+, 5-]}}}
    child { node {\color{blue} False}
      child{ node {\color{orange} [8+, 30-]}}};
  \end{tikzpicture}
\end{figure}

Se siamo nella situazione in cui dobbiamo confrontare l'attributo sopra con un
altro, per esempio:
\begin{figure}[H]
  \centering
  \begin{tikzpicture}[nodes={draw}, --, sibling distance=70pt, level
    distance=30pt]  
    \node{\color{red} $A_2=\,?$ \color{black} [29+, 35-]}
    child { node {\color{blue} True}
      child{ node {\color{orange} [18+, 33-]}}}
    child { node {\color{blue} False}
      child{ node {\color{orange} [11+, 2-]}}};
  \end{tikzpicture}
\end{figure}
Entrambe le foglie del primo attributi ci parlano di valori sbilanciati (tra
esempi positivi e negativi), a differenza delle due del secondo attributo, dove
sono una sbilanciata e una no. Per ora stabiliamo ad occhio lo sbilanciamento.\\
Il criterio di scelta ci porta a preferire lo sbilanciamento, verso un ideale
``tutti positivi'' o ``tutti negativi''. Quindi se un attributo ha divisioni
sbilanciate è da ritenersi migliore.\\ 
Per essere ancora più precisi bisogna richiamare la matematica
dell'\textbf{entropia}.
\begin{definizione}
  Dato un training set $S$ con valori $v_i,\,\,i=1\ldots n$. Se l'entropia di un
  insieme di bit misura più o meno la sua quantità di informazione (quanto è
  ``speciale'') noi possiamo richiamare una formula per l'entropia su S:
  \[I(P(v_1),\ldots,P(v_n))=\sum_{i=1}-P(v_i)\log_2P(v_i)\]
  Dove $I(x)$ indica il valore dell'entropia su $x$ e $P(y)$ sta per la
  probabilità legata ad un valore $y$.  \\
  Nel caso booleano le istanze presenti in un certo insieme $S$ sono associate
  ad un'etichetta, conteggiandole. Nella variabile $p$ conto i valori di $S$ con
  etichetta positiva e con $n$ negativa (esempi positivi e negativi). Ottengo
  quindi in modo esplicito la sommatoria:
  \[I\left(\frac{p}{p+n},\frac{n}{p+n}\right)=-\frac{p}{p+n}\log_2\frac{p}{p+n}
    -\frac{n}{p+n}\log_2\frac{n}{p+n}\]  
  Se inoltre diciamo che $p_+$ è la proporzione di esempi positivi e $p_-$ di
  quelli negativi (saranno quindi tra 0 e 1) possiamo misurare
  l'\textbf{impurità} di $S$ con l'entropia: 
  \[Entropy(S)=-p_+\log_2 p_+-p_-\log_2 p_-\]
  Avrò quindi alta entropia se positivi e negativi sono ``metà e metà''
\end{definizione}
Parliamo quindi di \textbf{information gain} $IG$ che viene calcolato su ogni
attributo $A$ e su $S$:
\[IG(S,A)=I\left(\frac{p}{p+n},\frac{n}{p+n}\right)-remainder(A)\]
dove:
\[remainder(A)=\sum_{i=1}^v \frac{p_i+n_i}{p+n}
  I\left(\frac{p_i}{p_i+n_i},\frac{n_i}{p_i+n_i}\right)\]
e quindi l'information gain è la riduzione aspettata nell'entropia per ordinare
$S$ sull'attributo $A$. Si sceglie l'attributo con il maggiore IG.\\
Possiamo riscrivere il conto come:
\[IG(S,A)=Entropy(S)-\sum_{v\in values(A)}\frac{|S_v|}{|S|}Entropy(S_v)\]
\begin{esempio}
  Vediamo l'esempio di calcolo di entropia di $A_1$ con [29+,35-]:
  \[Entropy([29+,35-])=
    -\frac{29}{64}\log_2\frac{29}{64}-\frac{35}{64}\log_2\frac{35}{64}=0.99\]
  Calcolo anche l'information gain di $A_1$, sapendo che
  $Entropy([21+,5-])=0.71$ e $Entropy([8+,30-])=0.74$,
  e quindi:
  \[IG(S,A_1)=0.99-\frac{26}{64}\cdot 0.71-\frac{38}{64}\cdot 0.74=0.27\]
  ugualmente calcolo $IG(S,A_2)=0.12$. \\
  Quindi so che devo scegliere $A_1$ in quanto $0.27 > 0.12$
\end{esempio}
Facciamo qualche osservazione finale sull'\textbf{algoritmo ID3}:
\begin{itemize}
  \item lo spazio delle ipotesi è completo e sicuramente contiene il target
  \item ho in output una singola ipotesi
  \item non si ha backtracking sugli attributi selezionati, si procede con una
  ricerca greedy (ma trovo scelte buone localmente e non ottime)
  \item fa scelte basate su una ricerca statistica, facendo sparire incertezze
  sui dati
  \item il bias non è sulla classe iniziale, essendo lo spazio delle ipotesi
  completo, ma sulla scelta di solo alcune funzioni, preferendo alberi corti (e
  più semplici) e posizionando attributi ad alto information gain vicino alla
  radice. Il bias è quindi sulla preferenza di alcune ipotesi. Si usa il
  criterio euristico di \textit{rasoio di Occam}
  \item $H$ è l'insieme potenza delle istanze $X$
\end{itemize}
Viene introdotto però l'\textbf{overfitting}. Se misuro l'errore di una ipotesi
$h$ sul training set ($error_{traini}(h)$) e poi misuro l'errore di quella
ipotesi sull'intero set delle possibili istanze
$D$ ($error_D(h)$) ho che l'ipotesi $h$ va in \textbf{overfit} sul quel data set
se:
\[error_{traini}(h) < error_{traini}(h') \,\,\land
  \,\,error_D(h)>error_D(h')\]
quindi se presa un'altra ipotesi questa è migliore della prima e ha un errore
sull'intera distribuzione delle ipotesi inferiore vado in \textit{overfit}. Il
problema è che non posso sapere se esiste tale $h'$. Per evitare il problema uso
sempre il rasoio di Occam scegliendo ipotesi semplici ed evitando di far
crescere l'albero quando lo ``split'' non è statisticamente significativo. Un
altro modo è quello di togliere pezzi, all'albero, che toccano poche istanze o
pure calcolare una \textit{misura di complessità dell'albero}, minimizzando la
grandezza dell'albero e gli errori del \textit{training set}, usando il
\textbf{Minimum Description Length (\textit{MDL})}
% \chapter{Reti neurali artificiali}
% I \textbf{neuroni} sono calcoli su valori reali. Ci si sposta quindi dagli spazi
% booleani (quindi discreti) del \textit{concept learning}. I neuroni accettano
% numeri reali sia in input che in output. Si aprono scenari di nuovi spazi
% applicativi grazie a questa capacità di manipolare dati reali. L'incertezza dei
% dati in ingresso è implicata dai numeri reali, comportando una maggior
% resistenza al rumore. Un neurone cerca di emulare il \textit{neurone biologico}.
% Si avrà una funzione con parametri che ne cambiano il comportamento ma questi
% parametri non saranno immediatamente intuibili come nel caso del \textit{concept
%   learning}.\\
% % aggiungere descrizione biologica
% I parametri, in una corrispondenza biologica, sono pesi legati alle
% sinapsi. Questi pesi \textbf{eccitano} il neurone.
% Si avranno anche dei pesi in uscita, un neurone \textbf{inibito} non invia
% segnali.\\
% Bisogna formalizzare il neurone.

\end{document} 

% LocalWords:  Machine Learning machine learning dataset fit overfitting sse 
% LocalWords:  Concept concept experience learner rewards inductive validation
% LocalWords:  find Find findS version List biased Hypothesis unbiased bias yes
% LocalWords:  bias prover information gain slide level sibling distance wind
% LocalWords:  weak outlook sunny humidity high normal overcast rain branch IG
% LocalWords:  primis True backtracking greedy overfit split Description Length
% LocalWords:  cloudy rainy warm cold sky temp humid forecast same change Venn
% LocalWords:  darkgreen list then example label dell
