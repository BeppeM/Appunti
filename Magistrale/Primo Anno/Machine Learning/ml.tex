\documentclass[a4paper,12pt, oneside]{book}

% \usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{engrec}
\usepackage{rotating}
\usepackage{verbatim}
\usepackage[safe,extra]{tipa}
\usepackage{showkeys}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{fontspec}
\usepackage{enumerate}
\usepackage{braket}
\usepackage{marginnote}
\usepackage{pgfplots}
\usepackage{cancel}
\usepackage{polynom}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage[cache=false]{minted}
\usepackage{mathtools}
\usepackage[noend]{algpseudocode}

\usepackage{tikz}\usetikzlibrary{er}\tikzset{multi  attribute /.style={attribute
    ,double  distance =1.5pt}}\tikzset{derived  attribute /.style={attribute
    ,dashed}}\tikzset{total /.style={double  distance =1.5pt}}\tikzset{every
  entity /.style={draw=orange , fill=orange!20}}\tikzset{every  attribute
  /.style={draw=MediumPurple1, fill=MediumPurple1!20}}\tikzset{every
  relationship /.style={draw=Chartreuse2,
    fill=Chartreuse2!20}}\newcommand{\key}[1]{\underline{#1}}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{decorations.markings}
  \usetikzlibrary{arrows,shapes,backgrounds,petri}
\tikzset{
  place/.style={
        circle,
        thick,
        draw=black,
        minimum size=6mm,
    },
  transition/.style={
    rectangle,
    thick,
    fill=black,
    minimum width=8mm,
    inner ysep=2pt
  },
  transitionv/.style={
    rectangle,
    thick,
    fill=black,
    minimum height=8mm,
    inner xsep=2pt
    }
  } 
\usetikzlibrary{automata,positioning}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}
\fancyfoot[C]{\thepage}


\title{Machine Learning}
\author{UniShare\\\\Davide Cozzi\\\href{https://t.me/dlcgold}{@dlcgold}}
\date{}

\pgfplotsset{compat=1.13}
\begin{document}
\maketitle

\definecolor{shadecolor}{gray}{0.80}
\setlist{leftmargin = 2cm}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}
\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}
\tableofcontents
\renewcommand{\chaptermark}[1]{%
  \markboth{\chaptername
    \ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}%
\chapter{Introduzione}
\textbf{Questi appunti sono presi a lezione. Per quanto sia stata fatta
  una revisione è altamente probabile (praticamente certo) che possano
  contenere errori, sia di stampa che di vero e proprio contenuto. Per
  eventuali proposte di correzione effettuare una pull request. Link: }
\url{https://github.com/dlcgold/Appunti}.\\
\chapter{Introduzione al ML}
Il \textbf{Machine Learning (\textit{ML})} è sempre più diffuso nonostante sia
nato diversi anni fa.\\
Un \textbf{sistema di apprendimento automatico} ricava da un \textit{dataset}
una conoscenza non fornita a priori, descrivendo dati non forniti in
precedenza. Si estrapolano informazioni facendo assunzioni sulle informazioni
sistema già conosciute, creando una \textbf{classe delle ipotesi H}. Si cercano
ipotesi coerenti per guidare il sistema di apprendimento automatico. Bisogna
però mettere in conto anche eventuali errori, cercando di capire se esiste
davvero un'ipotesi coerente e, in caso di assenza, si cerca di approssimare. In
quest'ottica bisogna mediare tra \textbf{fit} e \textbf{complessità}. Ogni
sistema dovrà cercare di mediare tra questi due aspetti, un \textit{fit}
migliore comporta alta \textit{complessità}. Si ha sempre il rischio di
\textbf{overfitting}, cercando una precisione dei dati che magari non esiste. Si
ha un \textbf{generatore di dati} ma il sistema non ha conoscenza della totalità
degli stessi.\\
Durante l'\textbf{apprendimento} si estrapolano dati da \textbf{istanze di
  addestramento o test}. Quindi:
\begin{itemize}
  \item si ricevono i dati di addestramento
  \item il sistema impara ad estrapolare partendo da quei dati
  \item si ricevono dati di test su cui si estrapola
\end{itemize}
L'ipotesi da apprendere viene chiamata \textbf{concetto target} (tra tutte le
ipotesi possibili identifico quella giusta dai dati di addestramento).\\
Si hanno tre tipi di apprendimento:
\begin{enumerate}
  \item \textbf{apprendimento supervisionato}, con un \textit{insegnante} che
  comunica  l'output corretto
  \item \textbf{apprendimento non supervisionato}, dove si riconosce
  \textit{schemi} nell'input senza indicazioni sui valori in uscita. Questo tipo
  si basa sui \textit{cluster}. Non c'è target
  \item \textbf{apprendimento per rinforzo}, dove bisogna apprendere sulla base
  della risposta dell’ambiente alle proprie azioni. Si lavora in \textit{modo
    continuo}, aggiornando le ipotesi con l'arrivo dei dati
\end{enumerate}
\section{Concept learning}
In questo settore il dato è un vettore booleano e il dato che viene richiesto in
output è anch'esso un booleano. Il target dell'addestramento
\end{document}

% LocalWords:  Machine Learning machine learning dataset fit overfitting
% LocalWords:  Concept
