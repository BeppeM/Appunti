\documentclass[a4paper,12pt, oneside]{book}

% \usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{engrec}
\usepackage{rotating}
\usepackage{verbatim}
\usepackage[safe,extra]{tipa}
%\usepackage{showkeys}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{fontspec}
\usepackage{enumerate}
\usepackage{physics}
\usepackage{braket}
\usepackage{marginnote}
\usepackage{pgfplots}
\usepackage{cancel}
\usepackage{polynom}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage[cache=false]{minted}
\usepackage{mathtools}
\usepackage[noend]{algpseudocode}

\usepackage{tikz}\usetikzlibrary{er}\tikzset{multi  attribute /.style={attribute
    ,double  distance =1.5pt}}\tikzset{derived  attribute /.style={attribute
    ,dashed}}\tikzset{total /.style={double  distance =1.5pt}}\tikzset{every
  entity /.style={draw=orange , fill=orange!20}}\tikzset{every  attribute
  /.style={draw=MediumPurple1, fill=MediumPurple1!20}}\tikzset{every
  relationship /.style={draw=Chartreuse2,
    fill=Chartreuse2!20}}\newcommand{\key}[1]{\underline{#1}}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{decorations.markings}
  \usetikzlibrary{arrows,shapes,backgrounds,petri}
\tikzset{
  place/.style={
        circle,
        thick,
        draw=black,
        minimum size=6mm,
    },
  transition/.style={
    rectangle,
    thick,
    fill=black,
    minimum width=8mm,
    inner ysep=2pt
  },
  transitionv/.style={
    rectangle,
    thick,
    fill=black,
    minimum height=8mm,
    inner xsep=2pt
    }
  } 
\usetikzlibrary{automata,positioning,chains,fit,shapes}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}
\fancyfoot[C]{\thepage}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{epsfig}
\usepackage{pst-grad} % For gradients
\usepackage{pst-plot} % For axes
\usepackage[space]{grffile} % For spaces in paths
\usepackage{etoolbox} % For spaces in paths
\makeatletter % For spaces in paths
\patchcmd\Gread@eps{\@inputcheck#1 }{\@inputcheck"#1"\relax}{}{}
\makeatother

\title{Modelli Probabilistici per le Decisioni}
\author{UniShare\\\\Davide Cozzi\\\href{https://t.me/dlcgold}{@dlcgold}}
\date{}

\pgfplotsset{compat=1.13}
\begin{document}
\maketitle

\definecolor{shadecolor}{gray}{0.80}
\setlist{leftmargin = 2cm}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}
\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}
\tableofcontents
\renewcommand{\chaptermark}[1]{%
  \markboth{\chaptername
    \ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}%
\chapter{Introduzione}
\textbf{Questi appunti sono presi a lezione. Per quanto sia stata fatta
  una revisione è altamente probabile (praticamente certo) che possano
  contenere errori, sia di stampa che di vero e proprio contenuto. Per
  eventuali proposte di correzione effettuare una pull request. Link: }
\url{https://github.com/dlcgold/Appunti}.\\
\chapter{Ripasso di Probabilità}
Riprendiamo qualche definizione.
\begin{definizione}
  Definiamo \textbf{variabile casuale} come un'osservazione, un esito o un
  evento il cui valore è incerto.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{dominio o spazio degli eventi} come l'insieme dei possibili
  valore che può assumere una variabile casuale.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{spazio di probabilità o modello di probabilità} come uno
  spazio degli eventi corredato da un assegnamento:
  \[P(\omega),\omega\in \Omega\]
  tale che:
  \begin{itemize}
    \item $0\leq P(\omega)\leq 1$
    \item $\sum_\omega p(\omega)=1$
  \end{itemize}
  con $omega$ evento e $\Omega$ spazio degli eventi.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{evento atomico o campione} una specificazione completa del
  calore delle variabili casuali di interesse.\\
  L'insieme di tutti i possibili eventi atomici è:
  \begin{itemize}
    \item mutualmente esaustivo (non potendo accadere altro)
    \item mutualmente esclusivo (può accadere solo un evento atomico di quelli
    possibili) 
  \end{itemize}
\end{definizione}
\begin{definizione}
  Definiamo un \textbf{evento} (non atomico) $A$ può essere un qualunque
  sottoinsieme di $\Omega$ tale che: 
  \[P(A)=\sum_{\omega\in A}P(\omega)\]
\end{definizione}
\begin{definizione}
  Definiamo una \textbf{variabile aleatoria} è una variabile che può assumere
  diversi valori in corrispondenza di altrettanti eventi che costituiscono una
  partizione dello spazio delle probabilità.
\end{definizione}

Si ricorda che, per una variabile $a$ e una $b$:
\begin{itemize}
  \item $0\leq P(a)\leq 1$
  \item $P(\top)=1$ e $P(\bot) =0$
  \item $P(a\lor b) = P(a)+p(b) -p(a\land b)$
\end{itemize}
\begin{definizione}
  Definiamo una \textbf{probabilità condizionata} rappresenta la verosimiglianza
  che un evento $a$ si verifichi se $b$ si verifica e si denota con:
  \[P(a|b)\]
  Si ha quindi la specifica che alcuni eventi rendono altri eventi più o meno
  verosimili.\\
  Si parla quindi di eventi \textbf{dipendenti}.
\end{definizione}
\begin{definizione}
  Due eventi sono \textbf{indipendenti} se un evento non influisce sulla
  realizzazione dell'altro:
  \[P(a|b)=P(a)\]
\end{definizione}
Si ha quindi la seguente regola.
\begin{teorema}[Regola del prodotto]
  Possiamo calcolare che due eventi si verifichino contemporaneamente tramite la
  probabilità condizionata e quella dei singoli eventi:
  \[P(a,b)=P(a\land b)=P(a|b)P(b)=P(b|a)P(a)\]
  Con $P(a,b)=P(a\land b)$ è detta \textbf{probabilità congiunta} (``='' perché
  sono due modi per scriverla).
\end{teorema}
Posso fare la tabella dei vari eventi condizionati.
\begin{teorema}[Regola della somma]
  Si ha che, avendo la tabella degli eventi:
  \[P(x)=\sum_y P(x,y)\]
  con $P(x)$ detta \textbf{probabilità marginale}.
\end{teorema}
La somma di tutte le possibili combinazioni di eventi, quindi dei valori della
tabella, deve dare 1.\\ 
\textbf{Su slide esempio di uso di quanto detto, dove si arriva al teorema di
  Bayes}.\\
Si vuole infatti passare dal conoscere $P(a|b)$ al consocere $P(b|a)$.
\begin{teorema}[Teorema di Bayes]
  Il teorema enuncia che:
  \[P(h|D)=\frac{P(D|h)P(h)}{P(D)}\]
  Avendo:
  \begin{itemize}
    \item $P(h)$ che è la probabilità conosciuta a priori di $h$. Tale
    probabilità riflette qualsiasi conoscenza di base sulla possibilità
    che $h$ sia corretta  
    \item $P(D)$ che è la probabilità conosciuta a priori di $D$, ovvero la
    probabilità che $D$ sia osservato
    \item $P(D|h)$ che è la probabilità di osservare $D$ in presenza
    dell'ipotesi $h$
    \item $P(D|h)$ che è la probabilità a posteriori di $h$. Tale probabilità
    riflette la ``confidenza'' di avere $h$  dopo che $D$ è stato osservato
  \end{itemize}
\end{teorema}
In altri termini, avendo:
\[P(a\land b)=P(a|b)P(b)=P(b|a)P(a)\]
ho che:
\[P(a|b)P(b)=P(b|a)P(a)\]
arrivando a dire che:
\[P(a|b)=\frac{P(b|a)P(a)}{P(b)}\]
\textbf{notando la correlazione tra probabilità congiunta e Bayes}.\\
Che è il punto fondamentale della moderna teoria dell'intelligenza artificiale
in quanto permette di raccogliere l'evidenza senza poi usare le tabelle delle
probabilità congiunte, che sarebbero difficilissimi da osservare.
Se pensiamo ad alcuni eventi come cause ``nascoste'' non necessariamente
osservabili se modelliamo la verosimiglianza degli eventi osservabili date le
cause nascoste si ha:
\[P(causa|effetto)=\frac{P(effetto|causa)P(causa)}{P(effetto)}\]
Si ha quindi un modello per inferire/derivare la verosimiglianza della causa
nascosta e quindi rispondendo a:
\[P(causa|effetto)\]
Avendo quindi la probabilità di una causa dato un effetto.
\textit{Dato l'effetto modello la causa}.\\
Se non si ha una delle due probabilità a priori posso stimare per poi
normalizzare. In altri termini il denominatore $P(D)$ è spesso solo una quantità
di normalizzazione, essendo spesso difficile da stimare. 


\chapter{Modelli Probabilistici}
Nel passato si sono usati \textbf{sistemi a regole}, dove codificando tutto
quello che può succedere si cercava di giungere ad una decisione. Questo però
era molto dispendioso, si arrivava o a vero a falso, senza via di mezzo, e si
dovevano avere dati ipoteticamente completi e sicuri in partenza. Si parla in
questo caso di \textbf{modelli logici}.\\
Viviamo in un'era dove si hanno molti dati, sia in ambito sociale, che di
business che scientifico. Questi dati devono essere analizzati al fine di poter
prendere \textbf{decisioni} e per farlo si deve per capire la situazione in cui
ci si trova e spesso posso capirlo solo osservando i dati, non osservando la
variabile specifica. Dalle osservazioni dobbiamo inferire il valore di variabili
``nascoste''. Spesso si ha a che fare con dati non completi, non consistenti,
spesso errati, con rumore di trasmissione etc$\ldots$\\
Tali dati sono comunque
evidenze per percepire la situazione in cui ci si trova. L'obiettivo del corso è
fornire strumenti modellistici per rappresentare l'incertezza nel modello,
incertezza per struttura e parametri, e per rappresentare in termini
probabilistici gli errori nei dati. Si vuole quindi implementare algoritmi di
``ragionamento'', automatizzati e adattivi, oltre che robusti e scalabili.\\
I \textbf{modelli probabilistici} sono anche detti \textbf{modelli
  generativi}. Si usa la teoria delle probabilità per esprimere incertezza e
rumore associati al modello e ai dati, soprattutto usando la teoria Bayesana,
per fare previsione e adattare i modelli. Questi modelli permettono di partire
da una ``credenza'' iniziale, anche soggettiva, per poi raccogliere evidenze
aggiustando tale modello.\\
I modelli probabilistici sono anche modelli di machine learning, in quanto
apprendono.\\
Bisogna quindi partire dalle osservazioni generate rispetto ad un valore di
variabile per poi inferire tale variabile (ad esempio parto dai risultati di un
gioco per capire quando è bravo il giocatore, che non è una variabile che posso
sapere a priori). Si parte dai dati e si arriva al
valore della variabile che ha generato questi dati (per questo \textit{modello
  generativo}). Man mano che raccolgo informazioni raffino il modello, più o
meno come fa un essere umano (``più rispondi alle domande all'orale e più il
docente capisce il tuo voto, anche se alla fine non si ha la certezza che il
voto rispecchi la preparazione''). I dati possono non portare alla certezza, ma
più dati si hanno e più ci si avvicina, riducendo l'incertezza.\\
Un esempio pratico è il modello \textbf{Elo} (nato per gli scacchi) da cui
deriva quello usato da \textit{Xbox} per capire come appaiare giocatori online
in base alle skill. Il valore di bravura viene rappresentato come una
distribuzione, in primis con una Gaussiana, con una certa media e una certa
varianza/deviazione standard, quindi solo due numeri. Cambiare il modello
significa solo cambiare quei due valori. Per confrontare due giocatori capisco
la distribuzione a partire dai dati del giocatore che si hanno, diminuendo
l'incertezza all'aumentare dei dati. Con il modello probabilistico poi, a
partire dal risultato modificherò le distribuzioni di partenza, cambiando la
percezione su essi. Nel tempo posso tenere aggiornato i modelli probabilistici
che rappresentano una certa variabile e usarli per fare confronti (ad esempio
confrontando due giocatori per poi fare l'appaiamento).\\
Con i modelli probabilistici si ha una capacità espressiva maggiore di quella di
un modello logico, avendo le distribuzioni di probabilità e potendo anche usare
varie soglie.\\
Un \textit{modello generativ}o parte dalle probabilità a priori e può
``generare'' possibili eventi, generando campioni verosimili con una certa
distribuzione statistica. \\
Nella vita reale si osservano degli accadimenti e studiandoli si può risalire
alla probabilità degli eventi, tramite l'approccio frequentista.
\section{Incertezza}
Si introduce quindi l'\textbf{incertezza}. Non sempre si ha a che fare con dati
``certi'' e precisi, che possono portare con più facilità ad una certa
decisione, potendo giungere ad una decisione \textbf{ottimale} senza alcun
dubbio su quale essa sia.\\
Con l'\textbf{incertezza} sui dati bisogna modificare l'idea di
\textbf{soluzione ottimale}. Si arriva a dover capire quale sia la
\textbf{soluzione ottima} in un contesto dove ``non si sa cosa succederà'',
partendo da dati incerti.\\
Si ha che:
\begin{itemize}
  \item un evento osservato può avere molte cause
  \item la verosimiglianza di un'ipotesi sulla causa cambia man mano che si
  raccolgono pezzi di evidenza
  \item usando modelli probabilistici di ragionamento possiamo calcolare quanto
  probabile è una certa ipotesi. Si ipotizza che le fonti di incertezza siano
  quantificabili
\end{itemize}
\textbf{\textit{Vari esempi di vita in merito sulle slide.}}\\
Spesso si ha un approccio ``frequentista'', valutando la frequenza di un evento
per capire la probabilità che tale evento accada, inferendo così una
distribuzione di probabilità dalla frequenza con la quale si osservano i
dati. Questo è piuù o meno come funziona il cervello umano ma bisogna fare la
stessa cosa con un calcolatore e per questo ci verrà incontro il \textbf{teorema
  di Bayes}.\\
Si ha inoltre che un sistema che considera anche l'incertezza, che è presente in
moltissime situazioni, dovrebbe funzionare meglio di uno che non lo fa ma ci
serve in primis un modo per rappresentare l'incertezza stessa. \\
Più parametri ha il modello e più è difficile rappresentarlo.\\
Si ha il \textbf{Degree of Belief} che è una probabilità a priori sono ricavate
da:
\begin{itemize}
  \item osservazioni statistiche
  \item regole generali e conosciute
  \item combinazioni di sorgenti di evidenza
\end{itemize}
In ogni caso si hanno quindi evidenze empiriche.\\
\end{document}  
% LocalWords:  clock  Bayesana machine learning Bayes
