\documentclass[a4paper,12pt, oneside]{book}

% \usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{engrec}
\usepackage{rotating}
\usepackage{verbatim}
\usepackage[safe,extra]{tipa}
%\usepackage{showkeys}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{fontspec}
\usepackage{enumerate}
\usepackage{physics}
\usepackage{braket}
\usepackage{marginnote}
\usepackage{pgfplots}
\usepackage{cancel}
\usepackage{polynom}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage[cache=false]{minted}
\usepackage{mathtools}
\usepackage[noend]{algpseudocode}

\usepackage{tikz}\usetikzlibrary{er}\tikzset{multi  attribute /.style={attribute
    ,double  distance =1.5pt}}\tikzset{derived  attribute /.style={attribute
    ,dashed}}\tikzset{total /.style={double  distance =1.5pt}}\tikzset{every
  entity /.style={draw=orange , fill=orange!20}}\tikzset{every  attribute
  /.style={draw=MediumPurple1, fill=MediumPurple1!20}}\tikzset{every
  relationship /.style={draw=Chartreuse2,
    fill=Chartreuse2!20}}\newcommand{\key}[1]{\underline{#1}}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{decorations.markings}
  \usetikzlibrary{arrows,shapes,backgrounds,petri}
\tikzset{
  place/.style={
        circle,
        thick,
        draw=black,
        minimum size=6mm,
    },
  transition/.style={
    rectangle,
    thick,
    fill=black,
    minimum width=8mm,
    inner ysep=2pt
  },
  transitionv/.style={
    rectangle,
    thick,
    fill=black,
    minimum height=8mm,
    inner xsep=2pt
    }
  } 
\usetikzlibrary{automata,positioning,chains,fit,shapes}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}
\fancyfoot[C]{\thepage}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{epsfig}
\usepackage{pst-grad} % For gradients
\usepackage{pst-plot} % For axes
\usepackage[space]{grffile} % For spaces in paths
\usepackage{etoolbox} % For spaces in paths
\makeatletter % For spaces in paths
\patchcmd\Gread@eps{\@inputcheck#1 }{\@inputcheck"#1"\relax}{}{}
\makeatother

\title{Modelli Probabilistici per le Decisioni}
\author{UniShare\\\\Davide Cozzi\\\href{https://t.me/dlcgold}{@dlcgold}}
\date{}

\pgfplotsset{compat=1.13}
\begin{document}
\maketitle

\definecolor{shadecolor}{gray}{0.80}
\setlist{leftmargin = 2cm}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}
\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}
\tableofcontents
\renewcommand{\chaptermark}[1]{%
  \markboth{\chaptername
    \ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}%
\chapter{Introduzione}
\textbf{Questi appunti sono presi a lezione. Per quanto sia stata fatta
  una revisione è altamente probabile (praticamente certo) che possano
  contenere errori, sia di stampa che di vero e proprio contenuto. Per
  eventuali proposte di correzione effettuare una pull request. Link: }
\url{https://github.com/dlcgold/Appunti}.\\
\chapter{Ripasso di Probabilità}
Riprendiamo qualche definizione.
\begin{definizione}
  Definiamo \textbf{variabile casuale} come un'osservazione, un esito o un
  evento il cui valore è incerto.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{dominio o spazio degli eventi} come l'insieme dei possibili
  valore che può assumere una variabile casuale.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{spazio di probabilità o modello di probabilità} come uno
  spazio degli eventi corredato da un assegnamento:
  \[P(\omega),\omega\in \Omega\]
  tale che:
  \begin{itemize}
    \item $0\leq P(\omega)\leq 1$
    \item $\sum_\omega p(\omega)=1$
  \end{itemize}
  con $omega$ evento e $\Omega$ spazio degli eventi.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{evento atomico o campione} una specificazione completa del
  calore delle variabili casuali di interesse.\\
  L'insieme di tutti i possibili eventi atomici è:
  \begin{itemize}
    \item mutualmente esaustivo (non potendo accadere altro)
    \item mutualmente esclusivo (può accadere solo un evento atomico di quelli
    possibili) 
  \end{itemize}
\end{definizione}
\begin{definizione}
  Definiamo un \textbf{evento} (non atomico) $A$ può essere un qualunque
  sottoinsieme di $\Omega$ tale che: 
  \[P(A)=\sum_{\omega\in A}P(\omega)\]
\end{definizione}
\begin{definizione}
  Definiamo una \textbf{variabile aleatoria} è una variabile che può assumere
  diversi valori in corrispondenza di altrettanti eventi che costituiscono una
  partizione dello spazio delle probabilità.
\end{definizione}

Si ricorda che, per una variabile $a$ e una $b$:
\begin{itemize}
  \item $0\leq P(a)\leq 1$
  \item $P(\top)=1$ e $P(\bot) =0$
  \item $P(a\lor b) = P(a)+p(b) -p(a\land b)$
\end{itemize}
\begin{definizione}
  Definiamo una \textbf{probabilità condizionata} rappresenta la verosimiglianza
  che un evento $a$ si verifichi se $b$ si verifica e si denota con:
  \[P(a|b)\]
  Si ha quindi la specifica che alcuni eventi rendono altri eventi più o meno
  verosimili.\\
  Si parla quindi di eventi \textbf{dipendenti}.
\end{definizione}
\begin{definizione}
  Due eventi sono \textbf{indipendenti} se un evento non influisce sulla
  realizzazione dell'altro:
  \[P(a|b)=P(a)\]
\end{definizione}
Si ha quindi la seguente regola.
\begin{teorema}[Regola del prodotto]
  Possiamo calcolare che due eventi si verifichino contemporaneamente tramite la
  probabilità condizionata e quella dei singoli eventi:
  \[P(a,b)=P(a\land b)=P(a|b)P(b)=P(b|a)P(a)\]
  Con $P(a,b)=P(a\land b)$ è detta \textbf{probabilità congiunta} (``='' perché
  sono due modi per scriverla).
\end{teorema}
Posso fare la tabella dei vari eventi condizionati.
\begin{teorema}[Regola della somma]
  Si ha che, avendo la tabella degli eventi:
  \[P(x)=\sum_y P(x,y)\]
  con $P(x)$ detta \textbf{probabilità marginale}.
\end{teorema}
La somma di tutte le possibili combinazioni di eventi, quindi dei valori della
tabella, deve dare 1.\\ 
\textbf{Su slide esempio di uso di quanto detto, dove si arriva al teorema di
  Bayes}.\\
Si vuole infatti passare dal conoscere $P(a|b)$ al consocere $P(b|a)$.
\begin{teorema}[Teorema di Bayes]
  Il teorema enuncia che:
  \[P(h|D)=\frac{P(D|h)P(h)}{P(D)}\]
  Avendo:
  \begin{itemize}
    \item $P(h)$ che è la probabilità conosciuta a priori di $h$. Tale
    probabilità riflette qualsiasi conoscenza di base sulla possibilità
    che $h$ sia corretta  
    \item $P(D)$ che è la probabilità conosciuta a priori di $D$, ovvero la
    probabilità che $D$ sia osservato
    \item $P(D|h)$ che è la probabilità di osservare $D$ in presenza
    dell'ipotesi $h$
    \item $P(D|h)$ che è la probabilità a posteriori di $h$. Tale probabilità
    riflette la ``confidenza'' di avere $h$  dopo che $D$ è stato osservato
  \end{itemize}
\end{teorema}
In altri termini, avendo:
\[P(a\land b)=P(a|b)P(b)=P(b|a)P(a)\]
ho che:
\[P(a|b)P(b)=P(b|a)P(a)\]
arrivando a dire che:
\[P(a|b)=\frac{P(b|a)P(a)}{P(b)}\]
\textbf{notando la correlazione tra probabilità congiunta e Bayes}.\\
Che è il punto fondamentale della moderna teoria dell'intelligenza artificiale
in quanto permette di raccogliere l'evidenza senza poi usare le tabelle delle
probabilità congiunte, che sarebbero difficilissimi da osservare.
Se pensiamo ad alcuni eventi come cause ``nascoste'' non necessariamente
osservabili se modelliamo la verosimiglianza degli eventi osservabili date le
cause nascoste si ha:
\[P(causa|effetto)=\frac{P(effetto|causa)P(causa)}{P(effetto)}\]
Si ha quindi un modello per inferire/derivare la verosimiglianza della causa
nascosta e quindi rispondendo a:
\[P(causa|effetto)\]
Avendo quindi la probabilità di una causa dato un effetto.
\textit{Dato l'effetto modello la causa}.\\
Se non si ha una delle due probabilità a priori posso stimare per poi
normalizzare. In altri termini il denominatore $P(D)$ è spesso solo una quantità
di normalizzazione, essendo spesso difficile da stimare. \\
Le probabilità possono essere definite su due approcci:
\begin{itemize}
  \item \textbf{approccio frequentista o oggettivista} che considera la
  probabilità come un'entità misurabile legata alla frequenza di accadimento,
  come si fa ne machine learning
  \item \textbf{approccio soggettivista} che considera la
  probabilità come una misura del grado di attesa soggettivo del verificarsi di
  un evento, come si fa nel corso di statistica
\end{itemize}

\chapter{Modelli Probabilistici}
Nel passato si sono usati \textbf{sistemi a regole}, dove codificando tutto
quello che può succedere si cercava di giungere ad una decisione. Questo però
era molto dispendioso, si arrivava o a vero a falso, senza via di mezzo, e si
dovevano avere dati ipoteticamente completi e sicuri in partenza. Si parla in
questo caso di \textbf{modelli logici}.\\
Viviamo in un'era dove si hanno molti dati, sia in ambito sociale, che di
business che scientifico. Questi dati devono essere analizzati al fine di poter
prendere \textbf{decisioni} e per farlo si deve per capire la situazione in cui
ci si trova e spesso posso capirlo solo osservando i dati, non osservando la
variabile specifica. Dalle osservazioni dobbiamo inferire il valore di variabili
``nascoste''. Spesso si ha a che fare con dati non completi, non consistenti,
spesso errati, con rumore di trasmissione etc$\ldots$\\
Tali dati sono comunque
evidenze per percepire la situazione in cui ci si trova. L'obiettivo del corso è
fornire strumenti modellistici per rappresentare l'incertezza nel modello,
incertezza per struttura e parametri, e per rappresentare in termini
probabilistici gli errori nei dati. Si vuole quindi implementare algoritmi di
``ragionamento'', automatizzati e adattivi, oltre che robusti e scalabili.\\
I \textbf{modelli probabilistici} sono anche detti \textbf{modelli
  generativi}. Si usa la teoria delle probabilità per esprimere incertezza e
rumore associati al modello e ai dati, soprattutto usando la teoria Bayesana,
per fare previsione e adattare i modelli. Questi modelli permettono di partire
da una ``credenza'' iniziale, anche soggettiva, per poi raccogliere evidenze
aggiustando tale modello.\\
I modelli probabilistici sono anche modelli di machine learning, in quanto
apprendono.\\
Bisogna quindi partire dalle osservazioni generate rispetto ad un valore di
variabile per poi inferire tale variabile (ad esempio parto dai risultati di un
gioco per capire quando è bravo il giocatore, che non è una variabile che posso
sapere a priori). Si parte dai dati e si arriva al
valore della variabile che ha generato questi dati (per questo \textit{modello
  generativo}). Man mano che raccolgo informazioni raffino il modello, più o
meno come fa un essere umano (``più rispondi alle domande all'orale e più il
docente capisce il tuo voto, anche se alla fine non si ha la certezza che il
voto rispecchi la preparazione''). I dati possono non portare alla certezza, ma
più dati si hanno e più ci si avvicina, riducendo l'incertezza.\\
Un esempio pratico è il modello \textbf{Elo} (nato per gli scacchi) da cui
deriva quello usato da \textit{Xbox} per capire come appaiare giocatori online
in base alle skill. Il valore di bravura viene rappresentato come una
distribuzione, in primis con una Gaussiana, con una certa media e una certa
varianza/deviazione standard, quindi solo due numeri. Cambiare il modello
significa solo cambiare quei due valori. Per confrontare due giocatori capisco
la distribuzione a partire dai dati del giocatore che si hanno, diminuendo
l'incertezza all'aumentare dei dati. Con il modello probabilistico poi, a
partire dal risultato modificherò le distribuzioni di partenza, cambiando la
percezione su essi. Nel tempo posso tenere aggiornato i modelli probabilistici
che rappresentano una certa variabile e usarli per fare confronti (ad esempio
confrontando due giocatori per poi fare l'appaiamento).\\
Con i modelli probabilistici si ha una capacità espressiva maggiore di quella di
un modello logico, avendo le distribuzioni di probabilità e potendo anche usare
varie soglie.\\
Un \textit{modello generativ}o parte dalle probabilità a priori e può
``generare'' possibili eventi, generando campioni verosimili con una certa
distribuzione statistica. \\
Nella vita reale si osservano degli accadimenti e studiandoli si può risalire
alla probabilità degli eventi, tramite l'approccio frequentista.
\section{Incertezza}
Si introduce quindi l'\textbf{incertezza}. Non sempre si ha a che fare con dati
``certi'' e precisi, che possono portare con più facilità ad una certa
decisione, potendo giungere ad una decisione \textbf{ottimale} senza alcun
dubbio su quale essa sia.\\
Con l'\textbf{incertezza} sui dati bisogna modificare l'idea di
\textbf{soluzione ottimale}. Si arriva a dover capire quale sia la
\textbf{soluzione ottima} in un contesto dove ``non si sa cosa succederà'',
partendo da dati incerti.\\
Si ha che:
\begin{itemize}
  \item un evento osservato può avere molte cause
  \item la verosimiglianza di un'ipotesi sulla causa cambia man mano che si
  raccolgono pezzi di evidenza
  \item usando modelli probabilistici di ragionamento possiamo calcolare quanto
  probabile è una certa ipotesi. Si ipotizza che le fonti di incertezza siano
  quantificabili
\end{itemize}
\textbf{\textit{Vari esempi di vita in merito sulle slide.}}\\
Spesso si ha un approccio ``frequentista'', valutando la frequenza di un evento
per capire la probabilità che tale evento accada, inferendo così una
distribuzione di probabilità dalla frequenza con la quale si osservano i
dati. Questo è piuù o meno come funziona il cervello umano ma bisogna fare la
stessa cosa con un calcolatore e per questo ci verrà incontro il \textbf{teorema
  di Bayes}.\\
Si ha inoltre che un sistema che considera anche l'incertezza, che è presente in
moltissime situazioni, dovrebbe funzionare meglio di uno che non lo fa ma ci
serve in primis un modo per rappresentare l'incertezza stessa. \\
Più parametri ha il modello e più è difficile rappresentarlo.\\
Si ha il \textbf{Degree of Belief} che è una probabilità a priori sono ricavate
da:
\begin{itemize}
  \item osservazioni statistiche
  \item regole generali e conosciute
  \item combinazioni di sorgenti di evidenza
\end{itemize}
In ogni caso si hanno quindi evidenze empiriche.\\
Vediamo ora il rapporto tra i \textbf{modelli causali} e la \textbf{regola di
  Bayes}.\\
Ricordiamo che per Bayes si ha:
\[P(causa|effetto)=\frac{P(effetto|causa)P(causa)}{P(effetto)}\]
Con le reti causali vorremmo risalire dall'effetto alla causa ma normalmente si
hanno più informazioni su $P(causa|effetto)$ che su $P(effetto|causa)$.\\
Conoscendo $P(effetto|causa)$ per ogni causa posso evitare di calcolare
$P(effetto)$, infatti, dato $c=causa$ ed $e=effeto$:
\[P(c|e)=\frac{P(e|c)P(c)}{P(e)}=\frac{P(e|c)P(c)}{\sum_{\forall h\in
      causa}P(e|h)P(h)}\] 
Vediamo un po' di notazione:
\begin{itemize}
  \item con $<\top,\bot>$ indichiamo una distribuzione di probabilità
  \item $\alpha$ costante di normalizzazione per trascurare il denominatore di
  Bayes (lo sostituisce). È detto \textbf{fattore di normalizzazione}
\end{itemize}
\begin{esempio}
  Vediamo un esempio:
  \[P(meningite=<\top,\bot>|s=\top)=\alpha<P(s|m)P(m),P(s|\neg m)P(\neg m)>\]
\end{esempio}
SI assume che l'effetto deve essere scaturito a causa di una delle cause
ipotizzate e non altre. A volte è più difficile calcolare $P(effeto|causa)$ per
tutte le cause indipendentemente che calcolare direttamente $P(effetto)$.\\
Dato:
\[P(A|B)=\alpha P(B|A)P(A)\]
si ha che:
\begin{itemize}
  \item $P(A)$ è la probabilità a priori
  \item $P(B|A)$ probabilità a posteriori
  \item $P(B|A)$ verosimiglianza
\end{itemize}
Se la probabilità a priori è nulla si assegna una probabilità $\varepsilon$
(anche solo per un'osservazione) a tutti gli eventi che riteniamo possibili,
anche se ancora non sono accaduti. Se un evento può realizzarsi deve avere una
probabilità a priori, anche se molto piccola. Bisogna poi riscalare la
probabilità di tutti per poter includere anche questi eventi
rari. \textbf{Esempi su slide}.\\
Vediamo quindi come si \textbf{combinano le evidenze}. Qualora si abbiano più
effetti il modello diventa più complesso. Per $n$ effetti arei $2^n$ possibili
combinazioni di evidenze da modellate. Si utilizza quindi la \textbf{catena di
  probabilità condizionali}, che, per esempio, per 4 eventi è:
\[P(A,B,C,D)=P(A|B,C,D)P(B|C,D)P(C|D)P(D)\]
ottenuta sfruttando la regola del prodotto:
\[P(A,B)=P(A|B)P(B)\]
La catena di probabilità condizionali è utile per rappresentare la probabilità
congiunta in quanto permette una rappresentazione più compatta (potendo mettere
anche insieme diverse fonti).\\
\begin{definizione}
  Considerato un insieme di eventi $E_1,\ldots E_n$ e tutte le possibili
  combinazioni dei loro valori $\top$ e $\bot$. Supponiamo di conoscere tutti i
  valori $P(E_1,\ldots,E_n)$.  Supponiamo che un sottoinsieme di questi presenti
  un valore definito, ovvero $E_j=e=\top$ allora chiamo \textbf{inferenza
    probabilistica} il processo di calcolo del valore:\\
  \[P(E_i=\top|E_i=e)\]
  In generale l'inferenza probabilistica non è trattabile con questo metodo
  avendo una lista $2^n$ probabilità congiunte $P(E_1,\ldots E_n)$ (lista che
  per di più spesso non abbiamo).\\
  Si ragiona quindi spesso tramite \textbf{metodi approssimati/qualitativi},
  avendo magari centinaia di evidenze.
\end{definizione}
\textbf{Esempio su slide}.\\

Per risolvere il problema viene anche incontro l'\textbf{indipendenza
  condizionata}.\\
Due eventi possono diventare indipendenti data la presenza di un altro evento,
che è causa comune di entrambi. Si passa da una dipendenza causale diretta alla
dipendenza dovuta ad un effetto causale indiretto (???). Se si conosce la causa
i due eventi sono indipendenti se non la si conosce potrebbero essere
dipendenti.
\begin{definizione}
  Definiamo la \textbf{regola di marginalizzazione} per due insiemi di variabili
  $Y$ e $Z$ come:
  \[P(Y)=\sum_{z\in Z}P(Y,z)\]
  In alternativa uso le probabilità condizionate usando la \textbf{regola del
    condizionamento}:
  \[P(Y)=\sum_{z\in Z}P(Y|z)P(z)\]
  Potrei anche usare l'\textbf{inferenza per enumerazione} dove semplicemente
  sommo i valori della tabella rispetto a ciò che mi interessa (se voglio
  $P(c=\top,m=\top)$ sommo tutti i valori con almeno uno dei due nella tabella).
\end{definizione}
\textbf{Su slide esempio di conto per tutti con anche conto per $\alpha$}.\\
Un principio generale di computazione è:
\begin{itemize}
  \item specificare la variabile oggetto della ``query''
  \item fissare lo stato delle variabili per le quali è disponibile l'evidenza
  \item calcolare la probabilità a posteriori sommando
  rispetto alle variabili sulle quali non è disponibile evidenza 
\end{itemize}
Quindi indiciamo con $x$ tale variabile oggetto di query. Data la realizzazione
congiunta $e(evidenza)$ per un sottoinsieme $E$ di variabili dette
\textbf{variabili con evidenza} si indica con $Y$ l'insieme restanti
variabili. $Y$ è detto insieme delle variabili senza evidenza. L'intero insieme
delle variabili del problema è quindi:
\[\{X\}\cup E \cup Y\]
La distribuzione marginale a posteriori di $X$ è ottenuto per marginalizzazione
rispetto a $Y$:
\[P(X|E=e)=\alpha P(X,E=e)=\alpha\sum P(X,E=e,Y=y)\]
Posso quindi fare query per qualsiasi variabili avendo la tabella delle
probabilità congiunte ma tale metodo non è efficiente.
\subsection{Reti Bayesiane}
Le relazioni di indipendenza condizionata può essere illustrata da un grafo,
dove un nodo è collegato ad un altro con arco diretto sse il primo è causa
dell'altro:
\begin{figure}[H]
  \centering
  \includegraphics[scale = 0.9]{img/b.pdf}
\end{figure}
\begin{esempio}
  Vediamo un esempio:
  \[P(carie|mal\_di\_denti\land incastro)=\alpha P(|mal\_di\_denti\land
    incastro|carie)P(carie)\]
  \[=\alpha P(|mal\_di\_denti|carie)P(incastro|carie)P(carie)\]
\end{esempio}
\textbf{Ulteriori esempi su slide}.\\
\textit{Le probabilità congiunte le posso rappresentare in una tabella.}\\
Le \textbf{reti Bayesiane} sfruttano grafi diretti aciclici per rappresentare le
assunzioni di indipendenza condizionale tra variabili in modo chiaro ed
efficiente. Un arco diretto tra $A$ e $B$ rappresenta una relazione di
causalità: $A$ influenza $B$. Si ha quindi che ``pattern'' di ragionamenti sono
un cammino tra un nodo e un altro.\\
Si passa da $O(2^n)$ a $O(n)$, per $n$ numero di effetti.
\begin{definizione}
  Si ha che l'evento $A$ è condizionalmente indipendente dall'evento $B$ se,
  dato l'evento $C$:
  \[P(A|B,C)=P(A|C)\]
  ovvero la conoscenza di $B$ non porta a nessuna ulteriore variazione della
  probabilità di $A$ rispetto a quella dell'avverarsi di $C$. \\
  Dall'indipendenza di $A$ e $B$ dato $C$ si ha che:
  \[P(A,B|C)=P(A|C)P(B|C)=P(A,B|C)\]
  Se $C$ è un insieme vuoto ho, non avendo correlazione:
  \[P(A,B)=P(A)P(B)\]
\end{definizione}
Le reti Bayesiane quindi analizzano le cause dirette e indirette.

\end{document}  
% LocalWords:  clock  Bayesana machine learning Bayes riscalare
% LocalWords:  condizionalmente
