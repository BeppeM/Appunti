\documentclass[a4paper,12pt, oneside]{book}

% \usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{engrec}
\usepackage{rotating}
\usepackage{verbatim}
\usepackage[safe,extra]{tipa}
% \usepackage{showkeys}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{fontspec}
\usepackage{enumerate}
\usepackage{physics}
\usepackage{braket}
\usepackage{marginnote}
\usepackage{pgfplots}
\usepackage{cancel}
\usepackage{polynom}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage[cache=false]{minted}
\usepackage{mathtools}
\usepackage[noend]{algpseudocode}

\usepackage{tikz}\usetikzlibrary{er}\tikzset{multi  attribute /.style={attribute
    ,double  distance =1.5pt}}\tikzset{derived  attribute /.style={attribute
    ,dashed}}\tikzset{total /.style={double  distance =1.5pt}}\tikzset{every
  entity /.style={draw=orange , fill=orange!20}}\tikzset{every  attribute
  /.style={draw=MediumPurple1, fill=MediumPurple1!20}}\tikzset{every
  relationship /.style={draw=Chartreuse2,
    fill=Chartreuse2!20}}\newcommand{\key}[1]{\underline{#1}}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{arrows,shapes,backgrounds,petri}
\tikzset{
  place/.style={
    circle,
    thick,
    draw=black,
    minimum size=6mm,
  },
  transition/.style={
    rectangle,
    thick,
    fill=black,
    minimum width=8mm,
    inner ysep=2pt
  },
  transitionv/.style={
    rectangle,
    thick,
    fill=black,
    minimum height=8mm,
    inner xsep=2pt
  }
} 
\usetikzlibrary{automata,positioning,chains,fit,shapes}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}
\fancyfoot[C]{\thepage}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{epsfig}
\usepackage{pst-grad} % For gradients
\usepackage{pst-plot} % For axes
\usepackage[space]{grffile} % For spaces in paths
\usepackage{etoolbox} % For spaces in paths
\makeatletter % For spaces in paths
\patchcmd\Gread@eps{\@inputcheck#1 }{\@inputcheck"#1"\relax}{}{}
\makeatother

\title{Modelli Probabilistici per le Decisioni}
\author{UniShare\\\\Davide Cozzi\\\href{https://t.me/dlcgold}{@dlcgold}}
\date{}

\pgfplotsset{compat=1.13}
\begin{document}
\maketitle

\definecolor{shadecolor}{gray}{0.80}
\setlist{leftmargin = 2cm}
\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{esempio}{Esempio}
\newtheorem{corollario}{Corollario}
\newtheorem{lemma}{Lemma}
\newtheorem{osservazione}{Osservazione}
\newtheorem{nota}{Nota}
\newtheorem{esercizio}{Esercizio}
\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}
\tableofcontents
\renewcommand{\chaptermark}[1]{%
  \markboth{\chaptername
    \ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}%
\chapter{Introduzione}
\textbf{Questi appunti sono presi a lezione. Per quanto sia stata fatta
  una revisione è altamente probabile (praticamente certo) che possano
  contenere errori, sia di stampa che di vero e proprio contenuto. Per
  eventuali proposte di correzione effettuare una pull request. Link: }
\url{https://github.com/dlcgold/Appunti}.\\
\chapter{Ripasso di Probabilità}
Riprendiamo qualche definizione.
\begin{definizione}
  Definiamo \textbf{variabile casuale} come un'osservazione, un esito o un
  evento il cui valore è incerto.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{dominio o spazio degli eventi} come l'insieme dei possibili
  valore che può assumere una variabile casuale.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{spazio di probabilità o modello di probabilità} come uno
  spazio degli eventi corredato da un assegnamento:
  \[P(\omega),\omega\in \Omega\]
  tale che:
  \begin{itemize}
    \item $0\leq P(\omega)\leq 1$
    \item $\sum_\omega p(\omega)=1$
  \end{itemize}
  con $omega$ evento e $\Omega$ spazio degli eventi.
\end{definizione}
\begin{definizione}
  Definiamo \textbf{evento atomico o campione} una specificazione completa del
  calore delle variabili casuali di interesse.\\
  L'insieme di tutti i possibili eventi atomici è:
  \begin{itemize}
    \item mutualmente esaustivo (non potendo accadere altro)
    \item mutualmente esclusivo (può accadere solo un evento atomico di quelli
    possibili) 
  \end{itemize}
\end{definizione}
\begin{definizione}
  Definiamo un \textbf{evento} (non atomico) $A$ può essere un qualunque
  sottoinsieme di $\Omega$ tale che: 
  \[P(A)=\sum_{\omega\in A}P(\omega)\]
\end{definizione}
\begin{definizione}
  Definiamo una \textbf{variabile aleatoria} è una variabile che può assumere
  diversi valori in corrispondenza di altrettanti eventi che costituiscono una
  partizione dello spazio delle probabilità.
\end{definizione}

Si ricorda che, per una variabile $a$ e una $b$:
\begin{itemize}
  \item $0\leq P(a)\leq 1$
  \item $P(\top)=1$ e $P(\bot) =0$
  \item $P(a\lor b) = P(a)+p(b) -p(a\land b)$
\end{itemize}
\begin{definizione}
  Definiamo una \textbf{probabilità condizionata} rappresenta la verosimiglianza
  che un evento $a$ si verifichi se $b$ si verifica e si denota con:
  \[P(a|b)\]
  Si ha quindi la specifica che alcuni eventi rendono altri eventi più o meno
  verosimili.\\
  Si parla quindi di eventi \textbf{dipendenti}.
\end{definizione}
\begin{definizione}
  Due eventi sono \textbf{indipendenti} se un evento non influisce sulla
  realizzazione dell'altro:
  \[P(a|b)=P(a)\]
\end{definizione}
Si ha quindi la seguente regola.
\begin{teorema}[Regola del prodotto]
  Possiamo calcolare che due eventi si verifichino contemporaneamente tramite la
  probabilità condizionata e quella dei singoli eventi:
  \[P(a,b)=P(a\land b)=P(a|b)P(b)=P(b|a)P(a)\]
  Con $P(a,b)=P(a\land b)$ è detta \textbf{probabilità congiunta} (``='' perché
  sono due modi per scriverla).
\end{teorema}
Posso fare la tabella dei vari eventi condizionati.
\begin{teorema}[Regola della somma]
  Si ha che, avendo la tabella degli eventi:
  \[P(x)=\sum_y P(x,y)\]
  con $P(x)$ detta \textbf{probabilità marginale}.
\end{teorema}
La somma di tutte le possibili combinazioni di eventi, quindi dei valori della
tabella, deve dare 1.\\ 
\textbf{Su slide esempio di uso di quanto detto, dove si arriva al teorema di
  Bayes}.\\
Si vuole infatti passare dal conoscere $P(a|b)$ al consocere $P(b|a)$.
\begin{teorema}[Teorema di Bayes]
  Il teorema enuncia che:
  \[P(h|D)=\frac{P(D|h)P(h)}{P(D)}\]
  Avendo:
  \begin{itemize}
    \item $P(h)$ che è la probabilità conosciuta a priori di $h$. Tale
    probabilità riflette qualsiasi conoscenza di base sulla possibilità
    che $h$ sia corretta  
    \item $P(D)$ che è la probabilità conosciuta a priori di $D$, ovvero la
    probabilità che $D$ sia osservato
    \item $P(D|h)$ che è la probabilità di osservare $D$ in presenza
    dell'ipotesi $h$
    \item $P(D|h)$ che è la probabilità a posteriori di $h$. Tale probabilità
    riflette la ``confidenza'' di avere $h$  dopo che $D$ è stato osservato
  \end{itemize}
\end{teorema}
In altri termini, avendo:
\[P(a\land b)=P(a|b)P(b)=P(b|a)P(a)\]
ho che:
\[P(a|b)P(b)=P(b|a)P(a)\]
arrivando a dire che:
\[P(a|b)=\frac{P(b|a)P(a)}{P(b)}\]
\textbf{notando la correlazione tra probabilità congiunta e Bayes}.\\
Che è il punto fondamentale della moderna teoria dell'intelligenza artificiale
in quanto permette di raccogliere l'evidenza senza poi usare le tabelle delle
probabilità congiunte, che sarebbero difficilissimi da osservare.
Se pensiamo ad alcuni eventi come cause ``nascoste'' non necessariamente
osservabili se modelliamo la verosimiglianza degli eventi osservabili date le
cause nascoste si ha:
\[P(causa|effetto)=\frac{P(effetto|causa)P(causa)}{P(effetto)}\]
Si ha quindi un modello per inferire/derivare la verosimiglianza della causa
nascosta e quindi rispondendo a:
\[P(causa|effetto)\]
Avendo quindi la probabilità di una causa dato un effetto.
\textit{Dato l'effetto modello la causa}.\\
Se non si ha una delle due probabilità a priori posso stimare per poi
normalizzare. In altri termini il denominatore $P(D)$ è spesso solo una quantità
di normalizzazione, essendo spesso difficile da stimare. \\
Le probabilità possono essere definite su due approcci:
\begin{itemize}
  \item \textbf{approccio frequentista o oggettivista} che considera la
  probabilità come un'entità misurabile legata alla frequenza di accadimento,
  come si fa ne machine learning
  \item \textbf{approccio soggettivista} che considera la
  probabilità come una misura del grado di attesa soggettivo del verificarsi di
  un evento, come si fa nel corso di statistica
\end{itemize}

\chapter{Modelli Probabilistici}
Nel passato si sono usati \textbf{sistemi a regole}, dove codificando tutto
quello che può succedere si cercava di giungere ad una decisione. Questo però
era molto dispendioso, si arrivava o a vero a falso, senza via di mezzo, e si
dovevano avere dati ipoteticamente completi e sicuri in partenza. Si parla in
questo caso di \textbf{modelli logici}.\\
Viviamo in un'era dove si hanno molti dati, sia in ambito sociale, che di
business che scientifico. Questi dati devono essere analizzati al fine di poter
prendere \textbf{decisioni} e per farlo si deve per capire la situazione in cui
ci si trova e spesso posso capirlo solo osservando i dati, non osservando la
variabile specifica. Dalle osservazioni dobbiamo inferire il valore di variabili
``nascoste''. Spesso si ha a che fare con dati non completi, non consistenti,
spesso errati, con rumore di trasmissione etc$\ldots$\\
Tali dati sono comunque
evidenze per percepire la situazione in cui ci si trova. L'obiettivo del corso è
fornire strumenti modellistici per rappresentare l'incertezza nel modello,
incertezza per struttura e parametri, e per rappresentare in termini
probabilistici gli errori nei dati. Si vuole quindi implementare algoritmi di
``ragionamento'', automatizzati e adattivi, oltre che robusti e scalabili.\\
I \textbf{modelli probabilistici} sono anche detti \textbf{modelli
  generativi}. Si usa la teoria delle probabilità per esprimere incertezza e
rumore associati al modello e ai dati, soprattutto usando la teoria Bayesana,
per fare previsione e adattare i modelli. Questi modelli permettono di partire
da una ``credenza'' iniziale, anche soggettiva, per poi raccogliere evidenze
aggiustando tale modello.\\
I modelli probabilistici sono anche modelli di machine learning, in quanto
apprendono.\\
Bisogna quindi partire dalle osservazioni generate rispetto ad un valore di
variabile per poi inferire tale variabile (ad esempio parto dai risultati di un
gioco per capire quando è bravo il giocatore, che non è una variabile che posso
sapere a priori). Si parte dai dati e si arriva al
valore della variabile che ha generato questi dati (per questo \textit{modello
  generativo}). Man mano che raccolgo informazioni raffino il modello, più o
meno come fa un essere umano (``più rispondi alle domande all'orale e più il
docente capisce il tuo voto, anche se alla fine non si ha la certezza che il
voto rispecchi la preparazione''). I dati possono non portare alla certezza, ma
più dati si hanno e più ci si avvicina, riducendo l'incertezza.\\
Un esempio pratico è il modello \textbf{Elo} (nato per gli scacchi) da cui
deriva quello usato da \textit{Xbox} per capire come appaiare giocatori online
in base alle skill. Il valore di bravura viene rappresentato come una
distribuzione, in primis con una Gaussiana, con una certa media e una certa
varianza/deviazione standard, quindi solo due numeri. Cambiare il modello
significa solo cambiare quei due valori. Per confrontare due giocatori capisco
la distribuzione a partire dai dati del giocatore che si hanno, diminuendo
l'incertezza all'aumentare dei dati. Con il modello probabilistico poi, a
partire dal risultato modificherò le distribuzioni di partenza, cambiando la
percezione su essi. Nel tempo posso tenere aggiornato i modelli probabilistici
che rappresentano una certa variabile e usarli per fare confronti (ad esempio
confrontando due giocatori per poi fare l'appaiamento).\\
Con i modelli probabilistici si ha una capacità espressiva maggiore di quella di
un modello logico, avendo le distribuzioni di probabilità e potendo anche usare
varie soglie.\\
Un \textit{modello generativ}o parte dalle probabilità a priori e può
``generare'' possibili eventi, generando campioni verosimili con una certa
distribuzione statistica. \\
Nella vita reale si osservano degli accadimenti e studiandoli si può risalire
alla probabilità degli eventi, tramite l'approccio frequentista.
\section{Incertezza}
Si introduce quindi l'\textbf{incertezza}. Non sempre si ha a che fare con dati
``certi'' e precisi, che possono portare con più facilità ad una certa
decisione, potendo giungere ad una decisione \textbf{ottimale} senza alcun
dubbio su quale essa sia.\\
Con l'\textbf{incertezza} sui dati bisogna modificare l'idea di
\textbf{soluzione ottimale}. Si arriva a dover capire quale sia la
\textbf{soluzione ottima} in un contesto dove ``non si sa cosa succederà'',
partendo da dati incerti.\\
Si ha che:
\begin{itemize}
  \item un evento osservato può avere molte cause
  \item la verosimiglianza di un'ipotesi sulla causa cambia man mano che si
  raccolgono pezzi di evidenza
  \item usando modelli probabilistici di ragionamento possiamo calcolare quanto
  probabile è una certa ipotesi. Si ipotizza che le fonti di incertezza siano
  quantificabili
\end{itemize}
\textbf{\textit{Vari esempi di vita in merito sulle slide.}}\\
Spesso si ha un approccio ``frequentista'', valutando la frequenza di un evento
per capire la probabilità che tale evento accada, inferendo così una
distribuzione di probabilità dalla frequenza con la quale si osservano i
dati. Questo è piuù o meno come funziona il cervello umano ma bisogna fare la
stessa cosa con un calcolatore e per questo ci verrà incontro il \textbf{teorema
  di Bayes}.\\
Si ha inoltre che un sistema che considera anche l'incertezza, che è presente in
moltissime situazioni, dovrebbe funzionare meglio di uno che non lo fa ma ci
serve in primis un modo per rappresentare l'incertezza stessa. \\
Più parametri ha il modello e più è difficile rappresentarlo.\\
Si ha il \textbf{Degree of Belief} che è una probabilità a priori sono ricavate
da:
\begin{itemize}
  \item osservazioni statistiche
  \item regole generali e conosciute
  \item combinazioni di sorgenti di evidenza
\end{itemize}
In ogni caso si hanno quindi evidenze empiriche.\\
Vediamo ora il rapporto tra i \textbf{modelli causali} e la \textbf{regola di
  Bayes}.\\
Ricordiamo che per Bayes si ha:
\[P(causa|effetto)=\frac{P(effetto|causa)P(causa)}{P(effetto)}\]
Con le reti causali vorremmo risalire dall'effetto alla causa ma normalmente si
hanno più informazioni su $P(causa|effetto)$ che su $P(effetto|causa)$.\\
Conoscendo $P(effetto|causa)$ per ogni causa posso evitare di calcolare
$P(effetto)$, infatti, dato $c=causa$ ed $e=effeto$:
\[P(c|e)=\frac{P(e|c)P(c)}{P(e)}=\frac{P(e|c)P(c)}{\sum_{\forall h\in
      causa}P(e|h)P(h)}\] 
Vediamo un po' di notazione:
\begin{itemize}
  \item con $<\top,\bot>$ indichiamo una distribuzione di probabilità
  \item $\alpha$ costante di normalizzazione per trascurare il denominatore di
  Bayes (lo sostituisce). È detto \textbf{fattore di normalizzazione}
\end{itemize}
\begin{esempio}
  Vediamo un esempio:
  \[P(meningite=<\top,\bot>|s=\top)=\alpha<P(s|m)P(m),P(s|\neg m)P(\neg m)>\]
\end{esempio}
SI assume che l'effetto deve essere scaturito a causa di una delle cause
ipotizzate e non altre. A volte è più difficile calcolare $P(effeto|causa)$ per
tutte le cause indipendentemente che calcolare direttamente $P(effetto)$.\\
Dato:
\[P(A|B)=\alpha P(B|A)P(A)\]
si ha che:
\begin{itemize}
  \item $P(A)$ è la probabilità a priori
  \item $P(B|A)$ probabilità a posteriori
  \item $P(B|A)$ verosimiglianza
\end{itemize}
Se la probabilità a priori è nulla si assegna una probabilità $\varepsilon$
(anche solo per un'osservazione) a tutti gli eventi che riteniamo possibili,
anche se ancora non sono accaduti. Se un evento può realizzarsi deve avere una
probabilità a priori, anche se molto piccola. Bisogna poi riscalare la
probabilità di tutti per poter includere anche questi eventi
rari. \textbf{Esempi su slide}.\\
Vediamo quindi come si \textbf{combinano le evidenze}. Qualora si abbiano più
effetti il modello diventa più complesso. Per $n$ effetti arei $2^n$ possibili
combinazioni di evidenze da modellate. Si utilizza quindi la \textbf{catena di
  probabilità condizionali}, che, per esempio, per 4 eventi è:
\[P(A,B,C,D)=P(A|B,C,D)P(B|C,D)P(C|D)P(D)\]
ottenuta sfruttando la regola del prodotto:
\[P(A,B)=P(A|B)P(B)\]
La catena di probabilità condizionali è utile per rappresentare la probabilità
congiunta in quanto permette una rappresentazione più compatta (potendo mettere
anche insieme diverse fonti).\\
\begin{definizione}
  Considerato un insieme di eventi $E_1,\ldots E_n$ e tutte le possibili
  combinazioni dei loro valori $\top$ e $\bot$. Supponiamo di conoscere tutti i
  valori $P(E_1,\ldots,E_n)$.  Supponiamo che un sottoinsieme di questi presenti
  un valore definito, ovvero $E_j=e=\top$ allora chiamo \textbf{inferenza
    probabilistica} il processo di calcolo del valore:\\
  \[P(E_i=\top|E_i=e)\]
  In generale l'inferenza probabilistica non è trattabile con questo metodo
  avendo una lista $2^n$ probabilità congiunte $P(E_1,\ldots E_n)$ (lista che
  per di più spesso non abbiamo).\\
  Si ragiona quindi spesso tramite \textbf{metodi approssimati/qualitativi},
  avendo magari centinaia di evidenze.
\end{definizione}
\textbf{Esempio su slide}.\\

Per risolvere il problema viene anche incontro l'\textbf{indipendenza
  condizionata}.\\
Due eventi possono diventare indipendenti data la presenza di un altro evento,
che è causa comune di entrambi. Si passa da una dipendenza causale diretta alla
dipendenza dovuta ad un effetto causale indiretto (???). Se si conosce la causa
i due eventi sono indipendenti se non la si conosce potrebbero essere
dipendenti.
\begin{definizione}
  Definiamo la \textbf{regola di marginalizzazione} per due insiemi di variabili
  $Y$ e $Z$ come:
  \[P(Y)=\sum_{z\in Z}P(Y,z)\]
  In alternativa uso le probabilità condizionate usando la \textbf{regola del
    condizionamento}:
  \[P(Y)=\sum_{z\in Z}P(Y|z)P(z)\]
  Potrei anche usare l'\textbf{inferenza per enumerazione} dove semplicemente
  sommo i valori della tabella rispetto a ciò che mi interessa (se voglio
  $P(c=\top,m=\top)$ sommo tutti i valori con almeno uno dei due nella tabella).
\end{definizione}
\textbf{Su slide esempio di conto per tutti con anche conto per $\alpha$}.\\
Un principio generale di computazione è:
\begin{itemize}
  \item specificare la variabile oggetto della ``query''
  \item fissare lo stato delle variabili per le quali è disponibile l'evidenza
  \item calcolare la probabilità a posteriori sommando
  rispetto alle variabili sulle quali non è disponibile evidenza 
\end{itemize}
Quindi indiciamo con $x$ tale variabile oggetto di query. Data la realizzazione
congiunta $e(evidenza)$ per un sottoinsieme $E$ di variabili dette
\textbf{variabili con evidenza} si indica con $Y$ l'insieme restanti
variabili. $Y$ è detto insieme delle variabili senza evidenza. L'intero insieme
delle variabili del problema è quindi:
\[\{X\}\cup E \cup Y\]
La distribuzione marginale a posteriori di $X$ è ottenuto per marginalizzazione
rispetto a $Y$:
\[P(X|E=e)=\alpha P(X,E=e)=\alpha\sum P(X,E=e,Y=y)\]
Posso quindi fare query per qualsiasi variabili avendo la tabella delle
probabilità congiunte ma tale metodo non è efficiente.
\subsection{Reti Bayesiane}
Le relazioni di indipendenza condizionata può essere illustrata da un grafo,
dove un nodo è collegato ad un altro con arco diretto sse il primo è causa
dell'altro:
\begin{figure}[H]
  \centering
  \includegraphics[scale = 0.9]{img/b.pdf}
\end{figure}
\begin{esempio}
  Vediamo un esempio:
  \[P(carie|mal\_di\_denti\land incastro)=\alpha P(|mal\_di\_denti\land
    incastro|carie)P(carie)\]
  \[=\alpha P(|mal\_di\_denti|carie)P(incastro|carie)P(carie)\]
\end{esempio}
\textbf{Ulteriori esempi su slide}.\\
\textit{Le probabilità congiunte le posso rappresentare in una tabella.}\\
Le \textbf{reti Bayesiane} sfruttano grafi diretti aciclici per rappresentare le
assunzioni di indipendenza condizionale tra variabili in modo chiaro ed
efficiente. Un arco diretto tra $A$ e $B$ rappresenta una relazione di
causalità: $A$ influenza $B$. Si ha quindi che ``pattern'' di ragionamenti sono
un cammino tra un nodo e un altro.\\
Si passa da $O(2^n)$ a $O(n)$, per $n$ numero di effetti.
\begin{definizione}
  Si ha che l'evento $A$ è condizionalmente indipendente dall'evento $B$ se,
  dato l'evento $C$:
  \[P(A|B,C)=P(A|C)\]
  ovvero la conoscenza di $B$ non porta a nessuna ulteriore variazione della
  probabilità di $A$ rispetto a quella dell'avverarsi di $C$. \\
  Dall'indipendenza di $A$ e $B$ dato $C$ si ha che:
  \[P(A,B|C)=P(A|C)P(B|C)=P(A,B|C)\]
  Se $C$ è un insieme vuoto ho, non avendo correlazione:
  \[P(A,B)=P(A)P(B)\]
\end{definizione}
Le reti Bayesiane quindi analizzano le cause dirette e indirette permettendo di
rappresentare in modo efficiente la distribuzione congiunta di probabilità,
tramite dipendenza e indipendenza condizionale.\\
L'inferenza basata su enumerazione è in $O(d^n)$ sia in spazio che tempo con:
\begin{itemize}
  \item $d$ massima cardinalità del supporto (se binario $d=2$)
  \item $n$ numero di variabili
\end{itemize}
è questo non va bene.\\
Una distribuzione congiunta può essere rappresentata come produttoria di $n$
valori di probabilità di \textbf{eventi indipendenti}, passando da un arrivando
a $O(n)$, avendo:
\[P(C_1,\ldots C_n)=P(C_1)\cdots \ldots P(C_n)\]
Rappresentando quindi, tramite l'indipendenza delle variabili, in modo compatto
una distribuzione congiunta. \\
Nel mondo reale però non si ha indipendenza assoluta tra le variabili e spesso
anche il gran numero di variabili rende difficile la specifica di una
distribuzione congiunta. \\
Si usa quindi l'indipendenza condizionale, sfruttando le variabili
condizionalmente indipendenti. \\
Per scrivere la definizione congiunta usiamo la \textbf{chain rule}.
Dato $P(X,Y,Z)$ si ha che, avendo $X$ e $Y$ indipendenti:
\[P(X,Y,Z)=P(X|Y,Z)P(Y,Z)=P(Z|Y,Z)P(Y|Z)P(Z)=P(X|Z)P(Y|Z)P(Z)\]
riducendo quindi il numero di valori di probabilità necessari al conto.\\
Le asserzioni di indipendenza condizionate si basano sul dominio in analisi e
consente di limitare le complessità del modello. Il caso in cui tutte le
variabili sono indipendenti ho la fattorizzazione delle probabilità delle
singole variabili ed è un caso specifico di questo discorso.\\
Ricordando che per Bayes:
\[P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}=\alpha P(X|Y)P(Y)\]
calcolando la probabilità della causa data la conoscenza dello stato degli
effetti. Quindi, avendo $X$ e $Y$ indipendenti:
\[P(X|Y,Z)=\alpha P(X,Y|Z)P(Z)=\alpha P(X|Z)P(Y|Z)P(Z)\]
Avendo graficamente $P(X,Y,Z)=\alpha P(X|Z)P(Y|Z)P(Z)$:
\begin{figure}[H]
  \centering
  \includegraphics[scale = 0.9]{img/b2.pdf}
\end{figure}
Possiamo quindi parlare meglio delle \textbf{reti Bayesiane}, spesso indicata
con:
\begin{itemize}
  \item \textbf{Bayesian Belief Network, BBN}
  \item \textbf{Probabilistic Network, PN}
  \item \textbf{Causal Network, CN}
\end{itemize}
Tali reti appartengono alla classe dei \textbf{modelli
  grafico-probabilistici}.\\ 
\begin{definizione}
  Una \textbf{rete Bayesiana} è un grafo cui nodi sono annotati da una
  informazione quantitativa, tramite tabelle di probabilità condizionata, e i
  cui archi definiscono dipendenza e indipendenza tra le variabili dei nodi. Si
  hanno solo archi orientati. Se $X$ è causa diretta di $Y$ ho un arco tra $X$ e
  $Y$. $X$ è detto genitore e $Y$ figlio. Le variabili possono essere sia
  continue che discrete.\\
  La topologia della rete e le probabilità condizionate dei nodi dati genitori
  sono sufficienti a specificare (implicitamente) la distribuzione congiunta di
  tutte le variabili.\\
  Uno o più nodi isolati segnalano indipendenza assoluta. Due figli di uno
  stesso genitore segnalano che sono condizionalmente
  indipendenti. Nell'immagine $X$ e $Y$ sono condizionalmente indipendenti, $W$
  è indipendente dalle altre 3 variabili, $Z$ è causa diretta di $X$ e $Y$
  mentre tra queste ultime non esiste una relazione diretta di causalità:
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.9]{img/b3.pdf}
  \end{figure}
  Tale grafo non contiene cicli e quindi si parla di \textbf{Directed Acyclic
    Graph (\textit{DAG})}, non essendo possibile che una variabile causi se
  stessa. 
\end{definizione}
Come detto la componente quantitativa è costruita da un insieme di tabella di
probabilità condizionale. Ogni nodo ha associata quindi una \textit{Conditioned
  Probability Table (\textit{CPT})} che traduce l'impatto dei genitori sulla
variabile stessa.\\
\textbf{Su slide esempio esteso.}\\
Ricapitolando:
\begin{itemize}
  \item ogni nodo ha CPT
  \item ogni riga della CPT somma ad uno (e se ho un solo valore non scrivo sia
  il vero che il falso visto che posso fare $1-$)
  \item la CPT di una variabile booleana con $K$ variabili genitori contiene
  $2^K$ valori che possono essere specificati indipendentemente
  \item una variabile senza genitori ha una sola riga con i valori di
  probabilità a priori per ogni possibile valore che la variabile può assumere 
\end{itemize}
Possiamo dire che si hanno due chiavi di lettura dal punto di vista della
semantica, semanticamente equivalenti: 
\begin{itemize}
  \item la rete rappresenta una \textbf{distribuzione congiunta di
    probabilità}. Questa 
  lettura è utile per progettare e implementare procedure di inferenza. Per
  questa lettura dice che ogni rete costituisce una descrizione completa del
  dominio che rappresenta e pertanto ogni elemento della distribuzione di
  probabilità congiunta può essere calcolato a partire dall’informazione
  contenuta nella rete. Un generico elemento della distribuzione di probabilità
  congiunta è associato ad una realizzazione congiunta delle variabili (nodi)
  presenti nella rete:
  \[P(X_1=x_1\land\cdots\land X_n=x_n)=P(x_1,\ldots
    ,x_n)=\prod_{i=1}^nP(x_i|parents(X_i))\]
  che è detta \textbf{formula di fattorizzazione}.\\
  Avendo che con le maiuscole abbiamo le variabili (anche per $Parents$) e con
  le minuscole le realizzazioni (anche per $parents$). Si ha quindi che ogni
  elemento della distribuzione congiunta è rappresentato come prodotto di
  opportune componenti delle CPT che costituiscono quindi una rappresentazione
  decomposta della distribuzione di probabilità congiunta. Per questa
  rappresentazione posso usare le reti per rispondere a qualsiasi query relative
  al dominio che descrive tramite marginalizzazioni.\\
  \textbf{Esempio su slide}.
  
  \item la rete codifica un \textbf{insieme di relazioni di indipendenza
    condizionale}. Questa lettura è utile per costruire un modello di rete
  Bayesiana.
\end{itemize}
Sfrutto la formula di fattorizzazione per determinate la
componente topologica della rete. Si ricorda che per la \textbf{cchin rule}:
\small{\[P\left(x_{1}, \ldots, x_{n}\right)=P\left(x_{n} \mid x_{n-1}, \ldots,
      x_{1}\right) \cdot P\left(x_{n-1} \mid x_{n-2}, \ldots, x_{1}\right) \cdot
    \ldots \cdot P\left(x_{2} \mid x_{1}\right) \cdot
    P\left(x_{1}\right)\]\[
    =\prod_{i=1}^n P\left(x_{i} \mid x_{n-1}, \ldots,
      x_{1}\right)\]}
Noto che tale formula è confrontabile con la formula di fattorizzazione e ho
che, a patto che $Parents(X_1)\subseteq \{x_{i-1},\ldots,x_1\}$:
\[\mathbf{P}\left(x_{i} \mid x_{i-1}, \ldots,
    x_{1}\right)=\mathbf{P}\left(x_{i} \mid \text { parents
    }\left(X_{i}\right)\right)\] 
Quindi una Rete Bayesiana rappresenta correttamente un dominio solo a
condizione che ogni nodo risulti condizionalmente indipendente dai suoi
predecessori, per un dato ordinamento, dati i suoi genitori. Pertanto, per
costruire una Rete Bayesiana che abbia la corretta struttura del dominio da
modellare è necessario scegliere, per ogni nodo, i nodi genitore in modo che
tale proprietà risulti verificata. Quindi i genitori di $X_i$ devono essere
scelti da $\{X_1,\ldots,X_{i-1}\}$.\\
Si ha quindi la seguente procedura di costruzione incrementale della
componente topologica;
\begin{enumerate}
  \item Si seleziona un insieme di variabili $\{X_1,\ldots, X_n\}$ per
  descrivere il modello
  \item scelgo un ordinamento per le variabili $\{X_{(1)},\ldots,
  X_{(n)}\}$. Con un ordinamento sbagliato arrivo a definire reti sbagliate o
  reti più complesse del necessario, magari con informazioni ridondanti
  \item inizializzo i nodi aggiunti alla rate partendo da $i=1$
  \item si seleziona la variabile $X_{(i)}$ alla rete, si pone
  $Parents(X_{(i)})$ uguale all’insieme minimale di nodi, attualmente
  appartenenti alla rete ${X_{(1)},\ldots, X_{(i-1)}}$, che soddisfa la
  proprietà di indipendenza condizionale:
  \[\mathbf{P}\left(X_{(i)} \mid X_{(i-1)}, \ldots,
      X\right)=\mathbf{P}\left(X_{(i)} \mid\right. \text { Parents
    }\left(X_{(i)}\right)\]
  per poi calcolare la CPT di $X_{(i)}$
  \item tengo conto del nodo aggiunto nel conto totale dei nodi e faccio
  i++. Se ho finito le variabili termino altrimenti torno a 4)
\end{enumerate}
Una rete è più compatta, solitamente, dell'intera distribuzione di probabilità
congiunta e tale compattezza è un esempio della proprietà dei \textbf{sistemi
  strutturati localmente o sparsi}, dove ogni sotto-componente interagisce solo
con un numero limitato di 
altre componenti, indipendentemente dal numero totale di componenti del
sistema. La strutturazione locale normalmente ha crescita lineare e non
esponenziale (mediamente con una rete Bayesiana è ragionevole pensare che ogni
variabile sia influenzata da al massimo $k$, con $k$ costante, variabili).\\  
Nel caso in cui si consideri una Rete Bayesiana costituita da $n$ variabili
(nodi) booleane. Si ha che la quantità di informazione per specificare una CPT è
limitata superiormente da $2^k$ per cui la rete completa richiede $n\cdot 2^k$
cifre contro i $2^n$ dell'intera distribuzione di probabilità congiunta.\\
Si hanno quindi vari tipi di rete, relativi a situazioni diametralmente opposte:
\begin{itemize}
  \item \textbf{rete completamente connessa (\textit{fully connected network})},
  dove ogni variabile può essere potenzialmente influenzata da tutte le altre e
  quindi specificare una CPT richiede le stesse informazioni della distribuzione
  congiunta
  \item \textbf{rete con relazioni di causalità tenui} dove se aggiungo delle
  relazioni, degli archi aumento la complessità della rete (???). Si valuta il
  guagno in accuratezza contro quelle in complessità
\end{itemize}
Anche in un dominio strutturato localmente la costruzione di una Rete Bayesiana
non è semplice, volendo un numero limitato di influenze per ogni variabile e che
la topologia della rete rifletta le relazioni di influenza diretta. La procedura
di costruzione di una Rete Bayesiana funziona in modo tale che quando si giunge
ad aggiungere un nodo, i nodi candidati ad essere suoi genitori, ovvero i nodi
che lo influenzano direttamente o indirettamente, siano già stati aggiunti alla
corrente struttura della rete. Il corretto ordine comporta che si devono prima
stabilire le cause radice per poi aggiungere quelle variabili che da loro
vengono influenzate, procedendo fino alle foglie che non sono causa di nulla. 
\end{document}  
% LocalWords:  clock  Bayesana machine learning Bayes riscalare
% LocalWords:  condizionalmente
