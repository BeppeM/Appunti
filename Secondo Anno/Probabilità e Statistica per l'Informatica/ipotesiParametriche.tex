\chapter{Ipotesi Parametriche}
Supponiamo di avere un campione di una popolazione, specificato eccetto per un vettore di parametri sconosciuti che deve
essere osservato ed invece di stimare i parametri sconosciuti, analizzato e considerato nel capitolo precedente, in
questo capitolo verifichiamo/testiamo alcune ipotesi, affermazioni riguardo un insieme di parametri della popolazione,
sul campione analizzato.\newline
L'obiettivo di questo capitolo è quello di determinare se un campione casuale è consistente con l'ipotesi fatta per cui
consideriamo una popolazione, con distribuzione $F_0$, dove abbiamo il parametro sconusciuto $\theta$, e supponiamo di
testare una specifica ipotesi riguardo $\theta$, denotata con $H_0$ e chiamata \emph{ipotesi nulla}.

Se $F_0$ è distribuita secondo una normale, con media $\theta$ e varianza pari a $1$ allora due possibili ipotesi sono:
\begin{itemize}
    \item $H_0: \theta = 1$:specifica la distribuzione della popolazione e quindi si definisce \emph{ipotesi semplice}
    \item $H_0: \theta \leq 1$: non specifica la distribuzione della popolazioni, per cui si definisce \emph{ipotesi composta}
\end{itemize}
Supponiamo di testare l'ipotesi nulla $H_0$, osservando un campione $X_1, X_2, \dots, X_n$ ed attraverso i valori delle
realizzazioni del campione dobbiamo decidere se accettare o meno l'ipotesi $H_0$.

Un test su un ipotesi $H_0$ consiste nel definire la regione $C$ in uno spazio $n$-esimo in cui l'ipotesi viene
accettata se il campione $X_1, X_2, \dots, X_n$ è fuori dalla regione altrimenti viene rifiutata.\newline
Praticamente $H_0$ viene accettato se $(X_1, X_2, \dots, X_n) \not \in C$ 
mentre $H_0$ viene rifiutato se $(X_1, X_2, \dots, X_n) \in C$.

Un test comune su $\theta = 1$, media di una normale con varianza $1$, ha la regione critica data da
\[ C = \{(X_1, X_2, \dots, X_n) : |\frac{\sum _{i = 1} ^ n - 1}{n}| > \frac{1.96}{\sqrt{n}}\} \]
Questo test viene rifiutato quando la media campionaria differisca da 1 per più di $\frac{1.96}{\sqrt{n}}$.\newline
Quando si effettua un test di ipotesi possono generarsi due tipologie di errori:
\begin{itemize}
    \item \emph{errore di prima specie} se il test ci porta a rifiutare $H_0$ mentre in realtà sarebbe corretto
    \item \emph{errore di seconda specie} se il test ci porta ad accettare $H_0$ mentre in realtà sarebbe da rifiutare
\end{itemize}
L'obiettivo della statistica inferenziale è quello di stabilire se $H_0$ è consistente rispetto ai dati e sembra
ragionabile che $H_0$ sia rifiutato se i dati sono distanti quando $H_0$ è vero.\newline
Il modo classico di verificarlo consiste nello specificare un valore $\alpha$ e richiediamo che il test ha la
possibilità che se $H_0$ sia vero, allora la probabilità di effettuare un errore, e quindi rifiutarlo, è minore o uguale
a $\alpha$.\newline
Il valore $\alpha$ viene chiamato \emph{valore di confidenza} del test e viene settato in anticipo, con valori soliti
$0.01, 0.05 \text{ e} 0.001$.

Per stabilire se l'ipotesi nulla $H_0:\alpha \in w$ è corretta si effettuano i seguenti due passi:
\begin{itemize}
    \item determinare lo stimatore di $\alpha$, chiamata $d(X)$, in cui si rifiuta $H_0$ 
          se $d(X)$ è distante dalla regione $w$
    \item determinare la distribuzione di $d(X)$ quando $H_0$ risulta vero, dato che ciò ci permette di stabilire
          l'appropriata regione critica per fare il test, con significato $\alpha$.
\end{itemize}
Supponiamo che $X_1, X_2, \dots, X_n$ siano un campione normale di lunghezza $n$, avente media sconosciuta $\mu$ e
varianza anch'essa sconosciuta $\sigma^2$ e supponiamo inoltre di essere interessati all'ipotesi nulla $H_0:\mu = \mu_0$ 
contro l'ipotesi alternativa $H_1:\mu \neq \mu_0$, dove $\mu_0$ è una costante significativa.\newline
Dato che $\mean{X} = \sum _{i = 1}^n \frac{X_i}{n}$ è lo stimatore naturale di $\mu$ è ragionevole accettare $H_0$se non
è troppo distante da $\mu_0$, per cui la regione critica deve essere, per qualche $c$ stabilito,
\[ C = \{X_1, X_2, \dots, X_n : |\mean{X} - \mu_0| > c \} \]
Se vogliamo affermare che il test ha significato $\alpha$, allora dobbiamo determinare il valore $c$, tale per cui si
rende l'errore di prima specie uguale a $\alpha$ per cui risulta ovviamente
\[ P_{\mu_0}(|\mean{X} - \mu_0| > c) = \alpha \]
Quando risulta $\mu = \mu_0$ risulta $\mean{X}$ una normale con media $\mu_0$ e varianza $\sigma^2$ per cui 
\[ Z \equiv \frac{\mean{X} - \mu_0}{\frac{\sigma}{\sqrt{n}}} \sim N(0, 1) \]
Sostituendo questo risultato nella formula precedente otteniamo che
\[ P(|Z| > \frac{c \sqrt{n}}{\sigma}) = \alpha \]
Sapendo che $P(Z > z_{\frac{\alpha}{2}}) = \frac{\alpha}{2}$ e con passaggi algebrici otteniamo che 
\[ c = \frac{z_{\frac{\alpha}{2} \sigma}{\sqrt{n}} \]
Il test di significato $\alpha$ viene rifiutato se risulta $|\mean{X} - \mu_0| > \frac{z_{\frac{\alpha}{2}}
\sigma}{\sqrt{n}}$ altrimenti viene accettato.

Un corretto livello di significato da usare dipende dalla circostanze, infatti se ad esempio rifiutare un ipotesi costa
un enorme quantità, che sarebbe uno spreco in caso di un errore, allora si usano dei valori $\alpha$ molto piccoli
mentre in caso siamo sicuri della correttezza di $H_0$ allora per avere un'evidenza del contrario usiamo dei valori di
$\alpha$ abbastanza grandi.\newline
Dall'equazione precedente segue che possiamo determinare se accettare o meno l'ipotesi nulla attraverso la computazione prima del
valore statistico $v$ e poi della probabilità che una normale unitaria sia in valore assoluto $> v$.\newline
Questa probabilità, chiamata $p$-value di un test, fornisce il livello critico di accettazione, nel senso che $H_0$
è accettato se il livello di accettazione $\alpha$ è minore o uguale al $p$-value altrimenti viene rifiutato.\newline
Il livello di accettazione di solito non viene settato in anticipo ma lo si cerca di determinare, quando si effettua
l'analisi e il test dell'ipotesi.

La probabilità di avere un errore di seconda specie, in cui accettiamo l'ipotesi nulla $H_0$ quando $\mu \neq \mu_0$,
dipende dal valore di $\mu$ per cui definiamo $\beta(\mu)$ come
\[  \begin{split}
    \beta(\mu) & = P_{\mu}(H_0 \text{ è accettato}) \\
               & = P_{\mu}(|\frac{\mean{X} - \mu}{\frac{\sigma}{\sqrt{n}}}| \leq z_{\frac{\alpha}{2}}) \\
               & = P_{\mu}(-z_{\frac{\alpha}{2}} \leq |\frac{\mean{X} - \mu}{\frac{\sigma}{\sqrt{n}}}| \leq z_{\frac{\alpha}{2}})\\
    \end{split} \]
La funzione $\beta(\mu)$ è chiamata la curva \emph{caratteristica operativa(OC)} e rappresenta la probabilità che $H_0$
viene accettata quando la media vera è $\mu$.
Attraverso dei passaggi algebrici e della definizione di approssimazione di una normale la valutazione della funzione
$\beta$ consiste nella differenza della valutazione, mediante le tavole normali standard, di $\frac{\mu_0 -
\mu}{\frac{\sigma}{\sqrt{n}}} + z_{\frac{\alpha}{2}}$ e $\frac{\mu_0 - \mu}{\frac{\sigma}{\sqrt{n}}} -z_{\frac{\alpha}{2}}$.
Per un livello fissato $\alpha$, la curva OC risulta simmetrica rispetto a $\mu_0$ e dipenda da $\mu$ solo attraverso
$\frac{\sqrt{n}}{\sigma} |\mu - \mu_0|$.\newline
La funzione $1 - \beta(\mu)$ è chiamata la funzione \emph{potenza} del test, ossia per un dato $\mu$, la potenza del
test è uguale alla proprietà di rifiuto quando $\mu$ è il valore corretto.\newline
La funzione OC è utile per determinare la lunghezza del campione casuale per cui possiamo fare alcune specifiche sugli
errori di seconda specie.


Nell'effettuare il test sull'ipotesi nulla $H_0:\mu = \mu_0$ abbiamo scelto un test che rifiuta quando $\mean{X}$ è
distante da $\mu_0$ con valore minore o maggiore di $\mu_0$.\newline
Se in caso volessimo avere come ipotesi alternativa $H_1:\mu > \mu_0$, in cui non vogliamo rifiutare $H_0$ quando
$\mean{X}$ sia minore di $\mu_0$, dato che in quel caso è più verosimile che $H_0$ sia corretto rispetto a $H_1$.\newline
Per questo motivo quando si effettua un test $H_0:\mu = \mu_0$ versus $H_1:\mu > \mu_0$ la regione critica deve essere
\[ C = \{(X_1, X_2, \dots, X_n) : \mean{X} - \mu_0 > c \} \]
Dato che la probabilità di rifiutare deve essere uguale a $\alpha$ quando $H_0$ è vero dobbiamo richiedere che 
\[ P(\mean{X} - \mu_0 > c) = \alpha \]
ma dato che $Z = \frac{\sqrt{n} \mean{X} - \mu_0}{\sigma} \sim N(0, 1)$ quando $H_0$ è vero, segue che
\[ P_{\mu_0}(\mean{X} - \mu_0) = P(Z > \frac{c \sqrt{n}}{\sigma} = \alpha \mbox{ quando } Z \sim N(0, 1) \]
Essendo $P(Z > z_{\alpha}) = \alpha$ notiamo che $c = \frac{z_{\alpha} \sigma}{\sqrt{n}}$.
Il test di ipotesi $H_0$ analizzato ora viene rifiutato se $\mean{X} - \mu_0 > \frac{z_{\alpha}\sigma}{\sqrt{n}}$
altrimenti viene accettato ossia equivalentemente risulta che
$H_0$ è accettato se $\frac{\sqrt{n}}{\sigma}(\mean{X} - \mu_0) \leq z_{\alpha}$ altrimenti viene accettato $H_1$.
Questa viene chiamata regione critica a solo un verso e il corrispondente test viene chiamato \emph{test a un solo verso}.

Per calcolare il $p$-value nell'equazione precedente prima usiamo i dati effettivi per calcolare il valore della
statistica $\frac{\sqrt{n} (\mean{X} - \mu)}{\sigma}$ e il p-value è uguale alla probabilità che l'ipotesi $H_0$ sia
verificata, per cui nel caso di un campione normalmente distribuito deve essere almeno largo 

La funzione OC per i test a un solo verso è definita come
\[  \begin{split}
    \beta(\mu) & = P_{\mu}(H_0 \mbox{ verificato}) \\
               & = P_{\mu}(\mean{X} \leq \mu_0 + z_{\alpha}\frac{\sigma}{\sqrt{n}} \\
               & = P_{\mu}(\frac{\mean{X} - \mu}{\sigma}{\sqrt{n}} \leq \frac{\mu_0 - \mu}{\frac{\sigma}{\sqrt{n}}} + z_{\alpha}\\
               & = P(Z \leq \frac{\mu_0 - \mu}{\frac{\sigma}{\sqrt{n}}} \\
    \end{split} \]
Risulta che la funzione $\beta(\mu)$ viene calcolata usando le tavole standard della normale, come avevamo visto nella
definizione della funzione $\beta$ per i test a doppio verso.\newline
All'aumento del valore del suo argomento, la funzione $\beta(\mu)$ porta a decrescere in $\mu$ e questo proviene
dall'intuizione che è ragionavolmente vero che lontani dalla media $\mu$ è molto meno probabile che si conclude $\mu \leq mu_0$
ed inoltre risulta $\beta(\mu_0) = 1 - \alpha$
Il test dato dall'equazione 8.3.10., disegnato per il test $H_0:\mu = \mu_0$ versus $H_1:\mu > \mu_0$ può essere usato
come test, con significatività $\alpha$, per il test di ipotesi ad una grandezza $H_0:\mu \leq \mu_0$ versus $H_1: \mu > \mu_0$.\newline
Per verificare che rimane un test di confidenza $\alpha$ dobbiamo mostrare che la probabilità di rifiuto di $H_0$ non
sarà più grande di $\alpha$ quando $H_0$ sarebbe vero.\newline
Per fare questo bisogna mostrare che $1 - \beta(\mu) \leq \alpha$ per ogni $\mu \leq \mu_0$ ma abbiamo già mostrato
nell'equazione 8.3.10 che $\beta(\mu)$ diminuisce in $\mu$ e $\beta(\mu_0) = 1 - \alpha$ da cui siamo in grado di
ottenere $\beta(\mu) \geq \beta(\mu_0) = 1 - \alpha$ per ogni valore $\mu \leq \mu_0$.\newline
Oltre alla definizione del test a un verso del tipo $H_0:\mu \leq \mu_0$, è possibile definire un test ad un solo verso 
del tipo $H_0:\mu = \mu_0(\mu \geq \mu_0)$ con test alternativo $H_1:\mu < \mu_0$, avente significato $\alpha$, tale per
cui $H_0$ risulta accettato se $\frac{\sqrt{n}}{\sigma} (\mean{X} - \mu_0) \geq -z_{\alpha}$ altrimenti $H_0$ è rifiutato.

Questo test può essere effettuato in maniera alternativa, calcolando prima il valore statistico $\frac{\sqrt{n}(\mean{X} -
\mu_0)}{\sigma}$ e poi calcolare il $p$-value, indicante la probabilità che l'ipotesi $H_0$ sia verificata, per cui si
rifiuta l'ipotesi $H_0$ in caso il nostro livello di significato $\alpha$ sia maggiore o uguale al $p$-value.

Fino ad ora abbiamo supposto che $\sigma^2$ non fosse sconosciuto ma il caso comune avviene 
con sia $\mu$ e $\sigma^2$ sconosciuti.\newline
Supponiamo ora di considerare un test di ipotesi $H_0:\mu = \mu_0$ con l'alternativa $H_1:\mu \neq \mu_0$ e si dovrebbe
notare che l'ipotesi nulla $H_0$ non è più semplice, in quanto non conosciamo la distribuzione di $\sigma^2$.\newline
Come prima, sembra ragionevole rigettare $H_0$ quando $\mean{X}$ è distante da $\mu$ ma la distanza necessaria per
rifiutarlo dipende dal valore di $\sigma^2$.\newline
Sapendo che $\sigma^2$ ha come massimo stimatore la variabile 
\[ S^2 = \frac{\sum _{i = 0}^n (\mean{X} - \mu)^2}{n - 1} \] 
da cui segue che si rifiuta $H_0$ quando è largo $|\frac{\mean{X} - \mu}{\frac{S}{\sqrt{n}}}|$.\newline
Per stabilire per quale valore dobbiamo rifiutare, al fine di avere un test con significato $\alpha$, dobbiamo
determinare la funzione di ripartizione di $|\frac{\mean{X} - \mu}{\frac{S}{\sqrt{n}}}|$ quando $H_0$ è verificato.

Come già notato e dimostrato nel capitolo precedente la statistica $T$, definita come
\[ T = \frac{\sqrt{n} (\mean{X} - \mu)}{S} \]
quando $\mu = \mu_0$ risulta una $t$-student con $n - 1$ gradi di libertà.\newline
Da questo aspetto si ricava che 
\[ P(-t_{\frac{\alpha}{2}, n - 1} \leq \frac{\sqrt{n} (\mean{X} - \mu_0)}{S} \leq t_{\frac{\alpha}{2}, n - 1}) = 1 - \alpha\]
dove $t_{\frac{\alpha}{2}, n - 1}$ è il $100(\frac{alpha}{2}$ quantile della distribuzione t con $n - 1$ gradi di libertà.\newline
Dall'ultima equazione si può notare che un test con significato $\alpha$ di $H_0:\mu = \mu_0$ con ipotesi alternativa
$H_1:\mu \neq \mu_0$, con $\sigma^2$ sconosciuto che ci pone ad affermare che $H_0$ risulta accettato se 
$|T| \leq t_{\frac{\alpha}{2}, n - 1}$ altrimenti $H_0$ risulta rifiutato.

È possibile effettuare un test $t$ ad un solo verso per testare l'ipotesi $H_0:\mu = \mu_0(\mu \leq \mu_0)$ con ipotesi
alternativa $H_1:\mu > \mu_0$ avente significato $\alpha$, in cui $H_0$ risulta accettato se $|T| \leq t_{\frac{\alpha}{2}, n - 1}$
altrimenti si rifiuta $H_0$.\newline
Il test avente significato $\alpha$, $H_0: \mu = \mu_0(\mu \geq \mu_0)$ con ipotesi alternativa $H_1:\mu < \mu_0$ porta
ad accettare $H_0$ se $\frac{\sqrt{n} (\mean{X} - \mu)}{S} \geq -t_{\frac{\alpha}{2}, n - 1}$ altrimenti $H_0$ viene rifiutato.

Una situazione normale è stabilire se due campioni, aventi distribuzione normale, di una popolazione hanno la stessa
media, per questo consideriamo il test di ipotesi $H_0:\mu_x = \mu_y$, con ipotesi alternativa $H_1:\mu_x \neq \mu_y$,
effettuato sui campioni $(X_1, X_2, \dots, X_n)$ e $(Y_1, Y_2, \dots, Y_m)$ indipendenti provenienti da una popolazione
normalmente distribuita, aventi media sconosciuta $\mu_x$ e $\mu_y$ ma varianze conosciute $\sigma^2_x$ e $\sigma^2_y$.

Essendo $\mean{X}$ il naturale stimatore di $\mu_x$ e $\mean{Y}$ il naturale stimatore di $\mu_y$, segue che $\mean{X} - \mean{Y}$
può essere usato per stimare $\mu_x - \mu_y$.\newline
In quanto il test di ipotesi può essere scritto come $H_0:\mu_x - \mu_y = 0$ sembra ragionevole
rifiutare $\mean{X} - \mean{Y}$ quando è distante da zero.\newline
La forma del test dovrebbe portarci ad accettare $H_0$ se $|\mean{X} - \mean{Y}| \leq c$ altrimenti a rifiutare $H_0$
e per determinare il valore di $c$, necessario per verificare il test di significato $\alpha$, dobbiamo conoscere la
distribuzione di $\mean{X} - \mean{Y}$ quando $H_0$ è vero.\newline
Come abbiamo già dimostrato nel capitolo precedente, abbiamo che 
$\mean{X} - \mean{Y} \sim N(\mu_x - \mu_y, \frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m})$ che implica che 
\[ \frac{(\mean{X} - \mean{Y}) - (\mu_x - \mu_y)}{\sqrt{\frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m}}} \sim N(0, 1) \]
e quindi si ottiene la probabilitò di effettuare un errore di prima specie attraverso
\[ P_{H_0}(-z_{\frac{\alpha}{2}} \leq \frac{(\mean{X} - \mean{Y}) - (\mu_x - \mu_y)}{\sqrt{\frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m}}}
                                 \leq z_{\frac{\alpha}{2}}) = 1 - \alpha \]
Da questa equazione otteniamo che $H_0$ risulta accettato se 
\[ \frac{(\mean{X} - \mean{Y}) - (\mu_x - \mu_y)}{\sqrt{\frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m}}} \leq z_{\frac{\alpha}{2}} \]
altrimenti $H_0$ viene rifiutato.

Per il test di ipotesi $H_0:\mu_x = \mu_y (\mu_x \leq \mu_y)$, con ipotesi alternativa $H_1:\mu_x > \mu_y$ si decide di
accettare $H_0$ se $\mean{X} - \mean{Y} \leq z_{\alpha}\sqrt{\frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m}}$ ed ovviamente 
rifiutarlo in caso contrario.

Supponiamo ora che i due campioni $(X_1, X_2, \dots, X_n)$ e $(Y_1, Y_2, \dots, Y_m)$ abbiamo tutti i parametri
sconosciuti, anche nelle due varianze $\sigma_x^2$ e $\sigma_y^2$, e di voler analizzare il test d'ipotesi 
$H_0:\mu_x = \mu_y$ con ipotesi alternativa $H_1:\mu_x \neq \mu_y$.\newline
Per poter determinare il test di ipotesi nulla $H_0$ effettuaimo l'assunzione che le varianze sconosciute $\sigma_x^2$ 
e $\sigma_y^2$ siano uguali, scrivendo $\sigma^2$ come valore comune.\mewline
Come prima si rifiuta $H_0$ quando $\mean{X} - \mean{Y}$ sono distanti da zero e per poterlo determinare definiamo 
le variabili $S_x^2$ e $S_y^2$ come gli stimatori delle varianze dei due campioni, la cui definizione è uguale a quella
di $S^2$, e come avevamo già notato nel capitolo precedente abbiamo che
\[ \frac{(\mean{X} - \mean{Y}) - (\mu_x - \mu_y)}{\sqrt{S^2_p(\frac{1}{n} + \frac{1}{m})}} \sim t_{n + m - 2} \]
dove $S_p^2$ è la pooled variance è data da 
\[ S_p^2 = \frac{(n-1)S^2_x + (m - 1)S^2_y}{n + m - 2} \]
Quando $H_0$ è verificato e quindi $\mu_x = \mu_y$ la variabile statistica 
\[ T \equiv \frac{(\mean{X} - \mean{Y})}{\sqrt{S^2_p(\frac{1}{n} + \frac{1}{m})}} \]
ha una distribuzione $t$, avente $n + m - 2$ gradi di libertà.\newline
Viene accettata l'ipotesi $H_0$ in caso $|Z| \leq t_{\frac{\alpha}{2}, n + m - 2}$ altrimenti lo si rifiuta.

In maniera alternativa è possibile determinare l'accettazione del test mediante il p-value, in cui si pone prima $v = T$
e il $p$-value è definito come
\[ \begin{split} 
    p-value & = P(|T_{n + m -2}| \geq |v|) \\
            & = 2P(T_{n + m -2} \geq |v|)\\
   \end{split} \]
Ovviamente, essendo il p-value la probabilità che l'ipotesi $H_0$ sia verificata, il p-value deve essere inferiore ad
$\alpha$ per avere il test, con confidenza $100(1 - \alpha)$.


