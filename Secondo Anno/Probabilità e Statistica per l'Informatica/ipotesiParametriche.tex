\chapter{Ipotesi Parametriche}
Supponiamo di avere un campione di una popolazione, specificato eccetto per un vettore di parametri sconosciuti che deve
essere osservato ed invece di stimare i parametri sconosciuti, analizzato e considerato nel capitolo precedente, in
questo capitolo verifichiamo/testiamo alcune ipotesi, affermazioni riguardo un insieme di parametri della popolazione,
sul campione analizzato.\newline
L'obiettivo di questo capitolo è quello di determinare se un campione casuale è consistente con l'ipotesi fatta per cui
consideriamo una popolazione, con distribuzione $F_0$, dove abbiamo il parametro sconusciuto $\theta$, e supponiamo di
testare una specifica ipotesi riguardo $\theta$, denotata con $H_0$ e chiamata \emph{ipotesi nulla}.

Se $F_0$ è distribuita secondo una normale, con media $\theta$ e varianza pari a $1$ allora due possibili ipotesi sono:
\begin{itemize}
    \item $H_0: \theta = 1$:specifica la distribuzione della popolazione e quindi si definisce \emph{ipotesi semplice}
    \item $H_0: \theta \leq 1$: non specifica la distribuzione della popolazioni, per cui si definisce \emph{ipotesi composta}
\end{itemize}
Supponiamo di testare l'ipotesi nulla $H_0$, osservando un campione $X_1, X_2, \dots, X_n$ ed attraverso i valori delle
realizzazioni del campione dobbiamo decidere se accettare o meno l'ipotesi $H_0$.

Un test su un ipotesi $H_0$ consiste nel definire la regione $C$ in uno spazio $n$-esimo in cui l'ipotesi viene
accettata se il campione $X_1, X_2, \dots, X_n$ è fuori dalla regione altrimenti viene rifiutata.\newline
Praticamente $H_0$ viene accettato se $(X_1, X_2, \dots, X_n) \not \in C$ 
mentre $H_0$ viene rifiutato se $(X_1, X_2, \dots, X_n) \in C$.

Un test comune su $\theta = 1$, media di una normale con varianza $1$, ha la regione critica data da
\[ C = \{(X_1, X_2, \dots, X_n) : |\frac{\sum _{i = 1} ^ n - 1}{n}| > \frac{1.96}{\sqrt{n}}\} \]
Questo test viene rifiutato quando la media campionaria differisca da 1 per più di $\frac{1.96}{\sqrt{n}}$.\newline
Quando si effettua un test di ipotesi possono generarsi due tipologie di errori:
\begin{itemize}
    \item \emph{errore di prima specie} se il test ci porta a rifiutare $H_0$ mentre in realtà sarebbe corretto
    \item \emph{errore di seconda specie} se il test ci porta ad accettare $H_0$ mentre in realtà sarebbe da rifiutare
\end{itemize}
L'obiettivo della statistica inferenziale è quello di stabilire se $H_0$ è consistente rispetto ai dati e sembra
ragionabile che $H_0$ sia rifiutato se i dati sono distanti quando $H_0$ è vero.\newline
Il modo classico di verificarlo consiste nello specificare un valore $\alpha$ e richiediamo che il test ha la
possibilità che se $H_0$ sia vero, allora la probabilità di effettuare un errore, e quindi rifiutarlo, è minore o uguale
a $\alpha$.\newline
Il valore $\alpha$ viene chiamato \emph{valore di confidenza} del test e viene settato in anticipo, con valori soliti
$0.01, 0.05 \text{ e } 0.001$.

Per stabilire se l'ipotesi nulla $H_0:\alpha \in w$ è corretta si effettuano i seguenti due passi:
\begin{itemize}
    \item determinare lo stimatore di $\alpha$, chiamata $d(X)$, in cui si rifiuta $H_0$ 
          se $d(X)$ è distante dalla regione $w$
    \item determinare la distribuzione di $d(X)$ quando $H_0$ risulta vero, dato che ciò ci permette di stabilire
          l'appropriata regione critica per fare il test, con significato $\alpha$.
\end{itemize}
Supponiamo che $X_1, X_2, \dots, X_n$ siano un campione normale di lunghezza $n$, avente media sconosciuta $\mu$ e
varianza anch'essa sconosciuta $\sigma^2$ e supponiamo inoltre di essere interessati all'ipotesi nulla $H_0:\mu = \mu_0$ 
contro l'ipotesi alternativa $H_1:\mu \neq \mu_0$, dove $\mu_0$ è una costante significativa.\newline
Dato che $\mean{X} = \sum _{i = 1}^n \frac{X_i}{n}$ è lo stimatore naturale di $\mu$ è ragionevole accettare $H_0$se non
è troppo distante da $\mu_0$, per cui la regione critica deve essere, per qualche $c$ stabilito,
\[ C = \{X_1, X_2, \dots, X_n : |\mean{X} - \mu_0| > c \} \]
Se vogliamo affermare che il test ha significato $\alpha$, allora dobbiamo determinare il valore $c$, tale per cui si
rende l'errore di prima specie uguale a $\alpha$ per cui risulta ovviamente
\[ P_{\mu_0}(|\mean{X} - \mu_0| > c) = \alpha \]
Quando risulta $\mu = \mu_0$ risulta $\mean{X}$ una normale con media $\mu_0$ e varianza $\sigma^2$ per cui 
\[ Z \equiv \frac{\mean{X} - \mu_0}{\frac{\sigma}{\sqrt{n}}} \sim N(0, 1) \]
Sostituendo questo risultato nella formula precedente otteniamo che
\[ P(|Z| > \frac{c \sqrt{n}}{\sigma}) = \alpha \]
Sapendo che $P(Z > z_{\frac{\alpha}{2}}) = \frac{\alpha}{2}$ e con passaggi algebrici otteniamo che 
\[ c = \frac{z_{\frac{\alpha}{2} \sigma}}{\sqrt{n}} \]
Il test di significato $\alpha$ viene rifiutato se risulta $|\mean{X} - \mu_0| > \frac{z_{\frac{\alpha}{2}}
\sigma}{\sqrt{n}}$ altrimenti viene accettato.

Un corretto livello di significato da usare dipende dalla circostanze, infatti se ad esempio rifiutare un ipotesi costa
un enormità, che sarebbe uno spreco in caso di un errore, allora si usano dei valori $\alpha$ molto piccoli
mentre in caso siamo sicuri della correttezza di $H_0$ allora per avere un'evidenza del contrario usiamo dei valori di
$\alpha$ abbastanza grandi.\newline
Dall'equazione precedente segue che possiamo determinare se accettare o meno l'ipotesi nulla attraverso la computazione prima del
valore statistico $v$ e poi della probabilità che una normale unitaria sia in valore assoluto $> v$.\newline
Questa probabilità, chiamata $p$-value di un test, fornisce il livello critico di accettazione, nel senso che $H_0$
è accettato se il livello di accettazione $\alpha$ è minore o uguale al $p$-value altrimenti viene rifiutato.\newline
Il livello di accettazione di solito non viene settato in anticipo ma lo si cerca di determinare, quando si effettua
l'analisi e il test dell'ipotesi.

La probabilità di avere un errore di seconda specie, in cui accettiamo l'ipotesi nulla $H_0$ quando $\mu \neq \mu_0$,
dipende dal valore di $\mu$ per cui definiamo $\beta(\mu)$ come
\[  \begin{split}
    \beta(\mu) & = P_{\mu}(H_0 \text{ è accettato}) \\
               & = P_{\mu}(|\frac{\mean{X} - \mu}{\frac{\sigma}{\sqrt{n}}}| \leq z_{\frac{\alpha}{2}}) \\
               & = P_{\mu}(-z_{\frac{\alpha}{2}} \leq |\frac{\mean{X} - \mu}{\frac{\sigma}{\sqrt{n}}}| \leq z_{\frac{\alpha}{2}})\\
    \end{split} \]
La funzione $\beta(\mu)$ è chiamata la curva \emph{caratteristica operativa(OC)} e rappresenta la probabilità che $H_0$
viene accettata quando la media vera è $\mu$.
Attraverso dei passaggi algebrici e della definizione di approssimazione di una normale la valutazione della funzione
$\beta$ consiste nella differenza della valutazione, mediante le tavole normali standard, di $\frac{\mu_0 -
\mu}{\frac{\sigma}{\sqrt{n}}} + z_{\frac{\alpha}{2}}$ e $\frac{\mu_0 - \mu}{\frac{\sigma}{\sqrt{n}}} -z_{\frac{\alpha}{2}}$.
Per un livello fissato $\alpha$, la curva OC risulta simmetrica rispetto a $\mu_0$ e dipenda da $\mu$ solo attraverso
$\frac{\sqrt{n}}{\sigma} |\mu - \mu_0|$.\newline
La funzione $1 - \beta(\mu)$ è chiamata la funzione \emph{potenza} del test, ossia per un dato $\mu$, la potenza del
test è uguale alla proprietà di rifiuto quando $\mu$ è il valore corretto.\newline
La funzione OC è utile per determinare la lunghezza del campione casuale per cui possiamo fare alcune specifiche sugli
errori di seconda specie.


Nell'effettuare il test sull'ipotesi nulla $H_0:\mu = \mu_0$ abbiamo scelto un test che rifiuta quando $\mean{X}$ è
distante da $\mu_0$ con valore minore o maggiore di $\mu_0$.\newline
Se in caso volessimo avere come ipotesi alternativa $H_1:\mu > \mu_0$, in cui non vogliamo rifiutare $H_0$ quando
$\mean{X}$ sia minore di $\mu_0$, dato che in quel caso è più verosimile che $H_0$ sia corretto rispetto a $H_1$.\newline
Per questo motivo quando si effettua un test $H_0:\mu = \mu_0$ versus $H_1:\mu > \mu_0$ la regione critica deve essere
\[ C = \{(X_1, X_2, \dots, X_n) : \mean{X} - \mu_0 > c \} \]
Dato che la probabilità di rifiutare deve essere uguale a $\alpha$ quando $H_0$ è vero dobbiamo richiedere che 
\[ P(\mean{X} - \mu_0 > c) = \alpha \]
ma dato che $Z = \frac{\sqrt{n} \mean{X} - \mu_0}{\sigma} \sim N(0, 1)$ quando $H_0$ è vero, segue che
\[ P_{\mu_0}(\mean{X} - \mu_0) = P(Z > \frac{c \sqrt{n}}{\sigma} = \alpha \mbox{ quando } Z \sim N(0, 1) \]
Essendo $P(Z > z_{\alpha}) = \alpha$ notiamo che $c = \frac{z_{\alpha} \sigma}{\sqrt{n}}$.
Il test di ipotesi $H_0$ analizzato ora viene rifiutato se $\mean{X} - \mu_0 > \frac{z_{\alpha}\sigma}{\sqrt{n}}$
altrimenti viene accettato ossia equivalentemente risulta che
$H_0$ è accettato se $\frac{\sqrt{n}}{\sigma}(\mean{X} - \mu_0) \leq z_{\alpha}$ altrimenti viene accettato $H_1$.
Questa viene chiamata regione critica a solo un verso e il corrispondente test viene chiamato \emph{test a un solo verso}.

Per calcolare il $p$-value nell'equazione precedente prima usiamo i dati effettivi per calcolare il valore della
statistica $\frac{\sqrt{n} (\mean{X} - \mu)}{\sigma}$ e il p-value è uguale alla probabilità che l'ipotesi $H_0$ sia
verificata, per cui nel caso di un campione normalmente distribuito deve essere almeno largo 

La funzione OC per i test a un solo verso è definita come
\[  \begin{split}
    \beta(\mu) & = P_{\mu}(H_0 \mbox{ verificato}) \\
               & = P_{\mu}(\mean{X} \leq \mu_0 + z_{\alpha}\frac{\sigma}{\sqrt{n}} \\
               & = P_{\mu}(\frac{\mean{X} - \mu}{\sigma}{\sqrt{n}} \leq \frac{\mu_0 - \mu}{\frac{\sigma}{\sqrt{n}}} + z_{\alpha}\\
               & = P(Z \leq \frac{\mu_0 - \mu}{\frac{\sigma}{\sqrt{n}}} \\
    \end{split} \]
Risulta che la funzione $\beta(\mu)$ viene calcolata usando le tavole standard della normale, come avevamo visto nella
definizione della funzione $\beta$ per i test a doppio verso.\newline
All'aumento del valore del suo argomento, la funzione $\beta(\mu)$ porta a decrescere in $\mu$ e questo proviene
dall'intuizione che è ragionavolmente vero che lontani dalla media $\mu$ è molto meno probabile che si conclude $\mu \leq mu_0$
ed inoltre risulta $\beta(\mu_0) = 1 - \alpha$
Il test dato dall'equazione 8.3.10., disegnato per il test $H_0:\mu = \mu_0$ versus $H_1:\mu > \mu_0$ può essere usato
come test, con significatività $\alpha$, per il test di ipotesi ad una grandezza $H_0:\mu \leq \mu_0$ versus $H_1: \mu > \mu_0$.\newline
Per verificare che rimane un test di confidenza $\alpha$ dobbiamo mostrare che la probabilità di rifiuto di $H_0$ non
sarà più grande di $\alpha$ quando $H_0$ sarebbe vero.\newline
Per fare questo bisogna mostrare che $1 - \beta(\mu) \leq \alpha$ per ogni $\mu \leq \mu_0$ ma abbiamo già mostrato
nell'equazione 8.3.10 che $\beta(\mu)$ diminuisce in $\mu$ e $\beta(\mu_0) = 1 - \alpha$ da cui siamo in grado di
ottenere $\beta(\mu) \geq \beta(\mu_0) = 1 - \alpha$ per ogni valore $\mu \leq \mu_0$.\newline
Oltre alla definizione del test a un verso del tipo $H_0:\mu \leq \mu_0$, è possibile definire un test ad un solo verso 
del tipo $H_0:\mu = \mu_0(\mu \geq \mu_0)$ con test alternativo $H_1:\mu < \mu_0$, avente significato $\alpha$, tale per
cui $H_0$ risulta accettato se $\frac{\sqrt{n}}{\sigma} (\mean{X} - \mu_0) \geq -z_{\alpha}$ altrimenti $H_0$ è rifiutato.

Questo test può essere effettuato in maniera alternativa, calcolando prima il valore statistico $\frac{\sqrt{n}(\mean{X} -
\mu_0)}{\sigma}$ e poi calcolare il $p$-value, indicante la probabilità che l'ipotesi $H_0$ sia verificata, per cui si
rifiuta l'ipotesi $H_0$ in caso il nostro livello di significato $\alpha$ sia maggiore o uguale al $p$-value.

Fino ad ora abbiamo supposto che $\sigma^2$ non fosse sconosciuto ma il caso comune avviene 
con sia $\mu$ e $\sigma^2$ sconosciuti.\newline
Supponiamo ora di considerare un test di ipotesi $H_0:\mu = \mu_0$ con l'alternativa $H_1:\mu \neq \mu_0$ e si dovrebbe
notare che l'ipotesi nulla $H_0$ non è più semplice, in quanto non conosciamo la distribuzione di $\sigma^2$.\newline
Come prima, sembra ragionevole rigettare $H_0$ quando $\mean{X}$ è distante da $\mu$ ma la distanza necessaria per
rifiutarlo dipende dal valore di $\sigma^2$.\newline
Sapendo che $\sigma^2$ ha come massimo stimatore la variabile 
\[ S^2 = \frac{\sum _{i = 0}^n (\mean{X} - \mu)^2}{n - 1} \] 
da cui segue che si rifiuta $H_0$ quando è largo $|\frac{\mean{X} - \mu}{\frac{S}{\sqrt{n}}}|$.\newline
Per stabilire per quale valore dobbiamo rifiutare, al fine di avere un test con significato $\alpha$, dobbiamo
determinare la funzione di ripartizione di $|\frac{\mean{X} - \mu}{\frac{S}{\sqrt{n}}}|$ quando $H_0$ è verificato.

Come già notato e dimostrato nel capitolo precedente la statistica $T$, definita come
\[ T = \frac{\sqrt{n} (\mean{X} - \mu)}{S} \]
quando $\mu = \mu_0$ risulta una $t$-student con $n - 1$ gradi di libertà.\newline
Da questo aspetto si ricava che 
\[ P(-t_{\frac{\alpha}{2}, n - 1} \leq \frac{\sqrt{n} (\mean{X} - \mu_0)}{S} \leq t_{\frac{\alpha}{2}, n - 1}) = 1 - \alpha\]
dove $t_{\frac{\alpha}{2}, n - 1}$ è il $100(\frac{alpha}{2}$ quantile della distribuzione t con $n - 1$ gradi di libertà.\newline
Dall'ultima equazione si può notare che un test con significato $\alpha$ di $H_0:\mu = \mu_0$ con ipotesi alternativa
$H_1:\mu \neq \mu_0$, con $\sigma^2$ sconosciuto che ci pone ad affermare che $H_0$ risulta accettato se 
$|T| \leq t_{\frac{\alpha}{2}, n - 1}$ altrimenti $H_0$ risulta rifiutato.

È possibile effettuare un test $t$ ad un solo verso per testare l'ipotesi $H_0:\mu = \mu_0(\mu \leq \mu_0)$ con ipotesi
alternativa $H_1:\mu > \mu_0$ avente significato $\alpha$, in cui $H_0$ risulta accettato se $|T| \leq t_{\frac{\alpha}{2}, n - 1}$
altrimenti si rifiuta $H_0$.\newline
Il test avente significato $\alpha$, $H_0: \mu = \mu_0(\mu \geq \mu_0)$ con ipotesi alternativa $H_1:\mu < \mu_0$ porta
ad accettare $H_0$ se $\frac{\sqrt{n} (\mean{X} - \mu)}{S} \geq -t_{\frac{\alpha}{2}, n - 1}$ altrimenti $H_0$ viene rifiutato.

Una situazione normale è stabilire se due campioni, aventi distribuzione normale, di una popolazione hanno la stessa
media, per questo consideriamo il test di ipotesi $H_0:\mu_x = \mu_y$, con ipotesi alternativa $H_1:\mu_x \neq \mu_y$,
effettuato sui campioni $(X_1, X_2, \dots, X_n)$ e $(Y_1, Y_2, \dots, Y_m)$ indipendenti provenienti da una popolazione
normalmente distribuita, aventi media sconosciuta $\mu_x$ e $\mu_y$ ma varianze conosciute $\sigma^2_x$ e $\sigma^2_y$.

Essendo $\mean{X}$ il naturale stimatore di $\mu_x$ e $\mean{Y}$ il naturale stimatore di $\mu_y$, segue che $\mean{X} - \mean{Y}$
può essere usato per stimare $\mu_x - \mu_y$.\newline
In quanto il test di ipotesi può essere scritto come $H_0:\mu_x - \mu_y = 0$ sembra ragionevole
rifiutare $\mean{X} - \mean{Y}$ quando è distante da zero.\newline
La forma del test dovrebbe portarci ad accettare $H_0$ se $|\mean{X} - \mean{Y}| \leq c$ altrimenti a rifiutare $H_0$
e per determinare il valore di $c$, necessario per verificare il test di significato $\alpha$, dobbiamo conoscere la
distribuzione di $\mean{X} - \mean{Y}$ quando $H_0$ è vero.\newline
Come abbiamo già dimostrato nel capitolo precedente, abbiamo che 
$\mean{X} - \mean{Y} \sim N(\mu_x - \mu_y, \frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m})$ che implica che 
\[ \frac{(\mean{X} - \mean{Y}) - (\mu_x - \mu_y)}{\sqrt{\frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m}}} \sim N(0, 1) \]
e quindi si ottiene la probabilitò di effettuare un errore di prima specie attraverso
\[ P_{H_0}(-z_{\frac{\alpha}{2}} \leq \frac{(\mean{X} - \mean{Y}) - (\mu_x - \mu_y)}{\sqrt{\frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m}}}
                                 \leq z_{\frac{\alpha}{2}}) = 1 - \alpha \]
Da questa equazione otteniamo che $H_0$ risulta accettato se 
\[ \frac{(\mean{X} - \mean{Y}) - (\mu_x - \mu_y)}{\sqrt{\frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m}}} \leq z_{\frac{\alpha}{2}} \]
altrimenti $H_0$ viene rifiutato.

Per il test di ipotesi $H_0:\mu_x = \mu_y (\mu_x \leq \mu_y)$, con ipotesi alternativa $H_1:\mu_x > \mu_y$ si decide di
accettare $H_0$ se $\mean{X} - \mean{Y} \leq z_{\alpha}\sqrt{\frac{\sigma_x^2}{n} + \frac{\sigma_y^2}{m}}$ ed ovviamente 
rifiutarlo in caso contrario.

Supponiamo ora che i due campioni $(X_1, X_2, \dots, X_n)$ e $(Y_1, Y_2, \dots, Y_m)$ abbiamo tutti i parametri
sconosciuti, anche nelle due varianze $\sigma_x^2$ e $\sigma_y^2$, e di voler analizzare il test d'ipotesi 
$H_0:\mu_x = \mu_y$ con ipotesi alternativa $H_1:\mu_x \neq \mu_y$.\newline
Per poter determinare il test di ipotesi nulla $H_0$ effettuaimo l'assunzione che le varianze sconosciute $\sigma_x^2$ 
e $\sigma_y^2$ siano uguali, scrivendo $\sigma^2$ come valore comune.\newline
Come prima si rifiuta $H_0$ quando $\mean{X} - \mean{Y}$ sono distanti da zero e per poterlo determinare definiamo 
le variabili $S_x^2$ e $S_y^2$ come gli stimatori delle varianze dei due campioni, la cui definizione è uguale a quella
di $S^2$, e come avevamo già notato nel capitolo precedente abbiamo che
\[ \frac{(\mean{X} - \mean{Y}) - (\mu_x - \mu_y)}{\sqrt{S^2_p(\frac{1}{n} + \frac{1}{m})}} \sim t_{n + m - 2} \]
dove $S_p^2$ è la pooled variance è data da 
\[ S_p^2 = \frac{(n-1)S^2_x + (m - 1)S^2_y}{n + m - 2} \]
Quando $H_0$ è verificato e quindi $\mu_x = \mu_y$ la variabile statistica 
\[ T \equiv \frac{(\mean{X} - \mean{Y})}{\sqrt{S^2_p(\frac{1}{n} + \frac{1}{m})}} \]
ha una distribuzione $t$, avente $n + m - 2$ gradi di libertà.\newline
Viene accettata l'ipotesi $H_0$ in caso $|Z| \leq t_{\frac{\alpha}{2}, n + m - 2}$ altrimenti lo si rifiuta.

In maniera alternativa è possibile determinare l'accettazione del test mediante il p-value, in cui si pone prima $v = T$
e il $p$-value è definito come
\[ \begin{split} 
    p-value & = P(|T_{n + m -2}| \geq |v|) \\
            & = 2P(T_{n + m -2} \geq |v|)\\
   \end{split} \]
Ovviamente, essendo il p-value la probabilit che l'ipotesi $H_0$ sia verificata, il p-value deve essere superiore ad
$\alpha$ per avere l'accettazione del test, con confidenza $100(1 - \alpha)$.

Supponiamo che la varianza $\sigma^2_x$ e $\sigma^2_y$ non solo sono sconosciute ma anche diseguali ed essendo $S^2_x$ e $S^2_y$ i normali stimatori di $\sigma_x^2$ e $\sigma_y^2$
sembra ragionevole basare il nostro test $H_0:\mu_x = \mu_y$ vs $H_1:\mu_x \neq \mu_y$ sulla statistica 
\[ \frac{\mean{x} - \mean{y}}{\sqrt{\frac{S^2_x}{n} + \frac{S^2_y}{m} \] 
Comunque questa statistica ha una distribuzione complicata, in cui a meno di $H_0$ verificato, dipende da parametri sconosciuti e non si puògeneralmente analizzare.\newline
L'unica situazione in cui possiamo usare questa statistica è quando $n$ e $m$ sono entrambi larghi e in questo caso può essere mostrato che quando $H_0$ è vero,
l'equazione precedente può essere approssimabile mediante una distribuzione normale standard in cui si accetta $H_0$ se 
\[ -z_{\frac{\alpha}{2} \leq \frac{\mean{X} - \mean{Y}}{\sqrt{\frac{S_x^2}{n} + \frac{S_y^2}{m}}} \leq z_{\frac{\alpha}{2}} \]
altrimenti $H_0$ viene rifiutato.\newline
Il problema di determinare l'esatto livello $\alpha$ di test d'ipotesi della media di 2 popolazioni normali, aventi sconosciute e non necessariamente uguali varianze,
è conosciuto come il problema di \emph{Behrens-Fishe}, di cui non ci sono ancora soluzioni completamente soddisfacenti.

Siano $X_1, X_2, \dots, X_n$ un campione normale avente media sconosciuta $\mu$ e varianza sconusciuta $\sigma^2$ e vogliamo effettuare il test d'ipotesi:
\[ H_0: \sigma_x^2 = \sigma_0^2 \mbox{  vs   } H_1: \sigma_x^2 \neq \sigma_0^2 \]
Per ottenere il test ricordiamo che $\frac{(n - 1)S^2}{\sigma^2}$ ha una distribuzione chi-quadro con $n - 1$ gradi di liberta' e quando $H_0$ è verificato
\[ \frac{(n - 1)S^2}{\sigma^2} \sim \chi_{n - 1} \] 
e quindi si ottiene che si accetta $H_0$, con significativita' $\alpha$, se 
\[ \chi_{1 - \frac{\alpha}{2}, n - 1} \leq \frac{(n - 1)S^2}{\sigma^2} \leq \chi_{\frac{\alpha}{2}, n - 1} \]
altrimenti lo si rifiuta.\newline
Il test precedente può essere implementatoi prima calcolando il valore della variabile statistica e poi calcolando la probabilita' che una variabile chi-quadro, con $n - 1$ gradi 
di liberta', sia minore della variabile statistica ossia 
\[ p-value = 2 \min(P(\chi^2_{n - 1} < c), P(\chi^2_{n - 1} > c)) \]
Il p-value e i test a un solo verso si possono ottenere in maniera equivalente, ragionando come fatto in precedenza per i test sulla media.

Siano $X_1, X_2, \dots, X_n$ e $Y_1, Y_2, \dots, Y_m$ 2 campioni indipendenti di 2 popolazioni normali, aventi parametri $(\mu_x, \sigma_x^2)$ e $(\mu_y, \sigma_y^2)$
e consideriamo il test statistico $H_0: \sigma_x^2 = \sigma_y^2$ con ipotesi alternativa $H_1:\sigma_x^2 \neq \sigma_y^2$.\newline
Se poniamo $S_x^2 = \frac{\sum _{i = 1}^n (X_i - \mean{X})^2}{n - 1}$ e $S_y^2 = \frac{\sum _{i = 1}^n (Y_i - \mean{Y})^2}{n - 1}$ e sapendo che 
$\frac{(n - 1)S_x^2}{\sigma_x^2}$ e $\frac{(n - 1)S_y^2}{\sigma y^2}$ hanno entrmabi una distribuzione chi-quadro con $n - 1$ e $m - 1$ gradi di liberta'.\newline
Quindi $\frac{\sigma_y^2 S_x^2}{\sigma_x^2 S_y^2}$ ha una distribuzione $F$, con parametri $n - 1$ e $m - 1$ e quindi si accetta $H_0$ se 
\[ F_{1 - \frac{\alpha}{2}, n - 1, m - 1} \leq \frac{S_x^2}{S_y^2} \leq F_{\frac{\alpha}{2}, n - 1, m - 1} \]
altrimenti $H_0$ viene rifiutato e comunque si può calcolare il $p-value$, che ha definizione e calcolo similare a quello gia' visto durante questo capitolo.

\section{Test per l'incorrelazione}
Il test che viene ora presentato si riferisce ad un parametro che descrive il grado di correlazione tra due popolazioni $X$ ed $Y$ ovvero tra due diversi 
caratteri di una popolazione bidimensionale $(X,Y)$.\newline
Tale parametro è il coefficiente di correlazione lineare di Pearson definito come
\[ p_{XY} = \frac{\sigma_{xy}}{\sigma_x \cdots \sigma_y \]
dove ovviamente $\sigma_{xy}$ è la covarianza tra i due caratteri.\newline
Osserviamo che quando sono noti i dati $(x_i, y_i)$ di tutti gli elementi della popolazione bidimensionale $(X, Y)$ allora il coefficiente di pearson concide con
il coefficiente di correlazione lineare nel primo capitolo per cui $p_{xy}$ ammette valori nell'intervallo $[-1, 1]$.\newline
Data una popolazione bidimensionale $(X,Y)$ in contesti reali non è mai possibile determinare il valore del coefficiente di correlazione lineare 
e questo per gli stessi motivi per i quali non è possibile determinare esattamente il valore dei parametri $\sigma_x, \sigma_y, \mu_x, \mu_y$ per cui si effettua una stima.\newline
A tal punto si utilizza lo stimatore $R_n$ definito sul campione $((X_1, Y_1), \dots, (X_n, Y_n))$ come
\[ R_n = \frac{\sum _{i = 1}^n (Y_i - \mean{Y})(X_i - \mean{X})}{n \cdots S_{X, n} S_{Y, n}} \]
Il test di incorrelazione che andiamo a presentare consiste nel verificare che il coefficiente $p_{xy}$ assuma valore $0$ e quindi vi sia un incorrelazione tra i due caratteri
quindi per l'ipotesi $H_0: p_{xy} = 0$ la statistica 
\[ \bar{T_n} = R_n * \sqrt{\frac{n - 2}{1 - R_n^2} \]
risulta distribuito come una t di student con $n - 2$ gradi di libertà e si accetta $H_0$ quando non assume valori non troppo distanti da zero.
